module.exports = [
"[project]/node_modules/bullmq/dist/esm/classes/async-fifo-queue.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "AsyncFifoQueue",
    ()=>AsyncFifoQueue
]);
class Node {
    constructor(value){
        this.value = undefined;
        this.next = null;
        this.value = value;
    }
}
class LinkedList {
    constructor(){
        this.length = 0;
        this.head = null;
        this.tail = null;
    }
    push(value) {
        const newNode = new Node(value);
        if (!this.length) {
            this.head = newNode;
        } else {
            this.tail.next = newNode;
        }
        this.tail = newNode;
        this.length += 1;
        return newNode;
    }
    shift() {
        if (!this.length) {
            return null;
        } else {
            const head = this.head;
            this.head = this.head.next;
            this.length -= 1;
            return head;
        }
    }
}
class AsyncFifoQueue {
    constructor(ignoreErrors = false){
        this.ignoreErrors = ignoreErrors;
        /**
         * A queue of completed promises. As the pending
         * promises are resolved, they are added to this queue.
         */ this.queue = new LinkedList();
        /**
         * A set of pending promises.
         */ this.pending = new Set();
        this.newPromise();
    }
    add(promise) {
        this.pending.add(promise);
        promise.then((data)=>{
            this.pending.delete(promise);
            if (this.queue.length === 0) {
                this.resolvePromise(data);
            }
            this.queue.push(data);
        }).catch((err)=>{
            // Ignore errors
            if (this.ignoreErrors) {
                this.queue.push(undefined);
            }
            this.pending.delete(promise);
            this.rejectPromise(err);
        });
    }
    async waitAll() {
        await Promise.all(this.pending);
    }
    numTotal() {
        return this.pending.size + this.queue.length;
    }
    numPending() {
        return this.pending.size;
    }
    numQueued() {
        return this.queue.length;
    }
    resolvePromise(data) {
        this.resolve(data);
        this.newPromise();
    }
    rejectPromise(err) {
        this.reject(err);
        this.newPromise();
    }
    newPromise() {
        this.nextPromise = new Promise((resolve, reject)=>{
            this.resolve = resolve;
            this.reject = reject;
        });
    }
    async wait() {
        return this.nextPromise;
    }
    async fetch() {
        var _a;
        if (this.pending.size === 0 && this.queue.length === 0) {
            return;
        }
        while(this.queue.length === 0){
            try {
                await this.wait();
            } catch (err) {
                // Ignore errors
                if (!this.ignoreErrors) {
                    console.error('Unexpected Error in AsyncFifoQueue', err);
                }
            }
        }
        return (_a = this.queue.shift()) === null || _a === void 0 ? void 0 : _a.value;
    }
} //# sourceMappingURL=async-fifo-queue.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/backoffs.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "Backoffs",
    ()=>Backoffs
]);
class Backoffs {
    static normalize(backoff) {
        if (Number.isFinite(backoff)) {
            return {
                type: 'fixed',
                delay: backoff
            };
        } else if (backoff) {
            return backoff;
        }
    }
    static calculate(backoff, attemptsMade, err, job, customStrategy) {
        if (backoff) {
            const strategy = lookupStrategy(backoff, customStrategy);
            return strategy(attemptsMade, backoff.type, err, job);
        }
    }
}
Backoffs.builtinStrategies = {
    fixed: function(delay, jitter = 0) {
        return function() {
            if (jitter > 0) {
                const minDelay = delay * (1 - jitter);
                return Math.floor(Math.random() * delay * jitter + minDelay);
            } else {
                return delay;
            }
        };
    },
    exponential: function(delay, jitter = 0) {
        return function(attemptsMade) {
            if (jitter > 0) {
                const maxDelay = Math.round(Math.pow(2, attemptsMade - 1) * delay);
                const minDelay = maxDelay * (1 - jitter);
                return Math.floor(Math.random() * maxDelay * jitter + minDelay);
            } else {
                return Math.round(Math.pow(2, attemptsMade - 1) * delay);
            }
        };
    }
};
function lookupStrategy(backoff, customStrategy) {
    if (backoff.type in Backoffs.builtinStrategies) {
        return Backoffs.builtinStrategies[backoff.type](backoff.delay, backoff.jitter);
    } else if (customStrategy) {
        return customStrategy;
    } else {
        throw new Error(`Unknown backoff strategy ${backoff.type}.
      If a custom backoff strategy is used, specify it when the queue is created.`);
    }
} //# sourceMappingURL=backoffs.js.map
}),
"[project]/node_modules/bullmq/dist/esm/enums/child-command.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "ChildCommand",
    ()=>ChildCommand
]);
var ChildCommand;
(function(ChildCommand) {
    ChildCommand[ChildCommand["Init"] = 0] = "Init";
    ChildCommand[ChildCommand["Start"] = 1] = "Start";
    ChildCommand[ChildCommand["Stop"] = 2] = "Stop";
    ChildCommand[ChildCommand["GetChildrenValuesResponse"] = 3] = "GetChildrenValuesResponse";
    ChildCommand[ChildCommand["GetIgnoredChildrenFailuresResponse"] = 4] = "GetIgnoredChildrenFailuresResponse";
    ChildCommand[ChildCommand["MoveToWaitingChildrenResponse"] = 5] = "MoveToWaitingChildrenResponse";
})(ChildCommand || (ChildCommand = {})); //# sourceMappingURL=child-command.js.map
}),
"[project]/node_modules/bullmq/dist/esm/enums/error-code.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "ErrorCode",
    ()=>ErrorCode
]);
var ErrorCode;
(function(ErrorCode) {
    ErrorCode[ErrorCode["JobNotExist"] = -1] = "JobNotExist";
    ErrorCode[ErrorCode["JobLockNotExist"] = -2] = "JobLockNotExist";
    ErrorCode[ErrorCode["JobNotInState"] = -3] = "JobNotInState";
    ErrorCode[ErrorCode["JobPendingChildren"] = -4] = "JobPendingChildren";
    ErrorCode[ErrorCode["ParentJobNotExist"] = -5] = "ParentJobNotExist";
    ErrorCode[ErrorCode["JobLockMismatch"] = -6] = "JobLockMismatch";
    ErrorCode[ErrorCode["ParentJobCannotBeReplaced"] = -7] = "ParentJobCannotBeReplaced";
    ErrorCode[ErrorCode["JobBelongsToJobScheduler"] = -8] = "JobBelongsToJobScheduler";
    ErrorCode[ErrorCode["JobHasFailedChildren"] = -9] = "JobHasFailedChildren";
    ErrorCode[ErrorCode["SchedulerJobIdCollision"] = -10] = "SchedulerJobIdCollision";
    ErrorCode[ErrorCode["SchedulerJobSlotsBusy"] = -11] = "SchedulerJobSlotsBusy";
})(ErrorCode || (ErrorCode = {})); //# sourceMappingURL=error-code.js.map
}),
"[project]/node_modules/bullmq/dist/esm/enums/parent-command.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "ParentCommand",
    ()=>ParentCommand
]);
var ParentCommand;
(function(ParentCommand) {
    ParentCommand[ParentCommand["Completed"] = 0] = "Completed";
    ParentCommand[ParentCommand["Error"] = 1] = "Error";
    ParentCommand[ParentCommand["Failed"] = 2] = "Failed";
    ParentCommand[ParentCommand["InitFailed"] = 3] = "InitFailed";
    ParentCommand[ParentCommand["InitCompleted"] = 4] = "InitCompleted";
    ParentCommand[ParentCommand["Log"] = 5] = "Log";
    ParentCommand[ParentCommand["MoveToDelayed"] = 6] = "MoveToDelayed";
    ParentCommand[ParentCommand["MoveToWait"] = 7] = "MoveToWait";
    ParentCommand[ParentCommand["Progress"] = 8] = "Progress";
    ParentCommand[ParentCommand["Update"] = 9] = "Update";
    ParentCommand[ParentCommand["GetChildrenValues"] = 10] = "GetChildrenValues";
    ParentCommand[ParentCommand["GetIgnoredChildrenFailures"] = 11] = "GetIgnoredChildrenFailures";
    ParentCommand[ParentCommand["MoveToWaitingChildren"] = 12] = "MoveToWaitingChildren";
})(ParentCommand || (ParentCommand = {})); //# sourceMappingURL=parent-command.js.map
}),
"[project]/node_modules/bullmq/dist/esm/enums/metrics-time.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "MetricsTime",
    ()=>MetricsTime
]);
var MetricsTime;
(function(MetricsTime) {
    MetricsTime[MetricsTime["ONE_MINUTE"] = 1] = "ONE_MINUTE";
    MetricsTime[MetricsTime["FIVE_MINUTES"] = 5] = "FIVE_MINUTES";
    MetricsTime[MetricsTime["FIFTEEN_MINUTES"] = 15] = "FIFTEEN_MINUTES";
    MetricsTime[MetricsTime["THIRTY_MINUTES"] = 30] = "THIRTY_MINUTES";
    MetricsTime[MetricsTime["ONE_HOUR"] = 60] = "ONE_HOUR";
    MetricsTime[MetricsTime["ONE_WEEK"] = 10080] = "ONE_WEEK";
    MetricsTime[MetricsTime["TWO_WEEKS"] = 20160] = "TWO_WEEKS";
    MetricsTime[MetricsTime["ONE_MONTH"] = 80640] = "ONE_MONTH";
})(MetricsTime || (MetricsTime = {})); //# sourceMappingURL=metrics-time.js.map
}),
"[project]/node_modules/bullmq/dist/esm/enums/telemetry-attributes.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "SpanKind",
    ()=>SpanKind,
    "TelemetryAttributes",
    ()=>TelemetryAttributes
]);
var TelemetryAttributes;
(function(TelemetryAttributes) {
    TelemetryAttributes["QueueName"] = "bullmq.queue.name";
    TelemetryAttributes["QueueOperation"] = "bullmq.queue.operation";
    TelemetryAttributes["BulkCount"] = "bullmq.job.bulk.count";
    TelemetryAttributes["BulkNames"] = "bullmq.job.bulk.names";
    TelemetryAttributes["JobName"] = "bullmq.job.name";
    TelemetryAttributes["JobId"] = "bullmq.job.id";
    TelemetryAttributes["JobKey"] = "bullmq.job.key";
    TelemetryAttributes["JobIds"] = "bullmq.job.ids";
    TelemetryAttributes["JobAttemptsMade"] = "bullmq.job.attempts.made";
    TelemetryAttributes["DeduplicationKey"] = "bullmq.job.deduplication.key";
    TelemetryAttributes["JobOptions"] = "bullmq.job.options";
    TelemetryAttributes["JobProgress"] = "bullmq.job.progress";
    TelemetryAttributes["QueueDrainDelay"] = "bullmq.queue.drain.delay";
    TelemetryAttributes["QueueGrace"] = "bullmq.queue.grace";
    TelemetryAttributes["QueueCleanLimit"] = "bullmq.queue.clean.limit";
    TelemetryAttributes["QueueRateLimit"] = "bullmq.queue.rate.limit";
    TelemetryAttributes["JobType"] = "bullmq.job.type";
    TelemetryAttributes["QueueOptions"] = "bullmq.queue.options";
    TelemetryAttributes["QueueEventMaxLength"] = "bullmq.queue.event.max.length";
    TelemetryAttributes["WorkerOptions"] = "bullmq.worker.options";
    TelemetryAttributes["WorkerName"] = "bullmq.worker.name";
    TelemetryAttributes["WorkerId"] = "bullmq.worker.id";
    TelemetryAttributes["WorkerRateLimit"] = "bullmq.worker.rate.limit";
    TelemetryAttributes["WorkerDoNotWaitActive"] = "bullmq.worker.do.not.wait.active";
    TelemetryAttributes["WorkerForceClose"] = "bullmq.worker.force.close";
    TelemetryAttributes["WorkerStalledJobs"] = "bullmq.worker.stalled.jobs";
    TelemetryAttributes["WorkerFailedJobs"] = "bullmq.worker.failed.jobs";
    TelemetryAttributes["WorkerJobsToExtendLocks"] = "bullmq.worker.jobs.to.extend.locks";
    TelemetryAttributes["JobFinishedTimestamp"] = "bullmq.job.finished.timestamp";
    TelemetryAttributes["JobProcessedTimestamp"] = "bullmq.job.processed.timestamp";
    TelemetryAttributes["JobResult"] = "bullmq.job.result";
    TelemetryAttributes["JobFailedReason"] = "bullmq.job.failed.reason";
    TelemetryAttributes["FlowName"] = "bullmq.flow.name";
    TelemetryAttributes["JobSchedulerId"] = "bullmq.job.scheduler.id";
})(TelemetryAttributes || (TelemetryAttributes = {}));
var SpanKind;
(function(SpanKind) {
    SpanKind[SpanKind["INTERNAL"] = 0] = "INTERNAL";
    SpanKind[SpanKind["SERVER"] = 1] = "SERVER";
    SpanKind[SpanKind["CLIENT"] = 2] = "CLIENT";
    SpanKind[SpanKind["PRODUCER"] = 3] = "PRODUCER";
    SpanKind[SpanKind["CONSUMER"] = 4] = "CONSUMER";
})(SpanKind || (SpanKind = {})); //# sourceMappingURL=telemetry-attributes.js.map
}),
"[project]/node_modules/bullmq/dist/esm/enums/index.js [app-route] (ecmascript) <locals>", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$child$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/child-command.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$error$2d$code$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/error-code.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/parent-command.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$metrics$2d$time$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/metrics-time.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/telemetry-attributes.js [app-route] (ecmascript)"); //# sourceMappingURL=index.js.map
;
;
;
;
;
}),
"[project]/node_modules/bullmq/dist/esm/classes/child.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "Child",
    ()=>Child
]);
var __TURBOPACK__imported__module__$5b$externals$5d2f$child_process__$5b$external$5d$__$28$child_process$2c$__cjs$29$__ = __turbopack_context__.i("[externals]/child_process [external] (child_process, cjs)");
var __TURBOPACK__imported__module__$5b$externals$5d2f$net__$5b$external$5d$__$28$net$2c$__cjs$29$__ = __turbopack_context__.i("[externals]/net [external] (net, cjs)");
var __TURBOPACK__imported__module__$5b$externals$5d2f$worker_threads__$5b$external$5d$__$28$worker_threads$2c$__cjs$29$__ = __turbopack_context__.i("[externals]/worker_threads [external] (worker_threads, cjs)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$child$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/child-command.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/parent-command.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$externals$5d2f$events__$5b$external$5d$__$28$events$2c$__cjs$29$__ = __turbopack_context__.i("[externals]/events [external] (events, cjs)");
;
;
;
;
;
/**
 * @see https://nodejs.org/api/process.html#process_exit_codes
 */ const exitCodesErrors = {
    1: 'Uncaught Fatal Exception',
    2: 'Unused',
    3: 'Internal JavaScript Parse Error',
    4: 'Internal JavaScript Evaluation Failure',
    5: 'Fatal Error',
    6: 'Non-function Internal Exception Handler',
    7: 'Internal Exception Handler Run-Time Failure',
    8: 'Unused',
    9: 'Invalid Argument',
    10: 'Internal JavaScript Run-Time Failure',
    12: 'Invalid Debug Argument',
    13: 'Unfinished Top-Level Await'
};
class Child extends __TURBOPACK__imported__module__$5b$externals$5d2f$events__$5b$external$5d$__$28$events$2c$__cjs$29$__["EventEmitter"] {
    constructor(mainFile, processFile, opts = {
        useWorkerThreads: false
    }){
        super();
        this.mainFile = mainFile;
        this.processFile = processFile;
        this.opts = opts;
        this._exitCode = null;
        this._signalCode = null;
        this._killed = false;
    }
    get pid() {
        if (this.childProcess) {
            return this.childProcess.pid;
        } else if (this.worker) {
            // Worker threads pids can become negative when they are terminated
            // so we need to use the absolute value to index the retained object
            return Math.abs(this.worker.threadId);
        } else {
            throw new Error('No child process or worker thread');
        }
    }
    get exitCode() {
        return this._exitCode;
    }
    get signalCode() {
        return this._signalCode;
    }
    get killed() {
        if (this.childProcess) {
            return this.childProcess.killed;
        }
        return this._killed;
    }
    async init() {
        const execArgv = await convertExecArgv(process.execArgv);
        let parent;
        if (this.opts.useWorkerThreads) {
            this.worker = parent = new __TURBOPACK__imported__module__$5b$externals$5d2f$worker_threads__$5b$external$5d$__$28$worker_threads$2c$__cjs$29$__["Worker"](this.mainFile, Object.assign({
                execArgv,
                stdin: true,
                stdout: true,
                stderr: true
            }, this.opts.workerThreadsOptions ? this.opts.workerThreadsOptions : {}));
        } else {
            this.childProcess = parent = (0, __TURBOPACK__imported__module__$5b$externals$5d2f$child_process__$5b$external$5d$__$28$child_process$2c$__cjs$29$__["fork"])(this.mainFile, [], Object.assign({
                execArgv,
                stdio: 'pipe'
            }, this.opts.workerForkOptions ? this.opts.workerForkOptions : {}));
        }
        parent.on('exit', (exitCode, signalCode)=>{
            this._exitCode = exitCode;
            // Coerce to null if undefined for backwards compatibility
            signalCode = typeof signalCode === 'undefined' ? null : signalCode;
            this._signalCode = signalCode;
            this._killed = true;
            this.emit('exit', exitCode, signalCode);
            // Clean all listeners, we do not expect any more events after "exit"
            parent.removeAllListeners();
            this.removeAllListeners();
        });
        parent.on('error', (...args)=>this.emit('error', ...args));
        parent.on('message', (...args)=>this.emit('message', ...args));
        parent.on('close', (...args)=>this.emit('close', ...args));
        parent.stdout.pipe(process.stdout);
        parent.stderr.pipe(process.stderr);
        await this.initChild();
    }
    async send(msg) {
        return new Promise((resolve, reject)=>{
            if (this.childProcess) {
                this.childProcess.send(msg, (err)=>{
                    if (err) {
                        reject(err);
                    } else {
                        resolve();
                    }
                });
            } else if (this.worker) {
                resolve(this.worker.postMessage(msg));
            } else {
                resolve();
            }
        });
    }
    killProcess(signal = 'SIGKILL') {
        if (this.childProcess) {
            this.childProcess.kill(signal);
        } else if (this.worker) {
            this.worker.terminate();
        }
    }
    async kill(signal = 'SIGKILL', timeoutMs) {
        if (this.hasProcessExited()) {
            return;
        }
        const onExit = onExitOnce(this.childProcess || this.worker);
        this.killProcess(signal);
        if (timeoutMs !== undefined && (timeoutMs === 0 || isFinite(timeoutMs))) {
            const timeoutHandle = setTimeout(()=>{
                if (!this.hasProcessExited()) {
                    this.killProcess('SIGKILL');
                }
            }, timeoutMs);
            await onExit;
            clearTimeout(timeoutHandle);
        }
        await onExit;
    }
    async initChild() {
        const onComplete = new Promise((resolve, reject)=>{
            const onMessageHandler = (msg)=>{
                if (msg.cmd === __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].InitCompleted) {
                    resolve();
                } else if (msg.cmd === __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].InitFailed) {
                    const err = new Error();
                    err.stack = msg.err.stack;
                    err.message = msg.err.message;
                    reject(err);
                }
                this.off('message', onMessageHandler);
                this.off('close', onCloseHandler);
            };
            const onCloseHandler = (code, signal)=>{
                if (code > 128) {
                    code -= 128;
                }
                const msg = exitCodesErrors[code] || `Unknown exit code ${code}`;
                reject(new Error(`Error initializing child: ${msg} and signal ${signal}`));
                this.off('message', onMessageHandler);
                this.off('close', onCloseHandler);
            };
            this.on('message', onMessageHandler);
            this.on('close', onCloseHandler);
        });
        await this.send({
            cmd: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$child$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ChildCommand"].Init,
            value: this.processFile
        });
        await onComplete;
    }
    hasProcessExited() {
        return !!(this.exitCode !== null || this.signalCode);
    }
}
function onExitOnce(child) {
    return new Promise((resolve)=>{
        child.once('exit', ()=>resolve());
    });
}
const getFreePort = async ()=>{
    return new Promise((resolve)=>{
        const server = (0, __TURBOPACK__imported__module__$5b$externals$5d2f$net__$5b$external$5d$__$28$net$2c$__cjs$29$__["createServer"])();
        server.listen(0, ()=>{
            const { port } = server.address();
            server.close(()=>resolve(port));
        });
    });
};
const convertExecArgv = async (execArgv)=>{
    const standard = [];
    const convertedArgs = [];
    for(let i = 0; i < execArgv.length; i++){
        const arg = execArgv[i];
        if (arg.indexOf('--inspect') === -1) {
            standard.push(arg);
        } else {
            const argName = arg.split('=')[0];
            const port = await getFreePort();
            convertedArgs.push(`${argName}=${port}`);
        }
    }
    return standard.concat(convertedArgs);
}; //# sourceMappingURL=child.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/child-pool.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "ChildPool",
    ()=>ChildPool
]);
var __TURBOPACK__imported__module__$5b$externals$5d2f$path__$5b$external$5d$__$28$path$2c$__cjs$29$__ = __turbopack_context__.i("[externals]/path [external] (path, cjs)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$child$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/child.js [app-route] (ecmascript)");
;
;
const CHILD_KILL_TIMEOUT = 30000;
const supportCJS = ()=>{
    return ("TURBOPACK compile-time value", "function") === 'function' && ("TURBOPACK compile-time value", "undefined") === 'object' && typeof module.exports === 'object';
};
class ChildPool {
    constructor({ mainFile = supportCJS() ? "TURBOPACK unreachable" : __TURBOPACK__imported__module__$5b$externals$5d2f$path__$5b$external$5d$__$28$path$2c$__cjs$29$__["join"](process.cwd(), 'dist/esm/classes/main.js'), useWorkerThreads, workerForkOptions, workerThreadsOptions }){
        this.retained = {};
        this.free = {};
        this.opts = {
            mainFile,
            useWorkerThreads,
            workerForkOptions,
            workerThreadsOptions
        };
    }
    async retain(processFile) {
        let child = this.getFree(processFile).pop();
        if (child) {
            this.retained[child.pid] = child;
            return child;
        }
        child = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$child$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Child"](this.opts.mainFile, processFile, {
            useWorkerThreads: this.opts.useWorkerThreads,
            workerForkOptions: this.opts.workerForkOptions,
            workerThreadsOptions: this.opts.workerThreadsOptions
        });
        child.on('exit', this.remove.bind(this, child));
        try {
            await child.init();
            // Check status here as well, in case the child exited before we could
            // retain it.
            if (child.exitCode !== null || child.signalCode !== null) {
                throw new Error('Child exited before it could be retained');
            }
            this.retained[child.pid] = child;
            return child;
        } catch (err) {
            console.error(err);
            this.release(child);
            throw err;
        }
    }
    release(child) {
        delete this.retained[child.pid];
        this.getFree(child.processFile).push(child);
    }
    remove(child) {
        delete this.retained[child.pid];
        const free = this.getFree(child.processFile);
        const childIndex = free.indexOf(child);
        if (childIndex > -1) {
            free.splice(childIndex, 1);
        }
    }
    async kill(child, signal = 'SIGKILL') {
        this.remove(child);
        return child.kill(signal, CHILD_KILL_TIMEOUT);
    }
    async clean() {
        const children = Object.values(this.retained).concat(this.getAllFree());
        this.retained = {};
        this.free = {};
        await Promise.all(children.map((c)=>this.kill(c, 'SIGTERM')));
    }
    getFree(id) {
        return this.free[id] = this.free[id] || [];
    }
    getAllFree() {
        return Object.values(this.free).reduce((first, second)=>first.concat(second), []);
    }
} //# sourceMappingURL=child-pool.js.map
}),
"[project]/node_modules/bullmq/dist/esm/utils/index.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "DELAY_TIME_1",
    ()=>DELAY_TIME_1,
    "DELAY_TIME_5",
    ()=>DELAY_TIME_5,
    "QUEUE_EVENT_SUFFIX",
    ()=>QUEUE_EVENT_SUFFIX,
    "array2obj",
    ()=>array2obj,
    "asyncSend",
    ()=>asyncSend,
    "childSend",
    ()=>childSend,
    "clientCommandMessageReg",
    ()=>clientCommandMessageReg,
    "decreaseMaxListeners",
    ()=>decreaseMaxListeners,
    "delay",
    ()=>delay,
    "errorObject",
    ()=>errorObject,
    "errorToJSON",
    ()=>errorToJSON,
    "getParentKey",
    ()=>getParentKey,
    "increaseMaxListeners",
    ()=>increaseMaxListeners,
    "invertObject",
    ()=>invertObject,
    "isEmpty",
    ()=>isEmpty,
    "isNotConnectionError",
    ()=>isNotConnectionError,
    "isRedisCluster",
    ()=>isRedisCluster,
    "isRedisInstance",
    ()=>isRedisInstance,
    "isRedisVersionLowerThan",
    ()=>isRedisVersionLowerThan,
    "lengthInUtf8Bytes",
    ()=>lengthInUtf8Bytes,
    "objectToFlatArray",
    ()=>objectToFlatArray,
    "optsDecodeMap",
    ()=>optsDecodeMap,
    "optsEncodeMap",
    ()=>optsEncodeMap,
    "parseObjectValues",
    ()=>parseObjectValues,
    "removeAllQueueData",
    ()=>removeAllQueueData,
    "removeUndefinedFields",
    ()=>removeUndefinedFields,
    "toString",
    ()=>toString,
    "trace",
    ()=>trace,
    "tryCatch",
    ()=>tryCatch
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$ioredis$2f$built$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/ioredis/built/index.js [app-route] (ecmascript)");
// eslint-disable-next-line @typescript-eslint/ban-ts-comment
// @ts-ignore
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$ioredis$2f$built$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/ioredis/built/utils/index.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$node_modules$2f$semver$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/node_modules/semver/index.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/telemetry-attributes.js [app-route] (ecmascript)");
;
;
;
;
const errorObject = {
    value: null
};
function tryCatch(fn, ctx, args) {
    try {
        return fn.apply(ctx, args);
    } catch (e) {
        errorObject.value = e;
        return errorObject;
    }
}
function lengthInUtf8Bytes(str) {
    return Buffer.byteLength(str, 'utf8');
}
function isEmpty(obj) {
    for(const key in obj){
        if (Object.prototype.hasOwnProperty.call(obj, key)) {
            return false;
        }
    }
    return true;
}
function array2obj(arr) {
    const obj = {};
    for(let i = 0; i < arr.length; i += 2){
        obj[arr[i]] = arr[i + 1];
    }
    return obj;
}
function objectToFlatArray(obj) {
    const arr = [];
    for(const key in obj){
        if (Object.prototype.hasOwnProperty.call(obj, key) && obj[key] !== undefined) {
            arr[arr.length] = key;
            arr[arr.length] = obj[key];
        }
    }
    return arr;
}
function delay(ms, abortController) {
    return new Promise((resolve)=>{
        // eslint-disable-next-line prefer-const
        let timeout;
        const callback = ()=>{
            abortController === null || abortController === void 0 ? void 0 : abortController.signal.removeEventListener('abort', callback);
            clearTimeout(timeout);
            resolve();
        };
        timeout = setTimeout(callback, ms);
        abortController === null || abortController === void 0 ? void 0 : abortController.signal.addEventListener('abort', callback);
    });
}
function increaseMaxListeners(emitter, count) {
    const maxListeners = emitter.getMaxListeners();
    emitter.setMaxListeners(maxListeners + count);
}
function invertObject(obj) {
    return Object.entries(obj).reduce((result, [key, value])=>{
        result[value] = key;
        return result;
    }, {});
}
const optsDecodeMap = {
    de: 'deduplication',
    fpof: 'failParentOnFailure',
    cpof: 'continueParentOnFailure',
    idof: 'ignoreDependencyOnFailure',
    kl: 'keepLogs',
    rdof: 'removeDependencyOnFailure'
};
const optsEncodeMap = Object.assign(Object.assign({}, invertObject(optsDecodeMap)), {
    /*/ Legacy for backwards compatibility */ debounce: 'de'
});
function isRedisInstance(obj) {
    if (!obj) {
        return false;
    }
    const redisApi = [
        'connect',
        'disconnect',
        'duplicate'
    ];
    return redisApi.every((name)=>typeof obj[name] === 'function');
}
function isRedisCluster(obj) {
    return isRedisInstance(obj) && obj.isCluster;
}
function decreaseMaxListeners(emitter, count) {
    increaseMaxListeners(emitter, -count);
}
async function removeAllQueueData(client, queueName, prefix = process.env.BULLMQ_TEST_PREFIX || 'bull') {
    if (client instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$ioredis$2f$built$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Cluster"]) {
        // todo compat with cluster ?
        // @see https://github.com/luin/ioredis/issues/175
        return Promise.resolve(false);
    }
    const pattern = `${prefix}:${queueName}:*`;
    const removing = await new Promise((resolve, reject)=>{
        const stream = client.scanStream({
            match: pattern
        });
        stream.on('data', (keys)=>{
            if (keys.length) {
                const pipeline = client.pipeline();
                keys.forEach((key)=>{
                    pipeline.del(key);
                });
                pipeline.exec().catch((error)=>{
                    reject(error);
                });
            }
        });
        stream.on('end', ()=>resolve());
        stream.on('error', (error)=>reject(error));
    });
    await removing;
    await client.quit();
}
function getParentKey(opts) {
    if (opts) {
        return `${opts.queue}:${opts.id}`;
    }
}
const clientCommandMessageReg = /ERR unknown command ['`]\s*client\s*['`]/;
const DELAY_TIME_5 = 5000;
const DELAY_TIME_1 = 100;
function isNotConnectionError(error) {
    const { code, message: errorMessage } = error;
    return errorMessage !== __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$ioredis$2f$built$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["CONNECTION_CLOSED_ERROR_MSG"] && !errorMessage.includes('ECONNREFUSED') && code !== 'ECONNREFUSED';
}
const asyncSend = (proc, msg)=>{
    return new Promise((resolve, reject)=>{
        if (typeof proc.send === 'function') {
            proc.send(msg, (err)=>{
                if (err) {
                    reject(err);
                } else {
                    resolve();
                }
            });
        } else if (typeof proc.postMessage === 'function') {
            resolve(proc.postMessage(msg));
        } else {
            resolve();
        }
    });
};
const childSend = (proc, msg)=>asyncSend(proc, msg);
const isRedisVersionLowerThan = (currentVersion, minimumVersion)=>{
    const version = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$node_modules$2f$semver$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["valid"](__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$node_modules$2f$semver$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["coerce"](currentVersion));
    return __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$node_modules$2f$semver$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["lt"](version, minimumVersion);
};
const parseObjectValues = (obj)=>{
    const accumulator = {};
    for (const value of Object.entries(obj)){
        accumulator[value[0]] = JSON.parse(value[1]);
    }
    return accumulator;
};
const getCircularReplacer = (rootReference)=>{
    const references = new WeakSet();
    references.add(rootReference);
    return (_, value)=>{
        if (typeof value === 'object' && value !== null) {
            if (references.has(value)) {
                return '[Circular]';
            }
            references.add(value);
        }
        return value;
    };
};
const errorToJSON = (value)=>{
    const error = {};
    Object.getOwnPropertyNames(value).forEach(function(propName) {
        error[propName] = value[propName];
    });
    return JSON.parse(JSON.stringify(error, getCircularReplacer(value)));
};
const INFINITY = 1 / 0;
const toString = (value)=>{
    if (value == null) {
        return '';
    }
    // Exit early for strings to avoid a performance hit in some environments.
    if (typeof value === 'string') {
        return value;
    }
    if (Array.isArray(value)) {
        // Recursively convert values (susceptible to call stack limits).
        return `${value.map((other)=>other == null ? other : toString(other))}`;
    }
    if (typeof value == 'symbol' || Object.prototype.toString.call(value) == '[object Symbol]') {
        return value.toString();
    }
    const result = `${value}`;
    return result === '0' && 1 / value === -INFINITY ? '-0' : result;
};
const QUEUE_EVENT_SUFFIX = ':qe';
function removeUndefinedFields(obj) {
    const newObj = {};
    for(const key in obj){
        if (obj[key] !== undefined) {
            newObj[key] = obj[key];
        }
    }
    return newObj;
}
async function trace(telemetry, spanKind, queueName, operation, destination, callback, srcPropagationMetadata) {
    if (!telemetry) {
        return callback();
    } else {
        const { tracer, contextManager } = telemetry;
        const currentContext = contextManager.active();
        let parentContext;
        if (srcPropagationMetadata) {
            parentContext = contextManager.fromMetadata(currentContext, srcPropagationMetadata);
        }
        const spanName = destination ? `${operation} ${destination}` : operation;
        const span = tracer.startSpan(spanName, {
            kind: spanKind
        }, parentContext);
        try {
            span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].QueueName]: queueName,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].QueueOperation]: operation
            });
            let messageContext;
            let dstPropagationMetadata;
            if (spanKind === __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].CONSUMER && parentContext) {
                messageContext = span.setSpanOnContext(parentContext);
            } else {
                messageContext = span.setSpanOnContext(currentContext);
            }
            if (callback.length == 2) {
                dstPropagationMetadata = contextManager.getMetadata(messageContext);
            }
            return await contextManager.with(messageContext, ()=>callback(span, dstPropagationMetadata));
        } catch (err) {
            span.recordException(err);
            throw err;
        } finally{
            span.end();
        }
    }
} //# sourceMappingURL=index.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/child-processor.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "ChildProcessor",
    ()=>ChildProcessor
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/parent-command.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/utils/index.js [app-route] (ecmascript)");
;
;
var ChildStatus;
(function(ChildStatus) {
    ChildStatus[ChildStatus["Idle"] = 0] = "Idle";
    ChildStatus[ChildStatus["Started"] = 1] = "Started";
    ChildStatus[ChildStatus["Terminating"] = 2] = "Terminating";
    ChildStatus[ChildStatus["Errored"] = 3] = "Errored";
})(ChildStatus || (ChildStatus = {}));
const RESPONSE_TIMEOUT = ("TURBOPACK compile-time falsy", 0) ? "TURBOPACK unreachable" : 5000;
class ChildProcessor {
    constructor(send, receiver){
        this.send = send;
        this.receiver = receiver;
    }
    async init(processorFile) {
        let processor;
        try {
            const { default: processorFn } = await Promise.resolve().then(()=>{
                const e = new Error("Cannot find module as expression is too dynamic");
                e.code = 'MODULE_NOT_FOUND';
                throw e;
            });
            processor = processorFn;
            if (processor.default) {
                // support es2015 module.
                processor = processor.default;
            }
            if (typeof processor !== 'function') {
                throw new Error('No function is exported in processor file');
            }
        } catch (err) {
            this.status = ChildStatus.Errored;
            return this.send({
                cmd: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].InitFailed,
                err: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["errorToJSON"])(err)
            });
        }
        const origProcessor = processor;
        processor = function(job, token) {
            try {
                return Promise.resolve(origProcessor(job, token));
            } catch (err) {
                return Promise.reject(err);
            }
        };
        this.processor = processor;
        this.status = ChildStatus.Idle;
        await this.send({
            cmd: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].InitCompleted
        });
    }
    async start(jobJson, token) {
        if (this.status !== ChildStatus.Idle) {
            return this.send({
                cmd: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].Error,
                err: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["errorToJSON"])(new Error('cannot start a not idling child process'))
            });
        }
        this.status = ChildStatus.Started;
        this.currentJobPromise = (async ()=>{
            try {
                const job = this.wrapJob(jobJson, this.send);
                const result = await this.processor(job, token);
                await this.send({
                    cmd: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].Completed,
                    value: typeof result === 'undefined' ? null : result
                });
            } catch (err) {
                await this.send({
                    cmd: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].Failed,
                    value: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["errorToJSON"])(!err.message ? new Error(err) : err)
                });
            } finally{
                this.status = ChildStatus.Idle;
                this.currentJobPromise = undefined;
            }
        })();
    }
    async stop() {}
    async waitForCurrentJobAndExit() {
        this.status = ChildStatus.Terminating;
        try {
            await this.currentJobPromise;
        } finally{
            process.exit(process.exitCode || 0);
        }
    }
    /**
     * Enhance the given job argument with some functions
     * that can be called from the sandboxed job processor.
     *
     * Note, the `job` argument is a JSON deserialized message
     * from the main node process to this forked child process,
     * the functions on the original job object are not in tact.
     * The wrapped job adds back some of those original functions.
     */ wrapJob(job, send) {
        const wrappedJob = Object.assign(Object.assign({}, job), {
            queueQualifiedName: job.queueQualifiedName,
            data: JSON.parse(job.data || '{}'),
            opts: job.opts,
            returnValue: JSON.parse(job.returnvalue || '{}'),
            /*
             * Proxy `updateProgress` function, should works as `progress` function.
             */ async updateProgress (progress) {
                // Locally store reference to new progress value
                // so that we can return it from this process synchronously.
                this.progress = progress;
                // Send message to update job progress.
                await send({
                    cmd: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].Progress,
                    value: progress
                });
            },
            /*
             * Proxy job `log` function.
             */ log: async (row)=>{
                await send({
                    cmd: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].Log,
                    value: row
                });
            },
            /*
             * Proxy `moveToDelayed` function.
             */ moveToDelayed: async (timestamp, token)=>{
                await send({
                    cmd: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].MoveToDelayed,
                    value: {
                        timestamp,
                        token
                    }
                });
            },
            /*
             * Proxy `moveToWait` function.
             */ moveToWait: async (token)=>{
                await send({
                    cmd: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].MoveToWait,
                    value: {
                        token
                    }
                });
            },
            /*
             * Proxy `moveToWaitingChildren` function.
             */ moveToWaitingChildren: async (token, opts)=>{
                const requestId = Math.random().toString(36).substring(2, 15);
                await send({
                    requestId,
                    cmd: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].MoveToWaitingChildren,
                    value: {
                        token,
                        opts
                    }
                });
                return waitResponse(requestId, this.receiver, RESPONSE_TIMEOUT, 'moveToWaitingChildren');
            },
            /*
             * Proxy `updateData` function.
             */ updateData: async (data)=>{
                await send({
                    cmd: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].Update,
                    value: data
                });
                wrappedJob.data = data;
            },
            /**
             * Proxy `getChildrenValues` function.
             */ getChildrenValues: async ()=>{
                const requestId = Math.random().toString(36).substring(2, 15);
                await send({
                    requestId,
                    cmd: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].GetChildrenValues
                });
                return waitResponse(requestId, this.receiver, RESPONSE_TIMEOUT, 'getChildrenValues');
            },
            /**
             * Proxy `getIgnoredChildrenFailures` function.
             *
             * This method sends a request to retrieve the failures of ignored children
             * and waits for a response from the parent process.
             *
             * @returns - A promise that resolves with the ignored children failures.
             * The exact structure of the returned data depends on the parent process implementation.
             */ getIgnoredChildrenFailures: async ()=>{
                const requestId = Math.random().toString(36).substring(2, 15);
                await send({
                    requestId,
                    cmd: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].GetIgnoredChildrenFailures
                });
                return waitResponse(requestId, this.receiver, RESPONSE_TIMEOUT, 'getIgnoredChildrenFailures');
            }
        });
        return wrappedJob;
    }
}
const waitResponse = async (requestId, receiver, timeout, cmd)=>{
    return new Promise((resolve, reject)=>{
        const listener = (msg)=>{
            if (msg.requestId === requestId) {
                resolve(msg.value);
                receiver.off('message', listener);
            }
        };
        receiver.on('message', listener);
        setTimeout(()=>{
            receiver.off('message', listener);
            reject(new Error(`TimeoutError: ${cmd} timed out in (${timeout}ms)`));
        }, timeout);
    });
}; //# sourceMappingURL=child-processor.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/errors/delayed-error.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "DELAYED_ERROR",
    ()=>DELAYED_ERROR,
    "DelayedError",
    ()=>DelayedError
]);
const DELAYED_ERROR = 'bullmq:movedToDelayed';
class DelayedError extends Error {
    constructor(message = DELAYED_ERROR){
        super(message);
        this.name = this.constructor.name;
        Object.setPrototypeOf(this, new.target.prototype);
    }
} //# sourceMappingURL=delayed-error.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/errors/rate-limit-error.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "RATE_LIMIT_ERROR",
    ()=>RATE_LIMIT_ERROR,
    "RateLimitError",
    ()=>RateLimitError
]);
const RATE_LIMIT_ERROR = 'bullmq:rateLimitExceeded';
class RateLimitError extends Error {
    constructor(message = RATE_LIMIT_ERROR){
        super(message);
        this.name = this.constructor.name;
        Object.setPrototypeOf(this, new.target.prototype);
    }
} //# sourceMappingURL=rate-limit-error.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/errors/unrecoverable-error.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "UNRECOVERABLE_ERROR",
    ()=>UNRECOVERABLE_ERROR,
    "UnrecoverableError",
    ()=>UnrecoverableError
]);
const UNRECOVERABLE_ERROR = 'bullmq:unrecoverable';
class UnrecoverableError extends Error {
    constructor(message = UNRECOVERABLE_ERROR){
        super(message);
        this.name = this.constructor.name;
        Object.setPrototypeOf(this, new.target.prototype);
    }
} //# sourceMappingURL=unrecoverable-error.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/errors/waiting-children-error.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "WAITING_CHILDREN_ERROR",
    ()=>WAITING_CHILDREN_ERROR,
    "WaitingChildrenError",
    ()=>WaitingChildrenError
]);
const WAITING_CHILDREN_ERROR = 'bullmq:movedToWaitingChildren';
class WaitingChildrenError extends Error {
    constructor(message = WAITING_CHILDREN_ERROR){
        super(message);
        this.name = this.constructor.name;
        Object.setPrototypeOf(this, new.target.prototype);
    }
} //# sourceMappingURL=waiting-children-error.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/errors/waiting-error.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "WAITING_ERROR",
    ()=>WAITING_ERROR,
    "WaitingError",
    ()=>WaitingError
]);
const WAITING_ERROR = 'bullmq:movedToWait';
class WaitingError extends Error {
    constructor(message = WAITING_ERROR){
        super(message);
        this.name = this.constructor.name;
        Object.setPrototypeOf(this, new.target.prototype);
    }
} //# sourceMappingURL=waiting-error.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/errors/index.js [app-route] (ecmascript) <locals>", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$delayed$2d$error$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/errors/delayed-error.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$rate$2d$limit$2d$error$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/errors/rate-limit-error.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$unrecoverable$2d$error$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/errors/unrecoverable-error.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$waiting$2d$children$2d$error$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/errors/waiting-children-error.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$waiting$2d$error$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/errors/waiting-error.js [app-route] (ecmascript)"); //# sourceMappingURL=index.js.map
;
;
;
;
;
}),
"[project]/node_modules/bullmq/dist/esm/version.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "version",
    ()=>version
]);
const version = '5.65.1'; //# sourceMappingURL=version.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/scripts.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/**
 * Includes all the scripts needed by the queue and jobs.
 */ /*eslint-env node */ __turbopack_context__.s([
    "Scripts",
    ()=>Scripts,
    "raw2NextJobData",
    ()=>raw2NextJobData
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$msgpackr$2f$node$2d$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/msgpackr/node-index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$msgpackr$2f$pack$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/msgpackr/pack.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$error$2d$code$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/error-code.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/utils/index.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$version$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/version.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/errors/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$unrecoverable$2d$error$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/errors/unrecoverable-error.js [app-route] (ecmascript)");
'use strict';
;
const packer = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$msgpackr$2f$pack$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__["Packr"]({
    useRecords: false,
    encodeUndefinedAsNil: true
});
const pack = packer.pack;
;
;
;
;
class Scripts {
    constructor(queue){
        this.queue = queue;
        this.version = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$version$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["version"];
        const queueKeys = this.queue.keys;
        this.moveToFinishedKeys = [
            queueKeys.wait,
            queueKeys.active,
            queueKeys.prioritized,
            queueKeys.events,
            queueKeys.stalled,
            queueKeys.limiter,
            queueKeys.delayed,
            queueKeys.paused,
            queueKeys.meta,
            queueKeys.pc,
            undefined,
            undefined,
            undefined,
            undefined
        ];
    }
    execCommand(client, commandName, args) {
        const commandNameWithVersion = `${commandName}:${this.version}`;
        return client[commandNameWithVersion](args);
    }
    async isJobInList(listKey, jobId) {
        const client = await this.queue.client;
        let result;
        if ((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isRedisVersionLowerThan"])(this.queue.redisVersion, '6.0.6')) {
            result = await this.execCommand(client, 'isJobInList', [
                listKey,
                jobId
            ]);
        } else {
            result = await client.lpos(listKey, jobId);
        }
        return Number.isInteger(result);
    }
    addDelayedJobArgs(job, encodedOpts, args) {
        const queueKeys = this.queue.keys;
        const keys = [
            queueKeys.marker,
            queueKeys.meta,
            queueKeys.id,
            queueKeys.delayed,
            queueKeys.completed,
            queueKeys.events
        ];
        keys.push(pack(args), job.data, encodedOpts);
        return keys;
    }
    addDelayedJob(client, job, encodedOpts, args) {
        const argsList = this.addDelayedJobArgs(job, encodedOpts, args);
        return this.execCommand(client, 'addDelayedJob', argsList);
    }
    addPrioritizedJobArgs(job, encodedOpts, args) {
        const queueKeys = this.queue.keys;
        const keys = [
            queueKeys.marker,
            queueKeys.meta,
            queueKeys.id,
            queueKeys.prioritized,
            queueKeys.delayed,
            queueKeys.completed,
            queueKeys.active,
            queueKeys.events,
            queueKeys.pc
        ];
        keys.push(pack(args), job.data, encodedOpts);
        return keys;
    }
    addPrioritizedJob(client, job, encodedOpts, args) {
        const argsList = this.addPrioritizedJobArgs(job, encodedOpts, args);
        return this.execCommand(client, 'addPrioritizedJob', argsList);
    }
    addParentJobArgs(job, encodedOpts, args) {
        const queueKeys = this.queue.keys;
        const keys = [
            queueKeys.meta,
            queueKeys.id,
            queueKeys.delayed,
            queueKeys['waiting-children'],
            queueKeys.completed,
            queueKeys.events
        ];
        keys.push(pack(args), job.data, encodedOpts);
        return keys;
    }
    addParentJob(client, job, encodedOpts, args) {
        const argsList = this.addParentJobArgs(job, encodedOpts, args);
        return this.execCommand(client, 'addParentJob', argsList);
    }
    addStandardJobArgs(job, encodedOpts, args) {
        const queueKeys = this.queue.keys;
        const keys = [
            queueKeys.wait,
            queueKeys.paused,
            queueKeys.meta,
            queueKeys.id,
            queueKeys.completed,
            queueKeys.delayed,
            queueKeys.active,
            queueKeys.events,
            queueKeys.marker
        ];
        keys.push(pack(args), job.data, encodedOpts);
        return keys;
    }
    addStandardJob(client, job, encodedOpts, args) {
        const argsList = this.addStandardJobArgs(job, encodedOpts, args);
        return this.execCommand(client, 'addStandardJob', argsList);
    }
    async addJob(client, job, opts, jobId, parentKeyOpts = {}) {
        const queueKeys = this.queue.keys;
        const parent = job.parent;
        const args = [
            queueKeys[''],
            typeof jobId !== 'undefined' ? jobId : '',
            job.name,
            job.timestamp,
            job.parentKey || null,
            parentKeyOpts.parentDependenciesKey || null,
            parent,
            job.repeatJobKey,
            job.deduplicationId ? `${queueKeys.de}:${job.deduplicationId}` : null
        ];
        let encodedOpts;
        if (opts.repeat) {
            const repeat = Object.assign({}, opts.repeat);
            if (repeat.startDate) {
                repeat.startDate = +new Date(repeat.startDate);
            }
            if (repeat.endDate) {
                repeat.endDate = +new Date(repeat.endDate);
            }
            encodedOpts = pack(Object.assign(Object.assign({}, opts), {
                repeat
            }));
        } else {
            encodedOpts = pack(opts);
        }
        let result;
        if (parentKeyOpts.addToWaitingChildren) {
            result = await this.addParentJob(client, job, encodedOpts, args);
        } else if (typeof opts.delay == 'number' && opts.delay > 0) {
            result = await this.addDelayedJob(client, job, encodedOpts, args);
        } else if (opts.priority) {
            result = await this.addPrioritizedJob(client, job, encodedOpts, args);
        } else {
            result = await this.addStandardJob(client, job, encodedOpts, args);
        }
        if (result < 0) {
            throw this.finishedErrors({
                code: result,
                parentKey: parentKeyOpts.parentKey,
                command: 'addJob'
            });
        }
        return result;
    }
    pauseArgs(pause) {
        let src = 'wait', dst = 'paused';
        if (!pause) {
            src = 'paused';
            dst = 'wait';
        }
        const keys = [
            src,
            dst,
            'meta',
            'prioritized'
        ].map((name)=>this.queue.toKey(name));
        keys.push(this.queue.keys.events, this.queue.keys.delayed, this.queue.keys.marker);
        const args = [
            pause ? 'paused' : 'resumed'
        ];
        return keys.concat(args);
    }
    async pause(pause) {
        const client = await this.queue.client;
        const args = this.pauseArgs(pause);
        return this.execCommand(client, 'pause', args);
    }
    addRepeatableJobArgs(customKey, nextMillis, opts, legacyCustomKey) {
        const queueKeys = this.queue.keys;
        const keys = [
            queueKeys.repeat,
            queueKeys.delayed
        ];
        const args = [
            nextMillis,
            pack(opts),
            legacyCustomKey,
            customKey,
            queueKeys['']
        ];
        return keys.concat(args);
    }
    async addRepeatableJob(customKey, nextMillis, opts, legacyCustomKey) {
        const client = await this.queue.client;
        const args = this.addRepeatableJobArgs(customKey, nextMillis, opts, legacyCustomKey);
        return this.execCommand(client, 'addRepeatableJob', args);
    }
    async removeDeduplicationKey(deduplicationId, jobId) {
        const client = await this.queue.client;
        const queueKeys = this.queue.keys;
        const keys = [
            `${queueKeys.de}:${deduplicationId}`
        ];
        const args = [
            jobId
        ];
        return this.execCommand(client, 'removeDeduplicationKey', keys.concat(args));
    }
    async addJobScheduler(jobSchedulerId, nextMillis, templateData, templateOpts, opts, delayedJobOpts, // The job id of the job that produced this next iteration
    producerId) {
        const client = await this.queue.client;
        const queueKeys = this.queue.keys;
        const keys = [
            queueKeys.repeat,
            queueKeys.delayed,
            queueKeys.wait,
            queueKeys.paused,
            queueKeys.meta,
            queueKeys.prioritized,
            queueKeys.marker,
            queueKeys.id,
            queueKeys.events,
            queueKeys.pc,
            queueKeys.active
        ];
        const args = [
            nextMillis,
            pack(opts),
            jobSchedulerId,
            templateData,
            pack(templateOpts),
            pack(delayedJobOpts),
            Date.now(),
            queueKeys[''],
            producerId ? this.queue.toKey(producerId) : ''
        ];
        const result = await this.execCommand(client, 'addJobScheduler', keys.concat(args));
        if (typeof result === 'number' && result < 0) {
            throw this.finishedErrors({
                code: result,
                command: 'addJobScheduler'
            });
        }
        return result;
    }
    async updateRepeatableJobMillis(client, customKey, nextMillis, legacyCustomKey) {
        const args = [
            this.queue.keys.repeat,
            nextMillis,
            customKey,
            legacyCustomKey
        ];
        return this.execCommand(client, 'updateRepeatableJobMillis', args);
    }
    async updateJobSchedulerNextMillis(jobSchedulerId, nextMillis, templateData, delayedJobOpts, // The job id of the job that produced this next iteration - TODO: remove in next breaking change
    producerId) {
        const client = await this.queue.client;
        const queueKeys = this.queue.keys;
        const keys = [
            queueKeys.repeat,
            queueKeys.delayed,
            queueKeys.wait,
            queueKeys.paused,
            queueKeys.meta,
            queueKeys.prioritized,
            queueKeys.marker,
            queueKeys.id,
            queueKeys.events,
            queueKeys.pc,
            producerId ? this.queue.toKey(producerId) : '',
            queueKeys.active
        ];
        const args = [
            nextMillis,
            jobSchedulerId,
            templateData,
            pack(delayedJobOpts),
            Date.now(),
            queueKeys[''],
            producerId
        ];
        return this.execCommand(client, 'updateJobScheduler', keys.concat(args));
    }
    removeRepeatableArgs(legacyRepeatJobId, repeatConcatOptions, repeatJobKey) {
        const queueKeys = this.queue.keys;
        const keys = [
            queueKeys.repeat,
            queueKeys.delayed,
            queueKeys.events
        ];
        const args = [
            legacyRepeatJobId,
            this.getRepeatConcatOptions(repeatConcatOptions, repeatJobKey),
            repeatJobKey,
            queueKeys['']
        ];
        return keys.concat(args);
    }
    // TODO: remove this check in next breaking change
    getRepeatConcatOptions(repeatConcatOptions, repeatJobKey) {
        if (repeatJobKey && repeatJobKey.split(':').length > 2) {
            return repeatJobKey;
        }
        return repeatConcatOptions;
    }
    async removeRepeatable(legacyRepeatJobId, repeatConcatOptions, repeatJobKey) {
        const client = await this.queue.client;
        const args = this.removeRepeatableArgs(legacyRepeatJobId, repeatConcatOptions, repeatJobKey);
        return this.execCommand(client, 'removeRepeatable', args);
    }
    async removeJobScheduler(jobSchedulerId) {
        const client = await this.queue.client;
        const queueKeys = this.queue.keys;
        const keys = [
            queueKeys.repeat,
            queueKeys.delayed,
            queueKeys.events
        ];
        const args = [
            jobSchedulerId,
            queueKeys['']
        ];
        return this.execCommand(client, 'removeJobScheduler', keys.concat(args));
    }
    removeArgs(jobId, removeChildren) {
        const keys = [
            jobId,
            'repeat'
        ].map((name)=>this.queue.toKey(name));
        const args = [
            jobId,
            removeChildren ? 1 : 0,
            this.queue.toKey('')
        ];
        return keys.concat(args);
    }
    async remove(jobId, removeChildren) {
        const client = await this.queue.client;
        const args = this.removeArgs(jobId, removeChildren);
        const result = await this.execCommand(client, 'removeJob', args);
        if (result < 0) {
            throw this.finishedErrors({
                code: result,
                jobId,
                command: 'removeJob'
            });
        }
        return result;
    }
    async removeUnprocessedChildren(jobId) {
        const client = await this.queue.client;
        const args = [
            this.queue.toKey(jobId),
            this.queue.keys.meta,
            this.queue.toKey(''),
            jobId
        ];
        await this.execCommand(client, 'removeUnprocessedChildren', args);
    }
    async extendLock(jobId, token, duration, client) {
        client = client || await this.queue.client;
        const args = [
            this.queue.toKey(jobId) + ':lock',
            this.queue.keys.stalled,
            token,
            duration,
            jobId
        ];
        return this.execCommand(client, 'extendLock', args);
    }
    async extendLocks(jobIds, tokens, duration) {
        const client = await this.queue.client;
        const args = [
            this.queue.keys.stalled,
            this.queue.toKey(''),
            pack(tokens),
            pack(jobIds),
            duration
        ];
        return this.execCommand(client, 'extendLocks', args);
    }
    async updateData(job, data) {
        const client = await this.queue.client;
        const keys = [
            this.queue.toKey(job.id)
        ];
        const dataJson = JSON.stringify(data);
        const result = await this.execCommand(client, 'updateData', keys.concat([
            dataJson
        ]));
        if (result < 0) {
            throw this.finishedErrors({
                code: result,
                jobId: job.id,
                command: 'updateData'
            });
        }
    }
    async updateProgress(jobId, progress) {
        const client = await this.queue.client;
        const keys = [
            this.queue.toKey(jobId),
            this.queue.keys.events,
            this.queue.keys.meta
        ];
        const progressJson = JSON.stringify(progress);
        const result = await this.execCommand(client, 'updateProgress', keys.concat([
            jobId,
            progressJson
        ]));
        if (result < 0) {
            throw this.finishedErrors({
                code: result,
                jobId,
                command: 'updateProgress'
            });
        }
    }
    async addLog(jobId, logRow, keepLogs) {
        const client = await this.queue.client;
        const keys = [
            this.queue.toKey(jobId),
            this.queue.toKey(jobId) + ':logs'
        ];
        const result = await this.execCommand(client, 'addLog', keys.concat([
            jobId,
            logRow,
            keepLogs ? keepLogs : ''
        ]));
        if (result < 0) {
            throw this.finishedErrors({
                code: result,
                jobId,
                command: 'addLog'
            });
        }
        return result;
    }
    moveToFinishedArgs(job, val, propVal, shouldRemove, target, token, timestamp, fetchNext = true, fieldsToUpdate) {
        var _a, _b, _c, _d, _e, _f, _g;
        const queueKeys = this.queue.keys;
        const opts = this.queue.opts;
        const workerKeepJobs = target === 'completed' ? opts.removeOnComplete : opts.removeOnFail;
        const metricsKey = this.queue.toKey(`metrics:${target}`);
        const keys = this.moveToFinishedKeys;
        keys[10] = queueKeys[target];
        keys[11] = this.queue.toKey((_a = job.id) !== null && _a !== void 0 ? _a : '');
        keys[12] = metricsKey;
        keys[13] = this.queue.keys.marker;
        const keepJobs = this.getKeepJobs(shouldRemove, workerKeepJobs);
        const args = [
            job.id,
            timestamp,
            propVal,
            typeof val === 'undefined' ? 'null' : val,
            target,
            !fetchNext || this.queue.closing ? 0 : 1,
            queueKeys[''],
            pack({
                token,
                name: opts.name,
                keepJobs,
                limiter: opts.limiter,
                lockDuration: opts.lockDuration,
                attempts: job.opts.attempts,
                maxMetricsSize: ((_b = opts.metrics) === null || _b === void 0 ? void 0 : _b.maxDataPoints) ? (_c = opts.metrics) === null || _c === void 0 ? void 0 : _c.maxDataPoints : '',
                fpof: !!((_d = job.opts) === null || _d === void 0 ? void 0 : _d.failParentOnFailure),
                cpof: !!((_e = job.opts) === null || _e === void 0 ? void 0 : _e.continueParentOnFailure),
                idof: !!((_f = job.opts) === null || _f === void 0 ? void 0 : _f.ignoreDependencyOnFailure),
                rdof: !!((_g = job.opts) === null || _g === void 0 ? void 0 : _g.removeDependencyOnFailure)
            }),
            fieldsToUpdate ? pack((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["objectToFlatArray"])(fieldsToUpdate)) : void 0
        ];
        return keys.concat(args);
    }
    getKeepJobs(shouldRemove, workerKeepJobs) {
        if (typeof shouldRemove === 'undefined') {
            return workerKeepJobs || {
                count: shouldRemove ? 0 : -1
            };
        }
        return typeof shouldRemove === 'object' ? shouldRemove : typeof shouldRemove === 'number' ? {
            count: shouldRemove
        } : {
            count: shouldRemove ? 0 : -1
        };
    }
    async moveToFinished(jobId, args) {
        const client = await this.queue.client;
        const result = await this.execCommand(client, 'moveToFinished', args);
        if (result < 0) {
            throw this.finishedErrors({
                code: result,
                jobId,
                command: 'moveToFinished',
                state: 'active'
            });
        } else {
            if (typeof result !== 'undefined') {
                return raw2NextJobData(result);
            }
        }
    }
    drainArgs(delayed) {
        const queueKeys = this.queue.keys;
        const keys = [
            queueKeys.wait,
            queueKeys.paused,
            queueKeys.delayed,
            queueKeys.prioritized,
            queueKeys.repeat
        ];
        const args = [
            queueKeys[''],
            delayed ? '1' : '0'
        ];
        return keys.concat(args);
    }
    async drain(delayed) {
        const client = await this.queue.client;
        const args = this.drainArgs(delayed);
        return this.execCommand(client, 'drain', args);
    }
    removeChildDependencyArgs(jobId, parentKey) {
        const queueKeys = this.queue.keys;
        const keys = [
            queueKeys['']
        ];
        const args = [
            this.queue.toKey(jobId),
            parentKey
        ];
        return keys.concat(args);
    }
    async removeChildDependency(jobId, parentKey) {
        const client = await this.queue.client;
        const args = this.removeChildDependencyArgs(jobId, parentKey);
        const result = await this.execCommand(client, 'removeChildDependency', args);
        switch(result){
            case 0:
                return true;
            case 1:
                return false;
            default:
                throw this.finishedErrors({
                    code: result,
                    jobId,
                    parentKey,
                    command: 'removeChildDependency'
                });
        }
    }
    getRangesArgs(types, start, end, asc) {
        const queueKeys = this.queue.keys;
        const transformedTypes = types.map((type)=>{
            return type === 'waiting' ? 'wait' : type;
        });
        const keys = [
            queueKeys['']
        ];
        const args = [
            start,
            end,
            asc ? '1' : '0',
            ...transformedTypes
        ];
        return keys.concat(args);
    }
    async getRanges(types, start = 0, end = 1, asc = false) {
        const client = await this.queue.client;
        const args = this.getRangesArgs(types, start, end, asc);
        return await this.execCommand(client, 'getRanges', args);
    }
    getCountsArgs(types) {
        const queueKeys = this.queue.keys;
        const transformedTypes = types.map((type)=>{
            return type === 'waiting' ? 'wait' : type;
        });
        const keys = [
            queueKeys['']
        ];
        const args = [
            ...transformedTypes
        ];
        return keys.concat(args);
    }
    async getCounts(types) {
        const client = await this.queue.client;
        const args = this.getCountsArgs(types);
        return await this.execCommand(client, 'getCounts', args);
    }
    getCountsPerPriorityArgs(priorities) {
        const keys = [
            this.queue.keys.wait,
            this.queue.keys.paused,
            this.queue.keys.meta,
            this.queue.keys.prioritized
        ];
        const args = priorities;
        return keys.concat(args);
    }
    async getCountsPerPriority(priorities) {
        const client = await this.queue.client;
        const args = this.getCountsPerPriorityArgs(priorities);
        return await this.execCommand(client, 'getCountsPerPriority', args);
    }
    getDependencyCountsArgs(jobId, types) {
        const keys = [
            `${jobId}:processed`,
            `${jobId}:dependencies`,
            `${jobId}:failed`,
            `${jobId}:unsuccessful`
        ].map((name)=>{
            return this.queue.toKey(name);
        });
        const args = types;
        return keys.concat(args);
    }
    async getDependencyCounts(jobId, types) {
        const client = await this.queue.client;
        const args = this.getDependencyCountsArgs(jobId, types);
        return await this.execCommand(client, 'getDependencyCounts', args);
    }
    moveToCompletedArgs(job, returnvalue, removeOnComplete, token, fetchNext = false) {
        const timestamp = Date.now();
        return this.moveToFinishedArgs(job, returnvalue, 'returnvalue', removeOnComplete, 'completed', token, timestamp, fetchNext);
    }
    moveToFailedArgs(job, failedReason, removeOnFailed, token, fetchNext = false, fieldsToUpdate) {
        const timestamp = Date.now();
        return this.moveToFinishedArgs(job, failedReason, 'failedReason', removeOnFailed, 'failed', token, timestamp, fetchNext, fieldsToUpdate);
    }
    async isFinished(jobId, returnValue = false) {
        const client = await this.queue.client;
        const keys = [
            'completed',
            'failed',
            jobId
        ].map((key)=>{
            return this.queue.toKey(key);
        });
        return this.execCommand(client, 'isFinished', keys.concat([
            jobId,
            returnValue ? '1' : ''
        ]));
    }
    async getState(jobId) {
        const client = await this.queue.client;
        const keys = [
            'completed',
            'failed',
            'delayed',
            'active',
            'wait',
            'paused',
            'waiting-children',
            'prioritized'
        ].map((key)=>{
            return this.queue.toKey(key);
        });
        if ((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isRedisVersionLowerThan"])(this.queue.redisVersion, '6.0.6')) {
            return this.execCommand(client, 'getState', keys.concat([
                jobId
            ]));
        }
        return this.execCommand(client, 'getStateV2', keys.concat([
            jobId
        ]));
    }
    /**
     * Change delay of a delayed job.
     *
     * Reschedules a delayed job by setting a new delay from the current time.
     * For example, calling changeDelay(5000) will reschedule the job to execute
     * 5000 milliseconds (5 seconds) from now, regardless of the original delay.
     *
     * @param jobId - the ID of the job to change the delay for.
     * @param delay - milliseconds from now when the job should be processed.
     * @returns delay in milliseconds.
     * @throws JobNotExist
     * This exception is thrown if jobId is missing.
     * @throws JobNotInState
     * This exception is thrown if job is not in delayed state.
     */ async changeDelay(jobId, delay) {
        const client = await this.queue.client;
        const args = this.changeDelayArgs(jobId, delay);
        const result = await this.execCommand(client, 'changeDelay', args);
        if (result < 0) {
            throw this.finishedErrors({
                code: result,
                jobId,
                command: 'changeDelay',
                state: 'delayed'
            });
        }
    }
    changeDelayArgs(jobId, delay) {
        const timestamp = Date.now();
        const keys = [
            this.queue.keys.delayed,
            this.queue.keys.meta,
            this.queue.keys.marker,
            this.queue.keys.events
        ];
        return keys.concat([
            delay,
            JSON.stringify(timestamp),
            jobId,
            this.queue.toKey(jobId)
        ]);
    }
    async changePriority(jobId, priority = 0, lifo = false) {
        const client = await this.queue.client;
        const args = this.changePriorityArgs(jobId, priority, lifo);
        const result = await this.execCommand(client, 'changePriority', args);
        if (result < 0) {
            throw this.finishedErrors({
                code: result,
                jobId,
                command: 'changePriority'
            });
        }
    }
    changePriorityArgs(jobId, priority = 0, lifo = false) {
        const keys = [
            this.queue.keys.wait,
            this.queue.keys.paused,
            this.queue.keys.meta,
            this.queue.keys.prioritized,
            this.queue.keys.active,
            this.queue.keys.pc,
            this.queue.keys.marker
        ];
        return keys.concat([
            priority,
            this.queue.toKey(''),
            jobId,
            lifo ? 1 : 0
        ]);
    }
    moveToDelayedArgs(jobId, timestamp, token, delay, opts = {}) {
        const queueKeys = this.queue.keys;
        const keys = [
            queueKeys.marker,
            queueKeys.active,
            queueKeys.prioritized,
            queueKeys.delayed,
            this.queue.toKey(jobId),
            queueKeys.events,
            queueKeys.meta,
            queueKeys.stalled
        ];
        return keys.concat([
            this.queue.keys[''],
            timestamp,
            jobId,
            token,
            delay,
            opts.skipAttempt ? '1' : '0',
            opts.fieldsToUpdate ? pack((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["objectToFlatArray"])(opts.fieldsToUpdate)) : void 0
        ]);
    }
    moveToWaitingChildrenArgs(jobId, token, opts) {
        const timestamp = Date.now();
        const childKey = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getParentKey"])(opts.child);
        const keys = [
            'active',
            'waiting-children',
            jobId,
            `${jobId}:dependencies`,
            `${jobId}:unsuccessful`,
            'stalled',
            'events'
        ].map((name)=>{
            return this.queue.toKey(name);
        });
        return keys.concat([
            token,
            childKey !== null && childKey !== void 0 ? childKey : '',
            JSON.stringify(timestamp),
            jobId,
            this.queue.toKey('')
        ]);
    }
    isMaxedArgs() {
        const queueKeys = this.queue.keys;
        const keys = [
            queueKeys.meta,
            queueKeys.active
        ];
        return keys;
    }
    async isMaxed() {
        const client = await this.queue.client;
        const args = this.isMaxedArgs();
        return !!await this.execCommand(client, 'isMaxed', args);
    }
    async moveToDelayed(jobId, timestamp, delay, token = '0', opts = {}) {
        const client = await this.queue.client;
        const args = this.moveToDelayedArgs(jobId, timestamp, token, delay, opts);
        const result = await this.execCommand(client, 'moveToDelayed', args);
        if (result < 0) {
            throw this.finishedErrors({
                code: result,
                jobId,
                command: 'moveToDelayed',
                state: 'active'
            });
        }
    }
    /**
     * Move parent job to waiting-children state.
     *
     * @returns true if job is successfully moved, false if there are pending dependencies.
     * @throws JobNotExist
     * This exception is thrown if jobId is missing.
     * @throws JobLockNotExist
     * This exception is thrown if job lock is missing.
     * @throws JobNotInState
     * This exception is thrown if job is not in active state.
     */ async moveToWaitingChildren(jobId, token, opts = {}) {
        const client = await this.queue.client;
        const args = this.moveToWaitingChildrenArgs(jobId, token, opts);
        const result = await this.execCommand(client, 'moveToWaitingChildren', args);
        switch(result){
            case 0:
                return true;
            case 1:
                return false;
            default:
                throw this.finishedErrors({
                    code: result,
                    jobId,
                    command: 'moveToWaitingChildren',
                    state: 'active'
                });
        }
    }
    getRateLimitTtlArgs(maxJobs) {
        const keys = [
            this.queue.keys.limiter,
            this.queue.keys.meta
        ];
        return keys.concat([
            maxJobs !== null && maxJobs !== void 0 ? maxJobs : '0'
        ]);
    }
    async getRateLimitTtl(maxJobs) {
        const client = await this.queue.client;
        const args = this.getRateLimitTtlArgs(maxJobs);
        return this.execCommand(client, 'getRateLimitTtl', args);
    }
    /**
     * Remove jobs in a specific state.
     *
     * @returns Id jobs from the deleted records.
     */ async cleanJobsInSet(set, timestamp, limit = 0) {
        const client = await this.queue.client;
        return this.execCommand(client, 'cleanJobsInSet', [
            this.queue.toKey(set),
            this.queue.toKey('events'),
            this.queue.toKey('repeat'),
            this.queue.toKey(''),
            timestamp,
            limit,
            set
        ]);
    }
    getJobSchedulerArgs(id) {
        const keys = [
            this.queue.keys.repeat
        ];
        return keys.concat([
            id
        ]);
    }
    async getJobScheduler(id) {
        const client = await this.queue.client;
        const args = this.getJobSchedulerArgs(id);
        return this.execCommand(client, 'getJobScheduler', args);
    }
    retryJobArgs(jobId, lifo, token, opts = {}) {
        const keys = [
            this.queue.keys.active,
            this.queue.keys.wait,
            this.queue.keys.paused,
            this.queue.toKey(jobId),
            this.queue.keys.meta,
            this.queue.keys.events,
            this.queue.keys.delayed,
            this.queue.keys.prioritized,
            this.queue.keys.pc,
            this.queue.keys.marker,
            this.queue.keys.stalled
        ];
        const pushCmd = (lifo ? 'R' : 'L') + 'PUSH';
        return keys.concat([
            this.queue.toKey(''),
            Date.now(),
            pushCmd,
            jobId,
            token,
            opts.fieldsToUpdate ? pack((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["objectToFlatArray"])(opts.fieldsToUpdate)) : void 0
        ]);
    }
    async retryJob(jobId, lifo, token = '0', opts = {}) {
        const client = await this.queue.client;
        const args = this.retryJobArgs(jobId, lifo, token, opts);
        const result = await this.execCommand(client, 'retryJob', args);
        if (result < 0) {
            throw this.finishedErrors({
                code: result,
                jobId,
                command: 'retryJob',
                state: 'active'
            });
        }
    }
    moveJobsToWaitArgs(state, count, timestamp) {
        const keys = [
            this.queue.toKey(''),
            this.queue.keys.events,
            this.queue.toKey(state),
            this.queue.toKey('wait'),
            this.queue.toKey('paused'),
            this.queue.keys.meta,
            this.queue.keys.active,
            this.queue.keys.marker
        ];
        const args = [
            count,
            timestamp,
            state
        ];
        return keys.concat(args);
    }
    async retryJobs(state = 'failed', count = 1000, timestamp = new Date().getTime()) {
        const client = await this.queue.client;
        const args = this.moveJobsToWaitArgs(state, count, timestamp);
        return this.execCommand(client, 'moveJobsToWait', args);
    }
    async promoteJobs(count = 1000) {
        const client = await this.queue.client;
        const args = this.moveJobsToWaitArgs('delayed', count, Number.MAX_VALUE);
        return this.execCommand(client, 'moveJobsToWait', args);
    }
    /**
     * Attempts to reprocess a job
     *
     * @param job - The job to reprocess
     * @param state - The expected job state. If the job is not found
     * on the provided state, then it's not reprocessed. Supported states: 'failed', 'completed'
     *
     * @returns A promise that resolves when the job has been successfully moved to the wait queue.
     * @throws Will throw an error with a code property indicating the failure reason:
     *   - code 0: Job does not exist
     *   - code -1: Job is currently locked and can't be retried
     *   - code -2: Job was not found in the expected set
     */ async reprocessJob(job, state) {
        const client = await this.queue.client;
        const keys = [
            this.queue.toKey(job.id),
            this.queue.keys.events,
            this.queue.toKey(state),
            this.queue.keys.wait,
            this.queue.keys.meta,
            this.queue.keys.paused,
            this.queue.keys.active,
            this.queue.keys.marker
        ];
        const args = [
            job.id,
            (job.opts.lifo ? 'R' : 'L') + 'PUSH',
            state === 'failed' ? 'failedReason' : 'returnvalue',
            state
        ];
        const result = await this.execCommand(client, 'reprocessJob', keys.concat(args));
        switch(result){
            case 1:
                return;
            default:
                throw this.finishedErrors({
                    code: result,
                    jobId: job.id,
                    command: 'reprocessJob',
                    state
                });
        }
    }
    async getMetrics(type, start = 0, end = -1) {
        const client = await this.queue.client;
        const keys = [
            this.queue.toKey(`metrics:${type}`),
            this.queue.toKey(`metrics:${type}:data`)
        ];
        const args = [
            start,
            end
        ];
        const result = await this.execCommand(client, 'getMetrics', keys.concat(args));
        return result;
    }
    async moveToActive(client, token, name) {
        const opts = this.queue.opts;
        const queueKeys = this.queue.keys;
        const keys = [
            queueKeys.wait,
            queueKeys.active,
            queueKeys.prioritized,
            queueKeys.events,
            queueKeys.stalled,
            queueKeys.limiter,
            queueKeys.delayed,
            queueKeys.paused,
            queueKeys.meta,
            queueKeys.pc,
            queueKeys.marker
        ];
        const args = [
            queueKeys[''],
            Date.now(),
            pack({
                token,
                lockDuration: opts.lockDuration,
                limiter: opts.limiter,
                name
            })
        ];
        const result = await this.execCommand(client, 'moveToActive', keys.concat(args));
        return raw2NextJobData(result);
    }
    async promote(jobId) {
        const client = await this.queue.client;
        const keys = [
            this.queue.keys.delayed,
            this.queue.keys.wait,
            this.queue.keys.paused,
            this.queue.keys.meta,
            this.queue.keys.prioritized,
            this.queue.keys.active,
            this.queue.keys.pc,
            this.queue.keys.events,
            this.queue.keys.marker
        ];
        const args = [
            this.queue.toKey(''),
            jobId
        ];
        const code = await this.execCommand(client, 'promote', keys.concat(args));
        if (code < 0) {
            throw this.finishedErrors({
                code,
                jobId,
                command: 'promote',
                state: 'delayed'
            });
        }
    }
    moveStalledJobsToWaitArgs() {
        const opts = this.queue.opts;
        const keys = [
            this.queue.keys.stalled,
            this.queue.keys.wait,
            this.queue.keys.active,
            this.queue.keys['stalled-check'],
            this.queue.keys.meta,
            this.queue.keys.paused,
            this.queue.keys.marker,
            this.queue.keys.events
        ];
        const args = [
            opts.maxStalledCount,
            this.queue.toKey(''),
            Date.now(),
            opts.stalledInterval
        ];
        return keys.concat(args);
    }
    /**
     * Looks for unlocked jobs in the active queue.
     *
     * The job was being worked on, but the worker process died and it failed to renew the lock.
     * We call these jobs 'stalled'. This is the most common case. We resolve these by moving them
     * back to wait to be re-processed. To prevent jobs from cycling endlessly between active and wait,
     * (e.g. if the job handler keeps crashing),
     * we limit the number stalled job recoveries to settings.maxStalledCount.
     */ async moveStalledJobsToWait() {
        const client = await this.queue.client;
        const args = this.moveStalledJobsToWaitArgs();
        return this.execCommand(client, 'moveStalledJobsToWait', args);
    }
    /**
     * Moves a job back from Active to Wait.
     * This script is used when a job has been manually rate limited and needs
     * to be moved back to wait from active status.
     *
     * @param client - Redis client
     * @param jobId - Job id
     * @returns
     */ async moveJobFromActiveToWait(jobId, token = '0') {
        const client = await this.queue.client;
        const keys = [
            this.queue.keys.active,
            this.queue.keys.wait,
            this.queue.keys.stalled,
            this.queue.keys.paused,
            this.queue.keys.meta,
            this.queue.keys.limiter,
            this.queue.keys.prioritized,
            this.queue.keys.marker,
            this.queue.keys.events
        ];
        const args = [
            jobId,
            token,
            this.queue.toKey(jobId)
        ];
        const result = await this.execCommand(client, 'moveJobFromActiveToWait', keys.concat(args));
        if (result < 0) {
            throw this.finishedErrors({
                code: result,
                jobId,
                command: 'moveJobFromActiveToWait',
                state: 'active'
            });
        }
        return result;
    }
    async obliterate(opts) {
        const client = await this.queue.client;
        const keys = [
            this.queue.keys.meta,
            this.queue.toKey('')
        ];
        const args = [
            opts.count,
            opts.force ? 'force' : null
        ];
        const result = await this.execCommand(client, 'obliterate', keys.concat(args));
        if (result < 0) {
            switch(result){
                case -1:
                    throw new Error('Cannot obliterate non-paused queue');
                case -2:
                    throw new Error('Cannot obliterate queue with active jobs');
            }
        }
        return result;
    }
    /**
     * Paginate a set or hash keys.
     * @param opts - options to define the pagination behaviour
     *
     */ async paginate(key, opts) {
        const client = await this.queue.client;
        const keys = [
            key
        ];
        const maxIterations = 5;
        const pageSize = opts.end >= 0 ? opts.end - opts.start + 1 : Infinity;
        let cursor = '0', offset = 0, items, total, rawJobs, page = [], jobs = [];
        do {
            const args = [
                opts.start + page.length,
                opts.end,
                cursor,
                offset,
                maxIterations
            ];
            if (opts.fetchJobs) {
                args.push(1);
            }
            [cursor, offset, items, total, rawJobs] = await this.execCommand(client, 'paginate', keys.concat(args));
            page = page.concat(items);
            if (rawJobs && rawJobs.length) {
                jobs = jobs.concat(rawJobs.map(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["array2obj"]));
            }
        // Important to keep this coercive inequality (!=) instead of strict inequality (!==)
        }while (cursor != '0' && page.length < pageSize)
        // If we get an array of arrays, it means we are paginating a hash
        if (page.length && Array.isArray(page[0])) {
            const result = [];
            for(let index = 0; index < page.length; index++){
                const [id, value] = page[index];
                try {
                    result.push({
                        id,
                        v: JSON.parse(value)
                    });
                } catch (err) {
                    result.push({
                        id,
                        err: err.message
                    });
                }
            }
            return {
                cursor,
                items: result,
                total,
                jobs
            };
        } else {
            return {
                cursor,
                items: page.map((item)=>({
                        id: item
                    })),
                total,
                jobs
            };
        }
    }
    finishedErrors({ code, jobId, parentKey, command, state }) {
        let error;
        switch(code){
            case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$error$2d$code$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ErrorCode"].JobNotExist:
                error = new Error(`Missing key for job ${jobId}. ${command}`);
                break;
            case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$error$2d$code$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ErrorCode"].JobLockNotExist:
                error = new Error(`Missing lock for job ${jobId}. ${command}`);
                break;
            case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$error$2d$code$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ErrorCode"].JobNotInState:
                error = new Error(`Job ${jobId} is not in the ${state} state. ${command}`);
                break;
            case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$error$2d$code$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ErrorCode"].JobPendingChildren:
                error = new Error(`Job ${jobId} has pending dependencies. ${command}`);
                break;
            case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$error$2d$code$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ErrorCode"].ParentJobNotExist:
                error = new Error(`Missing key for parent job ${parentKey}. ${command}`);
                break;
            case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$error$2d$code$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ErrorCode"].JobLockMismatch:
                error = new Error(`Lock mismatch for job ${jobId}. Cmd ${command} from ${state}`);
                break;
            case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$error$2d$code$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ErrorCode"].ParentJobCannotBeReplaced:
                error = new Error(`The parent job ${parentKey} cannot be replaced. ${command}`);
                break;
            case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$error$2d$code$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ErrorCode"].JobBelongsToJobScheduler:
                error = new Error(`Job ${jobId} belongs to a job scheduler and cannot be removed directly. ${command}`);
                break;
            case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$error$2d$code$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ErrorCode"].JobHasFailedChildren:
                error = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$unrecoverable$2d$error$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["UnrecoverableError"](`Cannot complete job ${jobId} because it has at least one failed child. ${command}`);
                break;
            case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$error$2d$code$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ErrorCode"].SchedulerJobIdCollision:
                error = new Error(`Cannot create job scheduler iteration - job ID already exists. ${command}`);
                break;
            case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$error$2d$code$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ErrorCode"].SchedulerJobSlotsBusy:
                error = new Error(`Cannot create job scheduler iteration - current and next time slots already have jobs. ${command}`);
                break;
            default:
                error = new Error(`Unknown code ${code} error for ${jobId}. ${command}`);
        }
        // Add the code property to the error object
        error.code = code;
        return error;
    }
}
function raw2NextJobData(raw) {
    if (raw) {
        const result = [
            null,
            raw[1],
            raw[2],
            raw[3]
        ];
        if (raw[0]) {
            result[0] = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["array2obj"])(raw[0]);
        }
        return result;
    }
    return [];
} //# sourceMappingURL=scripts.js.map
}),
"[project]/node_modules/bullmq/dist/esm/utils/create-scripts.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "createScripts",
    ()=>createScripts
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$scripts$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/scripts.js [app-route] (ecmascript)");
;
const createScripts = (queue)=>{
    return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$scripts$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Scripts"]({
        keys: queue.keys,
        client: queue.client,
        get redisVersion () {
            return queue.redisVersion;
        },
        toKey: queue.toKey,
        opts: queue.opts,
        closing: queue.closing
    });
}; //# sourceMappingURL=create-scripts.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/job.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "Job",
    ()=>Job,
    "PRIORITY_LIMIT",
    ()=>PRIORITY_LIMIT
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$tslib$2f$tslib$2e$es6$2e$mjs__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/tslib/tslib.es6.mjs [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$externals$5d2f$util__$5b$external$5d$__$28$util$2c$__cjs$29$__ = __turbopack_context__.i("[externals]/util [external] (util, cjs)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/utils/index.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$create$2d$scripts$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/utils/create-scripts.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$backoffs$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/backoffs.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$unrecoverable$2d$error$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/errors/unrecoverable-error.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/telemetry-attributes.js [app-route] (ecmascript)");
;
;
;
;
;
;
;
const logger = (0, __TURBOPACK__imported__module__$5b$externals$5d2f$util__$5b$external$5d$__$28$util$2c$__cjs$29$__["debuglog"])('bull');
const PRIORITY_LIMIT = 2 ** 21;
class Job {
    constructor(queue, /**
     * The name of the Job
     */ name, /**
     * The payload for this job.
     */ data, /**
     * The options object for this job.
     */ opts = {}, id){
        this.queue = queue;
        this.name = name;
        this.data = data;
        this.opts = opts;
        this.id = id;
        /**
         * The progress a job has performed so far.
         * @defaultValue 0
         */ this.progress = 0;
        /**
         * The value returned by the processor when processing this job.
         * @defaultValue null
         */ this.returnvalue = null;
        /**
         * Stacktrace for the error (for failed jobs).
         * @defaultValue null
         */ this.stacktrace = null;
        /**
         * An amount of milliseconds to wait until this job can be processed.
         * @defaultValue 0
         */ this.delay = 0;
        /**
         * Ranges from 0 (highest priority) to 2 097 152 (lowest priority). Note that
         * using priorities has a slight impact on performance,
         * so do not use it if not required.
         * @defaultValue 0
         */ this.priority = 0;
        /**
         * Number of attempts when job is moved to active.
         * @defaultValue 0
         */ this.attemptsStarted = 0;
        /**
         * Number of attempts after the job has failed.
         * @defaultValue 0
         */ this.attemptsMade = 0;
        /**
         * Number of times where job has stalled.
         * @defaultValue 0
         */ this.stalledCounter = 0;
        const _a = this.opts, { repeatJobKey } = _a, restOpts = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$tslib$2f$tslib$2e$es6$2e$mjs__$5b$app$2d$route$5d$__$28$ecmascript$29$__["__rest"])(_a, [
            "repeatJobKey"
        ]);
        this.opts = Object.assign({
            attempts: 0
        }, restOpts);
        this.delay = this.opts.delay;
        this.priority = this.opts.priority || 0;
        this.repeatJobKey = repeatJobKey;
        this.timestamp = opts.timestamp ? opts.timestamp : Date.now();
        this.opts.backoff = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$backoffs$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Backoffs"].normalize(opts.backoff);
        this.parentKey = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getParentKey"])(opts.parent);
        if (opts.parent) {
            this.parent = {
                id: opts.parent.id,
                queueKey: opts.parent.queue
            };
            if (opts.failParentOnFailure) {
                this.parent.fpof = true;
            }
            if (opts.removeDependencyOnFailure) {
                this.parent.rdof = true;
            }
            if (opts.ignoreDependencyOnFailure) {
                this.parent.idof = true;
            }
            if (opts.continueParentOnFailure) {
                this.parent.cpof = true;
            }
        }
        this.debounceId = opts.debounce ? opts.debounce.id : undefined;
        this.deduplicationId = opts.deduplication ? opts.deduplication.id : this.debounceId;
        this.toKey = queue.toKey.bind(queue);
        this.createScripts();
        this.queueQualifiedName = queue.qualifiedName;
    }
    /**
     * Creates a new job and adds it to the queue.
     *
     * @param queue - the queue where to add the job.
     * @param name - the name of the job.
     * @param data - the payload of the job.
     * @param opts - the options bag for this job.
     * @returns
     */ static async create(queue, name, data, opts) {
        const client = await queue.client;
        const job = new this(queue, name, data, opts, opts && opts.jobId);
        job.id = await job.addJob(client, {
            parentKey: job.parentKey,
            parentDependenciesKey: job.parentKey ? `${job.parentKey}:dependencies` : ''
        });
        return job;
    }
    /**
     * Creates a bulk of jobs and adds them atomically to the given queue.
     *
     * @param queue -the queue were to add the jobs.
     * @param jobs - an array of jobs to be added to the queue.
     * @returns
     */ static async createBulk(queue, jobs) {
        const client = await queue.client;
        const jobInstances = jobs.map((job)=>{
            var _a;
            return new this(queue, job.name, job.data, job.opts, (_a = job.opts) === null || _a === void 0 ? void 0 : _a.jobId);
        });
        const pipeline = client.pipeline();
        for (const job of jobInstances){
            job.addJob(pipeline, {
                parentKey: job.parentKey,
                parentDependenciesKey: job.parentKey ? `${job.parentKey}:dependencies` : ''
            });
        }
        const results = await pipeline.exec();
        for(let index = 0; index < results.length; ++index){
            const [err, id] = results[index];
            if (err) {
                throw err;
            }
            jobInstances[index].id = id;
        }
        return jobInstances;
    }
    /**
     * Instantiates a Job from a JobJsonRaw object (coming from a deserialized JSON object)
     *
     * @param queue - the queue where the job belongs to.
     * @param json - the plain object containing the job.
     * @param jobId - an optional job id (overrides the id coming from the JSON object)
     * @returns
     */ static fromJSON(queue, json, jobId) {
        const data = JSON.parse(json.data || '{}');
        const opts = Job.optsFromJSON(json.opts);
        const job = new this(queue, json.name, data, opts, json.id || jobId);
        job.progress = JSON.parse(json.progress || '0');
        job.delay = parseInt(json.delay);
        job.priority = parseInt(json.priority);
        job.timestamp = parseInt(json.timestamp);
        if (json.finishedOn) {
            job.finishedOn = parseInt(json.finishedOn);
        }
        if (json.processedOn) {
            job.processedOn = parseInt(json.processedOn);
        }
        if (json.rjk) {
            job.repeatJobKey = json.rjk;
        }
        if (json.deid) {
            job.debounceId = json.deid;
            job.deduplicationId = json.deid;
        }
        if (json.failedReason) {
            job.failedReason = json.failedReason;
        }
        job.attemptsStarted = parseInt(json.ats || '0');
        job.attemptsMade = parseInt(json.attemptsMade || json.atm || '0');
        job.stalledCounter = parseInt(json.stc || '0');
        if (json.defa) {
            job.deferredFailure = json.defa;
        }
        job.stacktrace = getTraces(json.stacktrace);
        if (typeof json.returnvalue === 'string') {
            job.returnvalue = getReturnValue(json.returnvalue);
        }
        if (json.parentKey) {
            job.parentKey = json.parentKey;
        }
        if (json.parent) {
            job.parent = JSON.parse(json.parent);
        }
        if (json.pb) {
            job.processedBy = json.pb;
        }
        if (json.nrjid) {
            job.nextRepeatableJobId = json.nrjid;
        }
        return job;
    }
    createScripts() {
        this.scripts = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$create$2d$scripts$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["createScripts"])(this.queue);
    }
    static optsFromJSON(rawOpts, optsDecode = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["optsDecodeMap"]) {
        const opts = JSON.parse(rawOpts || '{}');
        const optionEntries = Object.entries(opts);
        const options = {};
        for (const item of optionEntries){
            const [attributeName, value] = item;
            if (optsDecode[attributeName]) {
                options[optsDecode[attributeName]] = value;
            } else {
                if (attributeName === 'tm') {
                    options.telemetry = Object.assign(Object.assign({}, options.telemetry), {
                        metadata: value
                    });
                } else if (attributeName === 'omc') {
                    options.telemetry = Object.assign(Object.assign({}, options.telemetry), {
                        omitContext: value
                    });
                } else {
                    options[attributeName] = value;
                }
            }
        }
        return options;
    }
    /**
     * Fetches a Job from the queue given the passed job id.
     *
     * @param queue - the queue where the job belongs to.
     * @param jobId - the job id.
     * @returns
     */ static async fromId(queue, jobId) {
        // jobId can be undefined if moveJob returns undefined
        if (jobId) {
            const client = await queue.client;
            const jobData = await client.hgetall(queue.toKey(jobId));
            return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isEmpty"])(jobData) ? undefined : this.fromJSON(queue, jobData, jobId);
        }
    }
    /**
     * addJobLog
     *
     * @param queue - A minimal queue instance
     * @param jobId - Job id
     * @param logRow - String with a row of log data to be logged
     * @param keepLogs - The optional amount of log entries to preserve
     *
     * @returns The total number of log entries for this job so far.
     */ static addJobLog(queue, jobId, logRow, keepLogs) {
        const scripts = queue.scripts;
        return scripts.addLog(jobId, logRow, keepLogs);
    }
    toJSON() {
        const _a = this, { queue, scripts } = _a, withoutQueueAndScripts = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$tslib$2f$tslib$2e$es6$2e$mjs__$5b$app$2d$route$5d$__$28$ecmascript$29$__["__rest"])(_a, [
            "queue",
            "scripts"
        ]);
        return withoutQueueAndScripts;
    }
    /**
     * Prepares a job to be serialized for storage in Redis.
     * @returns
     */ asJSON() {
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["removeUndefinedFields"])({
            id: this.id,
            name: this.name,
            data: JSON.stringify(typeof this.data === 'undefined' ? {} : this.data),
            opts: Job.optsAsJSON(this.opts),
            parent: this.parent ? Object.assign({}, this.parent) : undefined,
            parentKey: this.parentKey,
            progress: this.progress,
            attemptsMade: this.attemptsMade,
            attemptsStarted: this.attemptsStarted,
            stalledCounter: this.stalledCounter,
            finishedOn: this.finishedOn,
            processedOn: this.processedOn,
            timestamp: this.timestamp,
            failedReason: JSON.stringify(this.failedReason),
            stacktrace: JSON.stringify(this.stacktrace),
            debounceId: this.debounceId,
            deduplicationId: this.deduplicationId,
            repeatJobKey: this.repeatJobKey,
            returnvalue: JSON.stringify(this.returnvalue),
            nrjid: this.nextRepeatableJobId
        });
    }
    static optsAsJSON(opts = {}, optsEncode = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["optsEncodeMap"]) {
        const optionEntries = Object.entries(opts);
        const options = {};
        for (const [attributeName, value] of optionEntries){
            if (typeof value === 'undefined') {
                continue;
            }
            if (attributeName in optsEncode) {
                const compressableAttribute = attributeName;
                const key = optsEncode[compressableAttribute];
                options[key] = value;
            } else {
                // Handle complex compressable fields separately
                if (attributeName === 'telemetry') {
                    if (value.metadata !== undefined) {
                        options.tm = value.metadata;
                    }
                    if (value.omitContext !== undefined) {
                        options.omc = value.omitContext;
                    }
                } else {
                    options[attributeName] = value;
                }
            }
        }
        return options;
    }
    /**
     * Prepares a job to be passed to Sandbox.
     * @returns
     */ asJSONSandbox() {
        return Object.assign(Object.assign({}, this.asJSON()), {
            queueName: this.queueName,
            queueQualifiedName: this.queueQualifiedName,
            prefix: this.prefix
        });
    }
    /**
     * Updates a job's data
     *
     * @param data - the data that will replace the current jobs data.
     */ updateData(data) {
        this.data = data;
        return this.scripts.updateData(this, data);
    }
    /**
     * Updates a job's progress
     *
     * @param progress - number or object to be saved as progress.
     */ async updateProgress(progress) {
        this.progress = progress;
        await this.scripts.updateProgress(this.id, progress);
        this.queue.emit('progress', this, progress);
    }
    /**
     * Logs one row of log data.
     *
     * @param logRow - string with log data to be logged.
     * @returns The total number of log entries for this job so far.
     */ async log(logRow) {
        return Job.addJobLog(this.queue, this.id, logRow, this.opts.keepLogs);
    }
    /**
     * Removes child dependency from parent when child is not yet finished
     *
     * @returns True if the relationship existed and if it was removed.
     */ async removeChildDependency() {
        const childDependencyIsRemoved = await this.scripts.removeChildDependency(this.id, this.parentKey);
        if (childDependencyIsRemoved) {
            this.parent = undefined;
            this.parentKey = undefined;
            return true;
        }
        return false;
    }
    /**
     * Clears job's logs
     *
     * @param keepLogs - the amount of log entries to preserve
     */ async clearLogs(keepLogs) {
        const client = await this.queue.client;
        const logsKey = this.toKey(this.id) + ':logs';
        if (keepLogs) {
            await client.ltrim(logsKey, -keepLogs, -1);
        } else {
            await client.del(logsKey);
        }
    }
    /**
     * Completely remove the job from the queue.
     * Note, this call will throw an exception if the job
     * is being processed when the call is performed.
     *
     * @param opts - Options to remove a job
     */ async remove({ removeChildren = true } = {}) {
        await this.queue.waitUntilReady();
        const queue = this.queue;
        const job = this;
        const removed = await this.scripts.remove(job.id, removeChildren);
        if (removed) {
            queue.emit('removed', job);
        } else {
            throw new Error(`Job ${this.id} could not be removed because it is locked by another worker`);
        }
    }
    /**
     * Remove all children from this job that are not yet processed,
     * in other words that are in any other state than completed, failed or active.
     *
     * @remarks
     *  - Jobs with locks (most likely active) are ignored.
     *  - This method can be slow if the number of children is large (\> 1000).
     */ async removeUnprocessedChildren() {
        const jobId = this.id;
        await this.scripts.removeUnprocessedChildren(jobId);
    }
    /**
     * Extend the lock for this job.
     *
     * @param token - unique token for the lock
     * @param duration - lock duration in milliseconds
     */ extendLock(token, duration) {
        return this.scripts.extendLock(this.id, token, duration);
    }
    /**
     * Moves a job to the completed queue.
     * Returned job to be used with Queue.prototype.nextJobFromJobData.
     *
     * @param returnValue - The jobs success message.
     * @param token - Worker token used to acquire completed job.
     * @param fetchNext - True when wanting to fetch the next job.
     * @returns Returns the jobData of the next job in the waiting queue or void.
     */ async moveToCompleted(returnValue, token, fetchNext = true) {
        return this.queue.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'complete', this.queue.name, async (span, dstPropagationMedatadata)=>{
            var _a, _b;
            let tm;
            if (!((_b = (_a = this.opts) === null || _a === void 0 ? void 0 : _a.telemetry) === null || _b === void 0 ? void 0 : _b.omitContext) && dstPropagationMedatadata) {
                tm = dstPropagationMedatadata;
            }
            await this.queue.waitUntilReady();
            this.returnvalue = returnValue || void 0;
            const stringifiedReturnValue = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["tryCatch"])(JSON.stringify, JSON, [
                returnValue
            ]);
            if (stringifiedReturnValue === __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["errorObject"]) {
                throw __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["errorObject"].value;
            }
            const args = this.scripts.moveToCompletedArgs(this, stringifiedReturnValue, this.opts.removeOnComplete, token, fetchNext);
            const result = await this.scripts.moveToFinished(this.id, args);
            this.finishedOn = args[this.scripts.moveToFinishedKeys.length + 1];
            this.attemptsMade += 1;
            return result;
        });
    }
    /**
     * Moves a job to the wait or prioritized state.
     *
     * @param token - Worker token used to acquire completed job.
     * @returns Returns pttl.
     */ moveToWait(token) {
        return this.scripts.moveJobFromActiveToWait(this.id, token);
    }
    async shouldRetryJob(err) {
        if (this.attemptsMade + 1 < this.opts.attempts && !this.discarded && !(err instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$unrecoverable$2d$error$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["UnrecoverableError"] || err.name == 'UnrecoverableError')) {
            const opts = this.queue.opts;
            const delay = await __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$backoffs$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Backoffs"].calculate(this.opts.backoff, this.attemptsMade + 1, err, this, opts.settings && opts.settings.backoffStrategy);
            return [
                delay == -1 ? false : true,
                delay == -1 ? 0 : delay
            ];
        } else {
            return [
                false,
                0
            ];
        }
    }
    /**
     * Moves a job to the failed queue.
     *
     * @param err - the jobs error message.
     * @param token - token to check job is locked by current worker
     * @param fetchNext - true when wanting to fetch the next job
     * @returns Returns the jobData of the next job in the waiting queue or void.
     */ async moveToFailed(err, token, fetchNext = false) {
        this.failedReason = err === null || err === void 0 ? void 0 : err.message;
        // Check if an automatic retry should be performed
        const [shouldRetry, retryDelay] = await this.shouldRetryJob(err);
        return this.queue.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, this.getSpanOperation(shouldRetry, retryDelay), this.queue.name, async (span, dstPropagationMedatadata)=>{
            var _a, _b;
            let tm;
            if (!((_b = (_a = this.opts) === null || _a === void 0 ? void 0 : _a.telemetry) === null || _b === void 0 ? void 0 : _b.omitContext) && dstPropagationMedatadata) {
                tm = dstPropagationMedatadata;
            }
            let result;
            this.updateStacktrace(err);
            const fieldsToUpdate = {
                failedReason: this.failedReason,
                stacktrace: JSON.stringify(this.stacktrace),
                tm
            };
            let finishedOn;
            if (shouldRetry) {
                if (retryDelay) {
                    // Retry with delay
                    result = await this.scripts.moveToDelayed(this.id, Date.now(), retryDelay, token, {
                        fieldsToUpdate
                    });
                } else {
                    // Retry immediately
                    result = await this.scripts.retryJob(this.id, this.opts.lifo, token, {
                        fieldsToUpdate
                    });
                }
            } else {
                const args = this.scripts.moveToFailedArgs(this, this.failedReason, this.opts.removeOnFail, token, fetchNext, fieldsToUpdate);
                result = await this.scripts.moveToFinished(this.id, args);
                finishedOn = args[this.scripts.moveToFinishedKeys.length + 1];
            }
            if (finishedOn && typeof finishedOn === 'number') {
                this.finishedOn = finishedOn;
            }
            if (retryDelay && typeof retryDelay === 'number') {
                this.delay = retryDelay;
            }
            this.attemptsMade += 1;
            return result;
        });
    }
    getSpanOperation(shouldRetry, retryDelay) {
        if (shouldRetry) {
            if (retryDelay) {
                return 'delay';
            }
            return 'retry';
        }
        return 'fail';
    }
    /**
     * @returns true if the job has completed.
     */ isCompleted() {
        return this.isInZSet('completed');
    }
    /**
     * @returns true if the job has failed.
     */ isFailed() {
        return this.isInZSet('failed');
    }
    /**
     * @returns true if the job is delayed.
     */ isDelayed() {
        return this.isInZSet('delayed');
    }
    /**
     * @returns true if the job is waiting for children.
     */ isWaitingChildren() {
        return this.isInZSet('waiting-children');
    }
    /**
     * @returns true of the job is active.
     */ isActive() {
        return this.isInList('active');
    }
    /**
     * @returns true if the job is waiting.
     */ async isWaiting() {
        return await this.isInList('wait') || await this.isInList('paused');
    }
    /**
     * @returns the queue name this job belongs to.
     */ get queueName() {
        return this.queue.name;
    }
    /**
     * @returns the prefix that is used.
     */ get prefix() {
        return this.queue.opts.prefix;
    }
    /**
     * Get current state.
     *
     * @returns Returns one of these values:
     * 'completed', 'failed', 'delayed', 'active', 'waiting', 'waiting-children', 'unknown'.
     */ getState() {
        return this.scripts.getState(this.id);
    }
    /**
     * Change delay of a delayed job.
     *
     * Reschedules a delayed job by setting a new delay from the current time.
     * For example, calling changeDelay(5000) will reschedule the job to execute
     * 5000 milliseconds (5 seconds) from now, regardless of the original delay.
     *
     * @param delay - milliseconds from now when the job should be processed.
     * @returns void
     * @throws JobNotExist
     * This exception is thrown if jobId is missing.
     * @throws JobNotInState
     * This exception is thrown if job is not in delayed state.
     */ async changeDelay(delay) {
        await this.scripts.changeDelay(this.id, delay);
        this.delay = delay;
    }
    /**
     * Change job priority.
     *
     * @param opts - options containing priority and lifo values.
     * @returns void
     */ async changePriority(opts) {
        await this.scripts.changePriority(this.id, opts.priority, opts.lifo);
        this.priority = opts.priority || 0;
    }
    /**
     * Get this jobs children result values if any.
     *
     * @returns Object mapping children job keys with their values.
     */ async getChildrenValues() {
        const client = await this.queue.client;
        const result = await client.hgetall(this.toKey(`${this.id}:processed`));
        if (result) {
            return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["parseObjectValues"])(result);
        }
    }
    /**
     * Retrieves the failures of child jobs that were explicitly ignored while using ignoreDependencyOnFailure option.
     * This method is useful for inspecting which child jobs were intentionally ignored when an error occured.
     * @see {@link https://docs.bullmq.io/guide/flows/ignore-dependency}
     *
     * @returns Object mapping children job keys with their failure values.
     */ async getIgnoredChildrenFailures() {
        const client = await this.queue.client;
        return client.hgetall(this.toKey(`${this.id}:failed`));
    }
    /**
     * Get job's children failure values that were ignored if any.
     *
     * @deprecated This method is deprecated and will be removed in v6. Use getIgnoredChildrenFailures instead.
     *
     * @returns Object mapping children job keys with their failure values.
     */ async getFailedChildrenValues() {
        const client = await this.queue.client;
        return client.hgetall(this.toKey(`${this.id}:failed`));
    }
    /**
     * Get children job keys if this job is a parent and has children.
     * @remarks
     * Count options before Redis v7.2 works as expected with any quantity of entries
     * on processed/unprocessed dependencies, since v7.2 you must consider that count
     * won't have any effect until processed/unprocessed dependencies have a length
     * greater than 127
     * @see {@link https://redis.io/docs/management/optimization/memory-optimization/#redis--72}
     * @see {@link https://docs.bullmq.io/guide/flows#getters}
     * @returns dependencies separated by processed, unprocessed, ignored and failed.
     */ async getDependencies(opts = {}) {
        const client = await this.queue.client;
        const multi = client.multi();
        if (!opts.processed && !opts.unprocessed && !opts.ignored && !opts.failed) {
            multi.hgetall(this.toKey(`${this.id}:processed`));
            multi.smembers(this.toKey(`${this.id}:dependencies`));
            multi.hgetall(this.toKey(`${this.id}:failed`));
            multi.zrange(this.toKey(`${this.id}:unsuccessful`), 0, -1);
            const [[err1, processed], [err2, unprocessed], [err3, ignored], [err4, failed]] = await multi.exec();
            return {
                processed: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["parseObjectValues"])(processed),
                unprocessed,
                failed,
                ignored
            };
        } else {
            const defaultOpts = {
                cursor: 0,
                count: 20
            };
            const childrenResultOrder = [];
            if (opts.processed) {
                childrenResultOrder.push('processed');
                const processedOpts = Object.assign(Object.assign({}, defaultOpts), opts.processed);
                multi.hscan(this.toKey(`${this.id}:processed`), processedOpts.cursor, 'COUNT', processedOpts.count);
            }
            if (opts.unprocessed) {
                childrenResultOrder.push('unprocessed');
                const unprocessedOpts = Object.assign(Object.assign({}, defaultOpts), opts.unprocessed);
                multi.sscan(this.toKey(`${this.id}:dependencies`), unprocessedOpts.cursor, 'COUNT', unprocessedOpts.count);
            }
            if (opts.ignored) {
                childrenResultOrder.push('ignored');
                const ignoredOpts = Object.assign(Object.assign({}, defaultOpts), opts.ignored);
                multi.hscan(this.toKey(`${this.id}:failed`), ignoredOpts.cursor, 'COUNT', ignoredOpts.count);
            }
            let failedCursor;
            if (opts.failed) {
                childrenResultOrder.push('failed');
                const failedOpts = Object.assign(Object.assign({}, defaultOpts), opts.failed);
                failedCursor = failedOpts.cursor + failedOpts.count;
                multi.zrange(this.toKey(`${this.id}:unsuccessful`), failedOpts.cursor, failedOpts.count - 1);
            }
            const results = await multi.exec();
            let processedCursor, processed, unprocessedCursor, unprocessed, failed, ignoredCursor, ignored;
            childrenResultOrder.forEach((key, index)=>{
                switch(key){
                    case 'processed':
                        {
                            processedCursor = results[index][1][0];
                            const rawProcessed = results[index][1][1];
                            const transformedProcessed = {};
                            for(let ind = 0; ind < rawProcessed.length; ++ind){
                                if (ind % 2) {
                                    transformedProcessed[rawProcessed[ind - 1]] = JSON.parse(rawProcessed[ind]);
                                }
                            }
                            processed = transformedProcessed;
                            break;
                        }
                    case 'failed':
                        {
                            failed = results[index][1];
                            break;
                        }
                    case 'ignored':
                        {
                            ignoredCursor = results[index][1][0];
                            const rawIgnored = results[index][1][1];
                            const transformedIgnored = {};
                            for(let ind = 0; ind < rawIgnored.length; ++ind){
                                if (ind % 2) {
                                    transformedIgnored[rawIgnored[ind - 1]] = rawIgnored[ind];
                                }
                            }
                            ignored = transformedIgnored;
                            break;
                        }
                    case 'unprocessed':
                        {
                            unprocessedCursor = results[index][1][0];
                            unprocessed = results[index][1][1];
                            break;
                        }
                }
            });
            return Object.assign(Object.assign(Object.assign(Object.assign({}, processedCursor ? {
                processed,
                nextProcessedCursor: Number(processedCursor)
            } : {}), ignoredCursor ? {
                ignored,
                nextIgnoredCursor: Number(ignoredCursor)
            } : {}), failedCursor ? {
                failed,
                nextFailedCursor: failedCursor
            } : {}), unprocessedCursor ? {
                unprocessed,
                nextUnprocessedCursor: Number(unprocessedCursor)
            } : {});
        }
    }
    /**
     * Get children job counts if this job is a parent and has children.
     *
     * @returns dependencies count separated by processed, unprocessed, ignored and failed.
     */ async getDependenciesCount(opts = {}) {
        const types = [];
        Object.entries(opts).forEach(([key, value])=>{
            if (value) {
                types.push(key);
            }
        });
        const finalTypes = types.length ? types : [
            'processed',
            'unprocessed',
            'ignored',
            'failed'
        ];
        const responses = await this.scripts.getDependencyCounts(this.id, finalTypes);
        const counts = {};
        responses.forEach((res, index)=>{
            counts[`${finalTypes[index]}`] = res || 0;
        });
        return counts;
    }
    /**
     * Returns a promise the resolves when the job has completed (containing the return value of the job),
     * or rejects when the job has failed (containing the failedReason).
     *
     * @param queueEvents - Instance of QueueEvents.
     * @param ttl - Time in milliseconds to wait for job to finish before timing out.
     */ async waitUntilFinished(queueEvents, ttl) {
        await this.queue.waitUntilReady();
        const jobId = this.id;
        return new Promise(async (resolve, reject)=>{
            let timeout;
            if (ttl) {
                timeout = setTimeout(()=>onFailed(/* eslint-disable max-len */ `Job wait ${this.name} timed out before finishing, no finish notification arrived after ${ttl}ms (id=${jobId})`), ttl);
            }
            function onCompleted(args) {
                removeListeners();
                resolve(args.returnvalue);
            }
            function onFailed(args) {
                removeListeners();
                reject(new Error(args.failedReason || args));
            }
            const completedEvent = `completed:${jobId}`;
            const failedEvent = `failed:${jobId}`;
            queueEvents.on(completedEvent, onCompleted);
            queueEvents.on(failedEvent, onFailed);
            this.queue.on('closing', onFailed);
            const removeListeners = ()=>{
                clearInterval(timeout);
                queueEvents.removeListener(completedEvent, onCompleted);
                queueEvents.removeListener(failedEvent, onFailed);
                this.queue.removeListener('closing', onFailed);
            };
            // Poll once right now to see if the job has already finished. The job may have been completed before we were able
            // to register the event handlers on the QueueEvents, so we check here to make sure we're not waiting for an event
            // that has already happened. We block checking the job until the queue events object is actually listening to
            // Redis so there's no chance that it will miss events.
            await queueEvents.waitUntilReady();
            const [status, result] = await this.scripts.isFinished(jobId, true);
            const finished = status != 0;
            if (finished) {
                if (status == -1 || status == 2) {
                    onFailed({
                        failedReason: result
                    });
                } else {
                    onCompleted({
                        returnvalue: getReturnValue(result)
                    });
                }
            }
        });
    }
    /**
     * Moves the job to the delay set.
     *
     * @param timestamp - timestamp when the job should be moved back to "wait"
     * @param token - token to check job is locked by current worker
     * @returns
     */ async moveToDelayed(timestamp, token) {
        const now = Date.now();
        const delay = timestamp - now;
        const finalDelay = delay > 0 ? delay : 0;
        const movedToDelayed = await this.scripts.moveToDelayed(this.id, now, finalDelay, token, {
            skipAttempt: true
        });
        this.delay = finalDelay;
        return movedToDelayed;
    }
    /**
     * Moves the job to the waiting-children set.
     *
     * @param token - Token to check job is locked by current worker
     * @param opts - The options bag for moving a job to waiting-children.
     * @returns true if the job was moved
     */ async moveToWaitingChildren(token, opts = {}) {
        const movedToWaitingChildren = await this.scripts.moveToWaitingChildren(this.id, token, opts);
        return movedToWaitingChildren;
    }
    /**
     * Promotes a delayed job so that it starts to be processed as soon as possible.
     */ async promote() {
        const jobId = this.id;
        await this.scripts.promote(jobId);
        this.delay = 0;
    }
    /**
     * Attempts to retry the job. Only a job that has failed or completed can be retried.
     *
     * @param state - completed / failed
     * @returns A promise that resolves when the job has been successfully moved to the wait queue.
     * The queue emits a waiting event when the job is successfully moved.
     * @throws Will throw an error if the job does not exist, is locked, or is not in the expected state.
     */ retry(state = 'failed') {
        this.failedReason = null;
        this.finishedOn = null;
        this.processedOn = null;
        this.returnvalue = null;
        return this.scripts.reprocessJob(this, state);
    }
    /**
     * Marks a job to not be retried if it fails (even if attempts has been configured)
     * @deprecated use UnrecoverableError
     */ discard() {
        this.discarded = true;
    }
    async isInZSet(set) {
        const client = await this.queue.client;
        const score = await client.zscore(this.queue.toKey(set), this.id);
        return score !== null;
    }
    async isInList(list) {
        return this.scripts.isJobInList(this.queue.toKey(list), this.id);
    }
    /**
     * Adds the job to Redis.
     *
     * @param client -
     * @param parentOpts -
     * @returns
     */ addJob(client, parentOpts) {
        const jobData = this.asJSON();
        this.validateOptions(jobData);
        return this.scripts.addJob(client, jobData, jobData.opts, this.id, parentOpts);
    }
    /**
     * Removes a deduplication key if job is still the cause of deduplication.
     * @returns true if the deduplication key was removed.
     */ async removeDeduplicationKey() {
        if (this.deduplicationId) {
            const result = await this.scripts.removeDeduplicationKey(this.deduplicationId, this.id);
            return result > 0;
        }
        return false;
    }
    validateOptions(jobData) {
        var _a, _b, _c, _d, _e, _f, _g, _h;
        const exclusiveOptions = [
            'removeDependencyOnFailure',
            'failParentOnFailure',
            'continueParentOnFailure',
            'ignoreDependencyOnFailure'
        ];
        const exceedLimit = this.opts.sizeLimit && (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["lengthInUtf8Bytes"])(jobData.data) > this.opts.sizeLimit;
        if (exceedLimit) {
            throw new Error(`The size of job ${this.name} exceeds the limit ${this.opts.sizeLimit} bytes`);
        }
        if (this.opts.delay && this.opts.repeat && !((_a = this.opts.repeat) === null || _a === void 0 ? void 0 : _a.count)) {
            throw new Error(`Delay and repeat options could not be used together`);
        }
        const enabledExclusiveOptions = exclusiveOptions.filter((opt)=>this.opts[opt]);
        if (enabledExclusiveOptions.length > 1) {
            const optionsList = enabledExclusiveOptions.join(', ');
            throw new Error(`The following options cannot be used together: ${optionsList}`);
        }
        if ((_b = this.opts) === null || _b === void 0 ? void 0 : _b.jobId) {
            if (`${parseInt(this.opts.jobId, 10)}` === ((_c = this.opts) === null || _c === void 0 ? void 0 : _c.jobId)) {
                throw new Error('Custom Id cannot be integers');
            }
            // TODO: replace this check in next breaking check with include(':')
            // By using split we are still keeping compatibility with old repeatable jobs
            if (((_d = this.opts) === null || _d === void 0 ? void 0 : _d.jobId.includes(':')) && ((_f = (_e = this.opts) === null || _e === void 0 ? void 0 : _e.jobId) === null || _f === void 0 ? void 0 : _f.split(':').length) !== 3) {
                throw new Error('Custom Id cannot contain :');
            }
        }
        if (this.opts.priority) {
            if (Math.trunc(this.opts.priority) !== this.opts.priority) {
                throw new Error(`Priority should not be float`);
            }
            if (this.opts.priority > PRIORITY_LIMIT) {
                throw new Error(`Priority should be between 0 and ${PRIORITY_LIMIT}`);
            }
        }
        if (this.opts.deduplication) {
            if (!((_g = this.opts.deduplication) === null || _g === void 0 ? void 0 : _g.id)) {
                throw new Error('Deduplication id must be provided');
            }
        }
        // TODO: remove in v6
        if (this.opts.debounce) {
            if (!((_h = this.opts.debounce) === null || _h === void 0 ? void 0 : _h.id)) {
                throw new Error('Debounce id must be provided');
            }
        }
        if (typeof this.opts.backoff === 'object' && typeof this.opts.backoff.jitter === 'number') {
            if (this.opts.backoff.jitter < 0 || this.opts.backoff.jitter > 1) {
                throw new Error(`Jitter should be between 0 and 1`);
            }
        }
    }
    updateStacktrace(err) {
        this.stacktrace = this.stacktrace || [];
        if (err === null || err === void 0 ? void 0 : err.stack) {
            this.stacktrace.push(err.stack);
            if (this.opts.stackTraceLimit === 0) {
                this.stacktrace = [];
            } else if (this.opts.stackTraceLimit) {
                this.stacktrace = this.stacktrace.slice(-this.opts.stackTraceLimit);
            }
        }
    }
}
function getTraces(stacktrace) {
    if (!stacktrace) {
        return [];
    }
    const traces = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["tryCatch"])(JSON.parse, JSON, [
        stacktrace
    ]);
    if (traces === __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["errorObject"] || !(traces instanceof Array)) {
        return [];
    } else {
        return traces;
    }
}
function getReturnValue(_value) {
    const value = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["tryCatch"])(JSON.parse, JSON, [
        _value
    ]);
    if (value !== __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["errorObject"]) {
        return value;
    } else {
        logger('corrupted returnvalue: ' + _value, value);
    }
} //# sourceMappingURL=job.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/queue-keys.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "QueueKeys",
    ()=>QueueKeys
]);
class QueueKeys {
    constructor(prefix = 'bull'){
        this.prefix = prefix;
    }
    getKeys(name) {
        const keys = {};
        [
            '',
            'active',
            'wait',
            'waiting-children',
            'paused',
            'id',
            'delayed',
            'prioritized',
            'stalled-check',
            'completed',
            'failed',
            'stalled',
            'repeat',
            'limiter',
            'meta',
            'events',
            'pc',
            'marker',
            'de'
        ].forEach((key)=>{
            keys[key] = this.toKey(name, key);
        });
        return keys;
    }
    toKey(name, type) {
        return `${this.getQueueQualifiedName(name)}:${type}`;
    }
    getQueueQualifiedName(name) {
        return `${this.prefix}:${name}`;
    }
} //# sourceMappingURL=queue-keys.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/addDelayedJob-6.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "addDelayedJob",
    ()=>addDelayedJob
]);
const content = `--[[
  Adds a delayed job to the queue by doing the following:
    - Increases the job counter if needed.
    - Creates a new job key with the job data.
    - computes timestamp.
    - adds to delayed zset.
    - Emits a global event 'delayed' if the job is delayed.
    Input:
      KEYS[1] 'marker',
      KEYS[2] 'meta'
      KEYS[3] 'id'
      KEYS[4] 'delayed'
      KEYS[5] 'completed'
      KEYS[6] events stream key
      ARGV[1] msgpacked arguments array
            [1]  key prefix,
            [2]  custom id (use custom instead of one generated automatically)
            [3]  name
            [4]  timestamp
            [5]  parentKey?
            [6]  parent dependencies key.
            [7]  parent? {id, queueKey}
            [8]  repeat job key
            [9] deduplication key
      ARGV[2] Json stringified job data
      ARGV[3] msgpacked options
      Output:
        jobId  - OK
        -5     - Missing parent key
]]
local metaKey = KEYS[2]
local idKey = KEYS[3]
local delayedKey = KEYS[4]
local completedKey = KEYS[5]
local eventsKey = KEYS[6]
local jobId
local jobIdKey
local rcall = redis.call
local args = cmsgpack.unpack(ARGV[1])
local data = ARGV[2]
local parentKey = args[5]
local parent = args[7]
local repeatJobKey = args[8]
local deduplicationKey = args[9]
local parentData
-- Includes
--[[
  Adds a delayed job to the queue by doing the following:
    - Creates a new job key with the job data.
    - adds to delayed zset.
    - Emits a global event 'delayed' if the job is delayed.
]]
-- Includes
--[[
  Add delay marker if needed.
]]
-- Includes
--[[
  Function to return the next delayed job timestamp.
]]
local function getNextDelayedTimestamp(delayedKey)
  local result = rcall("ZRANGE", delayedKey, 0, 0, "WITHSCORES")
  if #result then
    local nextTimestamp = tonumber(result[2])
    if nextTimestamp ~= nil then
      return nextTimestamp / 0x1000
    end
  end
end
local function addDelayMarkerIfNeeded(markerKey, delayedKey)
  local nextTimestamp = getNextDelayedTimestamp(delayedKey)
  if nextTimestamp ~= nil then
    -- Replace the score of the marker with the newest known
    -- next timestamp.
    rcall("ZADD", markerKey, nextTimestamp, "1")
  end
end
--[[
  Bake in the job id first 12 bits into the timestamp
  to guarantee correct execution order of delayed jobs
  (up to 4096 jobs per given timestamp or 4096 jobs apart per timestamp)
  WARNING: Jobs that are so far apart that they wrap around will cause FIFO to fail
]]
local function getDelayedScore(delayedKey, timestamp, delay)
  local delayedTimestamp = (delay > 0 and (tonumber(timestamp) + delay)) or tonumber(timestamp)
  local minScore = delayedTimestamp * 0x1000
  local maxScore = (delayedTimestamp + 1 ) * 0x1000 - 1
  local result = rcall("ZREVRANGEBYSCORE", delayedKey, maxScore,
    minScore, "WITHSCORES","LIMIT", 0, 1)
  if #result then
    local currentMaxScore = tonumber(result[2])
    if currentMaxScore ~= nil then
      if currentMaxScore >= maxScore then
        return maxScore, delayedTimestamp
      else
        return currentMaxScore + 1, delayedTimestamp
      end
    end
  end
  return minScore, delayedTimestamp
end
local function addDelayedJob(jobId, delayedKey, eventsKey, timestamp,
  maxEvents, markerKey, delay)
  local score, delayedTimestamp = getDelayedScore(delayedKey, timestamp, tonumber(delay))
  rcall("ZADD", delayedKey, score, jobId)
  rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "delayed",
    "jobId", jobId, "delay", delayedTimestamp)
  -- mark that a delayed job is available
  addDelayMarkerIfNeeded(markerKey, delayedKey)
end
--[[
  Function to debounce a job.
]]
-- Includes
--[[
  Function to remove job keys.
]]
local function removeJobKeys(jobKey)
  return rcall("DEL", jobKey, jobKey .. ':logs', jobKey .. ':dependencies',
    jobKey .. ':processed', jobKey .. ':failed', jobKey .. ':unsuccessful')
end
local function removeDelayedJob(delayedKey, deduplicationKey, eventsKey, maxEvents, currentDeduplicatedJobId,
    jobId, deduplicationId, prefix)
    if rcall("ZREM", delayedKey, currentDeduplicatedJobId) > 0 then
        removeJobKeys(prefix .. currentDeduplicatedJobId)
        rcall("XADD", eventsKey, "*", "event", "removed", "jobId", currentDeduplicatedJobId,
            "prev", "delayed")
        -- TODO remove debounced event in next breaking change
        rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "debounced", "jobId",
            jobId, "debounceId", deduplicationId)
        rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "deduplicated", "jobId",
            jobId, "deduplicationId", deduplicationId, "deduplicatedJobId", currentDeduplicatedJobId)
        return true
    end
    return false
end
local function deduplicateJob(deduplicationOpts, jobId, delayedKey, deduplicationKey, eventsKey, maxEvents,
    prefix)
    local deduplicationId = deduplicationOpts and deduplicationOpts['id']
    if deduplicationId then
        local ttl = deduplicationOpts['ttl']
        if deduplicationOpts['replace'] then
            if ttl and ttl > 0 then
                local currentDebounceJobId = rcall('GET', deduplicationKey)
                if currentDebounceJobId then
                    local isRemoved = removeDelayedJob(delayedKey, deduplicationKey, eventsKey, maxEvents,
                        currentDebounceJobId, jobId, deduplicationId, prefix)
                    if isRemoved then
                        if deduplicationOpts['extend'] then
                            rcall('SET', deduplicationKey, jobId, 'PX', ttl)
                        else
                            rcall('SET', deduplicationKey, jobId, 'KEEPTTL')
                        end
                        return
                    else
                        return currentDebounceJobId
                    end
                else
                    rcall('SET', deduplicationKey, jobId, 'PX', ttl)
                    return
                end
            else
                local currentDebounceJobId = rcall('GET', deduplicationKey)
                if currentDebounceJobId then
                    local isRemoved = removeDelayedJob(delayedKey, deduplicationKey, eventsKey, maxEvents,
                        currentDebounceJobId, jobId, deduplicationId, prefix)
                    if isRemoved then
                        rcall('SET', deduplicationKey, jobId)
                        return
                    else
                        return currentDebounceJobId
                    end
                else
                    rcall('SET', deduplicationKey, jobId)
                    return
                end
            end
        else
            local deduplicationKeyExists
            if ttl and ttl > 0 then
                if deduplicationOpts['extend'] then
                    local currentDebounceJobId = rcall('GET', deduplicationKey)
                    if currentDebounceJobId then
                        rcall('SET', deduplicationKey, currentDebounceJobId, 'PX', ttl)
                        rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "debounced",
                            "jobId", currentDebounceJobId, "debounceId", deduplicationId)
                        rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "deduplicated", "jobId",
                            currentDebounceJobId, "deduplicationId", deduplicationId, "deduplicatedJobId", jobId)
                        return currentDebounceJobId
                    else
                        rcall('SET', deduplicationKey, jobId, 'PX', ttl)
                        return
                    end
                else
                    deduplicationKeyExists = not rcall('SET', deduplicationKey, jobId, 'PX', ttl, 'NX')
                end
            else
                deduplicationKeyExists = not rcall('SET', deduplicationKey, jobId, 'NX')
            end
            if deduplicationKeyExists then
                local currentDebounceJobId = rcall('GET', deduplicationKey)
                -- TODO remove debounced event in next breaking change
                rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "debounced", "jobId",
                    currentDebounceJobId, "debounceId", deduplicationId)
                rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "deduplicated", "jobId",
                    currentDebounceJobId, "deduplicationId", deduplicationId, "deduplicatedJobId", jobId)
                return currentDebounceJobId
            end
        end
    end
end
--[[
  Function to get max events value or set by default 10000.
]]
local function getOrSetMaxEvents(metaKey)
  local maxEvents = rcall("HGET", metaKey, "opts.maxLenEvents")
  if not maxEvents then
    maxEvents = 10000
    rcall("HSET", metaKey, "opts.maxLenEvents", maxEvents)
  end
  return maxEvents
end
--[[
  Function to handle the case when job is duplicated.
]]
-- Includes
--[[
    This function is used to update the parent's dependencies if the job
    is already completed and about to be ignored. The parent must get its
    dependencies updated to avoid the parent job being stuck forever in 
    the waiting-children state.
]]
-- Includes
--[[
  Validate and move or add dependencies to parent.
]]
-- Includes
--[[
  Validate and move parent to a wait status (waiting, delayed or prioritized)
  if no pending dependencies.
]]
-- Includes
--[[
  Validate and move parent to a wait status (waiting, delayed or prioritized) if needed.
]]
-- Includes
--[[
  Move parent to a wait status (wait, prioritized or delayed)
]]
-- Includes
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to add job considering priority.
]]
-- Includes
--[[
  Function to get priority score.
]]
local function getPriorityScore(priority, priorityCounterKey)
  local prioCounter = rcall("INCR", priorityCounterKey)
  return priority * 0x100000000 + prioCounter % 0x100000000
end
local function addJobWithPriority(markerKey, prioritizedKey, priority, jobId, priorityCounterKey,
  isPausedOrMaxed)
  local score = getPriorityScore(priority, priorityCounterKey)
  rcall("ZADD", prioritizedKey, score, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to check if queue is paused or maxed
  (since an empty list and !EXISTS are not really the same).
]]
local function isQueuePausedOrMaxed(queueMetaKey, activeKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency")
  if queueAttributes[1] then
    return true
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      return activeCount >= tonumber(queueAttributes[2])
    end
  end
  return false
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
local function moveParentToWait(parentQueueKey, parentKey, parentId, timestamp)
    local parentWaitKey = parentQueueKey .. ":wait"
    local parentPausedKey = parentQueueKey .. ":paused"
    local parentActiveKey = parentQueueKey .. ":active"
    local parentMetaKey = parentQueueKey .. ":meta"
    local parentMarkerKey = parentQueueKey .. ":marker"
    local jobAttributes = rcall("HMGET", parentKey, "priority", "delay")
    local priority = tonumber(jobAttributes[1]) or 0
    local delay = tonumber(jobAttributes[2]) or 0
    if delay > 0 then
        local delayedTimestamp = tonumber(timestamp) + delay
        local score = delayedTimestamp * 0x1000
        local parentDelayedKey = parentQueueKey .. ":delayed"
        rcall("ZADD", parentDelayedKey, score, parentId)
        rcall("XADD", parentQueueKey .. ":events", "*", "event", "delayed", "jobId", parentId, "delay",
            delayedTimestamp)
        addDelayMarkerIfNeeded(parentMarkerKey, parentDelayedKey)
    else
        if priority == 0 then
            local parentTarget, isParentPausedOrMaxed = getTargetQueueList(parentMetaKey, parentActiveKey,
                parentWaitKey, parentPausedKey)
            addJobInTargetList(parentTarget, parentMarkerKey, "RPUSH", isParentPausedOrMaxed, parentId)
        else
            local isPausedOrMaxed = isQueuePausedOrMaxed(parentMetaKey, parentActiveKey)
            addJobWithPriority(parentMarkerKey, parentQueueKey .. ":prioritized", priority, parentId,
                parentQueueKey .. ":pc", isPausedOrMaxed)
        end
        rcall("XADD", parentQueueKey .. ":events", "*", "event", "waiting", "jobId", parentId, "prev",
            "waiting-children")
    end
end
local function moveParentToWaitIfNeeded(parentQueueKey, parentKey, parentId, timestamp)
  if rcall("EXISTS", parentKey) == 1 then
    local parentWaitingChildrenKey = parentQueueKey .. ":waiting-children"
    if rcall("ZSCORE", parentWaitingChildrenKey, parentId) then    
      rcall("ZREM", parentWaitingChildrenKey, parentId)
      moveParentToWait(parentQueueKey, parentKey, parentId, timestamp)
    end
  end
end
local function moveParentToWaitIfNoPendingDependencies(parentQueueKey, parentDependenciesKey, parentKey,
  parentId, timestamp)
  local doNotHavePendingDependencies = rcall("SCARD", parentDependenciesKey) == 0
  if doNotHavePendingDependencies then
    moveParentToWaitIfNeeded(parentQueueKey, parentKey, parentId, timestamp)
  end
end
local function updateParentDepsIfNeeded(parentKey, parentQueueKey, parentDependenciesKey,
  parentId, jobIdKey, returnvalue, timestamp )
  local processedSet = parentKey .. ":processed"
  rcall("HSET", processedSet, jobIdKey, returnvalue)
  moveParentToWaitIfNoPendingDependencies(parentQueueKey, parentDependenciesKey, parentKey, parentId, timestamp)
end
local function updateExistingJobsParent(parentKey, parent, parentData,
                                        parentDependenciesKey, completedKey,
                                        jobIdKey, jobId, timestamp)
    if parentKey ~= nil then
        if rcall("ZSCORE", completedKey, jobId) then
            local returnvalue = rcall("HGET", jobIdKey, "returnvalue")
            updateParentDepsIfNeeded(parentKey, parent['queueKey'],
                                     parentDependenciesKey, parent['id'],
                                     jobIdKey, returnvalue, timestamp)
        else
            if parentDependenciesKey ~= nil then
                rcall("SADD", parentDependenciesKey, jobIdKey)
            end
        end
        rcall("HMSET", jobIdKey, "parentKey", parentKey, "parent", parentData)
    end
end
local function handleDuplicatedJob(jobKey, jobId, currentParentKey, currentParent,
  parentData, parentDependenciesKey, completedKey, eventsKey, maxEvents, timestamp)
  local existedParentKey = rcall("HGET", jobKey, "parentKey")
  if not existedParentKey or existedParentKey == currentParentKey then
    updateExistingJobsParent(currentParentKey, currentParent, parentData,
      parentDependenciesKey, completedKey, jobKey,
      jobId, timestamp)
  else
    if currentParentKey ~= nil and currentParentKey ~= existedParentKey
      and (rcall("EXISTS", existedParentKey) == 1) then
      return -7
    end
  end
  rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event",
    "duplicated", "jobId", jobId)
  return jobId .. "" -- convert to string
end
--[[
  Function to store a job
]]
local function storeJob(eventsKey, jobIdKey, jobId, name, data, opts, timestamp,
                        parentKey, parentData, repeatJobKey)
    local jsonOpts = cjson.encode(opts)
    local delay = opts['delay'] or 0
    local priority = opts['priority'] or 0
    local debounceId = opts['de'] and opts['de']['id']
    local optionalValues = {}
    if parentKey ~= nil then
        table.insert(optionalValues, "parentKey")
        table.insert(optionalValues, parentKey)
        table.insert(optionalValues, "parent")
        table.insert(optionalValues, parentData)
    end
    if repeatJobKey then
        table.insert(optionalValues, "rjk")
        table.insert(optionalValues, repeatJobKey)
    end
    if debounceId then
        table.insert(optionalValues, "deid")
        table.insert(optionalValues, debounceId)
    end
    rcall("HMSET", jobIdKey, "name", name, "data", data, "opts", jsonOpts,
          "timestamp", timestamp, "delay", delay, "priority", priority,
          unpack(optionalValues))
    rcall("XADD", eventsKey, "*", "event", "added", "jobId", jobId, "name", name)
    return delay, priority
end
if parentKey ~= nil then
    if rcall("EXISTS", parentKey) ~= 1 then return -5 end
    parentData = cjson.encode(parent)
end
local jobCounter = rcall("INCR", idKey)
local maxEvents = getOrSetMaxEvents(metaKey)
local opts = cmsgpack.unpack(ARGV[3])
local parentDependenciesKey = args[6]
local timestamp = args[4]
if args[2] == "" then
    jobId = jobCounter
    jobIdKey = args[1] .. jobId
else
    jobId = args[2]
    jobIdKey = args[1] .. jobId
    if rcall("EXISTS", jobIdKey) == 1 then
        return handleDuplicatedJob(jobIdKey, jobId, parentKey, parent,
            parentData, parentDependenciesKey, completedKey, eventsKey,
            maxEvents, timestamp)
    end
end
local deduplicationJobId = deduplicateJob(opts['de'], jobId, delayedKey, deduplicationKey,
  eventsKey, maxEvents, args[1])
if deduplicationJobId then
  return deduplicationJobId
end
local delay, priority = storeJob(eventsKey, jobIdKey, jobId, args[3], ARGV[2],
    opts, timestamp, parentKey, parentData, repeatJobKey)
addDelayedJob(jobId, delayedKey, eventsKey, timestamp, maxEvents, KEYS[1], delay)
-- Check if this job is a child of another job, if so add it to the parents dependencies
if parentDependenciesKey ~= nil then
    rcall("SADD", parentDependenciesKey, jobIdKey)
end
return jobId .. "" -- convert to string
`;
const addDelayedJob = {
    name: 'addDelayedJob',
    content,
    keys: 6
}; //# sourceMappingURL=addDelayedJob-6.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/addJobScheduler-11.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "addJobScheduler",
    ()=>addJobScheduler
]);
const content = `--[[
  Adds a job scheduler, i.e. a job factory that creates jobs based on a given schedule (repeat options).
    Input:
      KEYS[1]  'repeat' key
      KEYS[2]  'delayed' key
      KEYS[3]  'wait' key
      KEYS[4]  'paused' key
      KEYS[5]  'meta' key
      KEYS[6]  'prioritized' key
      KEYS[7]  'marker' key
      KEYS[8]  'id' key
      KEYS[9]  'events' key
      KEYS[10] 'pc' priority counter
      KEYS[11] 'active' key
      ARGV[1] next milliseconds
      ARGV[2] msgpacked options
            [1]  name
            [2]  tz?
            [3]  pattern?
            [4]  endDate?
            [5]  every?
      ARGV[3] jobs scheduler id
      ARGV[4] Json stringified template data
      ARGV[5] mspacked template opts
      ARGV[6] msgpacked delayed opts
      ARGV[7] timestamp
      ARGV[8] prefix key
      ARGV[9] producer key
      Output:
        repeatableKey  - OK
]] local rcall = redis.call
local repeatKey = KEYS[1]
local delayedKey = KEYS[2]
local waitKey = KEYS[3]
local pausedKey = KEYS[4]
local metaKey = KEYS[5]
local prioritizedKey = KEYS[6]
local eventsKey = KEYS[9]
local nextMillis = ARGV[1]
local jobSchedulerId = ARGV[3]
local templateOpts = cmsgpack.unpack(ARGV[5])
local now = tonumber(ARGV[7])
local prefixKey = ARGV[8]
local jobOpts = cmsgpack.unpack(ARGV[6])
-- Includes
--[[
  Add delay marker if needed.
]]
-- Includes
--[[
  Adds a delayed job to the queue by doing the following:
    - Creates a new job key with the job data.
    - adds to delayed zset.
    - Emits a global event 'delayed' if the job is delayed.
]]
-- Includes
--[[
  Add delay marker if needed.
]]
-- Includes
--[[
  Function to return the next delayed job timestamp.
]]
local function getNextDelayedTimestamp(delayedKey)
  local result = rcall("ZRANGE", delayedKey, 0, 0, "WITHSCORES")
  if #result then
    local nextTimestamp = tonumber(result[2])
    if nextTimestamp ~= nil then
      return nextTimestamp / 0x1000
    end
  end
end
local function addDelayMarkerIfNeeded(markerKey, delayedKey)
  local nextTimestamp = getNextDelayedTimestamp(delayedKey)
  if nextTimestamp ~= nil then
    -- Replace the score of the marker with the newest known
    -- next timestamp.
    rcall("ZADD", markerKey, nextTimestamp, "1")
  end
end
--[[
  Bake in the job id first 12 bits into the timestamp
  to guarantee correct execution order of delayed jobs
  (up to 4096 jobs per given timestamp or 4096 jobs apart per timestamp)
  WARNING: Jobs that are so far apart that they wrap around will cause FIFO to fail
]]
local function getDelayedScore(delayedKey, timestamp, delay)
  local delayedTimestamp = (delay > 0 and (tonumber(timestamp) + delay)) or tonumber(timestamp)
  local minScore = delayedTimestamp * 0x1000
  local maxScore = (delayedTimestamp + 1 ) * 0x1000 - 1
  local result = rcall("ZREVRANGEBYSCORE", delayedKey, maxScore,
    minScore, "WITHSCORES","LIMIT", 0, 1)
  if #result then
    local currentMaxScore = tonumber(result[2])
    if currentMaxScore ~= nil then
      if currentMaxScore >= maxScore then
        return maxScore, delayedTimestamp
      else
        return currentMaxScore + 1, delayedTimestamp
      end
    end
  end
  return minScore, delayedTimestamp
end
local function addDelayedJob(jobId, delayedKey, eventsKey, timestamp,
  maxEvents, markerKey, delay)
  local score, delayedTimestamp = getDelayedScore(delayedKey, timestamp, tonumber(delay))
  rcall("ZADD", delayedKey, score, jobId)
  rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "delayed",
    "jobId", jobId, "delay", delayedTimestamp)
  -- mark that a delayed job is available
  addDelayMarkerIfNeeded(markerKey, delayedKey)
end
--[[
  Function to add job considering priority.
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
--[[
  Function to get priority score.
]]
local function getPriorityScore(priority, priorityCounterKey)
  local prioCounter = rcall("INCR", priorityCounterKey)
  return priority * 0x100000000 + prioCounter % 0x100000000
end
local function addJobWithPriority(markerKey, prioritizedKey, priority, jobId, priorityCounterKey,
  isPausedOrMaxed)
  local score = getPriorityScore(priority, priorityCounterKey)
  rcall("ZADD", prioritizedKey, score, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function isQueuePaused(queueMetaKey)
  return rcall("HEXISTS", queueMetaKey, "paused") == 1
end
--[[
  Function to store a job
]]
local function storeJob(eventsKey, jobIdKey, jobId, name, data, opts, timestamp,
                        parentKey, parentData, repeatJobKey)
    local jsonOpts = cjson.encode(opts)
    local delay = opts['delay'] or 0
    local priority = opts['priority'] or 0
    local debounceId = opts['de'] and opts['de']['id']
    local optionalValues = {}
    if parentKey ~= nil then
        table.insert(optionalValues, "parentKey")
        table.insert(optionalValues, parentKey)
        table.insert(optionalValues, "parent")
        table.insert(optionalValues, parentData)
    end
    if repeatJobKey then
        table.insert(optionalValues, "rjk")
        table.insert(optionalValues, repeatJobKey)
    end
    if debounceId then
        table.insert(optionalValues, "deid")
        table.insert(optionalValues, debounceId)
    end
    rcall("HMSET", jobIdKey, "name", name, "data", data, "opts", jsonOpts,
          "timestamp", timestamp, "delay", delay, "priority", priority,
          unpack(optionalValues))
    rcall("XADD", eventsKey, "*", "event", "added", "jobId", jobId, "name", name)
    return delay, priority
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
local function addJobFromScheduler(jobKey, jobId, opts, waitKey, pausedKey, activeKey, metaKey, 
  prioritizedKey, priorityCounter, delayedKey, markerKey, eventsKey, name, maxEvents, timestamp,
  data, jobSchedulerId, repeatDelay)
  opts['delay'] = repeatDelay
  opts['jobId'] = jobId
  local delay, priority = storeJob(eventsKey, jobKey, jobId, name, data,
    opts, timestamp, nil, nil, jobSchedulerId)
  if delay ~= 0 then
    addDelayedJob(jobId, delayedKey, eventsKey, timestamp, maxEvents, markerKey, delay)
  else
    local target, isPausedOrMaxed = getTargetQueueList(metaKey, activeKey, waitKey, pausedKey)
    -- Standard or priority add
    if priority == 0 then
      local pushCmd = opts['lifo'] and 'RPUSH' or 'LPUSH'
      addJobInTargetList(target, markerKey, pushCmd, isPausedOrMaxed, jobId)
    else
      -- Priority add
      addJobWithPriority(markerKey, prioritizedKey, priority, jobId, priorityCounter, isPausedOrMaxed)
    end
    -- Emit waiting event
    rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents,  "*", "event", "waiting", "jobId", jobId)
  end
end
--[[
  Function to get max events value or set by default 10000.
]]
local function getOrSetMaxEvents(metaKey)
  local maxEvents = rcall("HGET", metaKey, "opts.maxLenEvents")
  if not maxEvents then
    maxEvents = 10000
    rcall("HSET", metaKey, "opts.maxLenEvents", maxEvents)
  end
  return maxEvents
end
--[[
  Function to remove job.
]]
-- Includes
--[[
  Function to remove deduplication key if needed
  when a job is being removed.
]]
local function removeDeduplicationKeyIfNeededOnRemoval(prefixKey,
  jobKey, jobId)
  local deduplicationId = rcall("HGET", jobKey, "deid")
  if deduplicationId then
    local deduplicationKey = prefixKey .. "de:" .. deduplicationId
    local currentJobId = rcall('GET', deduplicationKey)
    if currentJobId and currentJobId == jobId then
      return rcall("DEL", deduplicationKey)
    end
  end
end
--[[
  Function to remove job keys.
]]
local function removeJobKeys(jobKey)
  return rcall("DEL", jobKey, jobKey .. ':logs', jobKey .. ':dependencies',
    jobKey .. ':processed', jobKey .. ':failed', jobKey .. ':unsuccessful')
end
--[[
  Check if this job has a parent. If so we will just remove it from
  the parent child list, but if it is the last child we should move the parent to "wait/paused"
  which requires code from "moveToFinished"
]]
-- Includes
--[[
  Functions to destructure job key.
  Just a bit of warning, these functions may be a bit slow and affect performance significantly.
]]
local getJobIdFromKey = function (jobKey)
  return string.match(jobKey, ".*:(.*)")
end
local getJobKeyPrefix = function (jobKey, jobId)
  return string.sub(jobKey, 0, #jobKey - #jobId)
end
local function _moveParentToWait(parentPrefix, parentId, emitEvent)
  local parentTarget, isPausedOrMaxed = getTargetQueueList(parentPrefix .. "meta", parentPrefix .. "active",
    parentPrefix .. "wait", parentPrefix .. "paused")
  addJobInTargetList(parentTarget, parentPrefix .. "marker", "RPUSH", isPausedOrMaxed, parentId)
  if emitEvent then
    local parentEventStream = parentPrefix .. "events"
    rcall("XADD", parentEventStream, "*", "event", "waiting", "jobId", parentId, "prev", "waiting-children")
  end
end
local function removeParentDependencyKey(jobKey, hard, parentKey, baseKey, debounceId)
  if parentKey then
    local parentDependenciesKey = parentKey .. ":dependencies"
    local result = rcall("SREM", parentDependenciesKey, jobKey)
    if result > 0 then
      local pendingDependencies = rcall("SCARD", parentDependenciesKey)
      if pendingDependencies == 0 then
        local parentId = getJobIdFromKey(parentKey)
        local parentPrefix = getJobKeyPrefix(parentKey, parentId)
        local numRemovedElements = rcall("ZREM", parentPrefix .. "waiting-children", parentId)
        if numRemovedElements == 1 then
          if hard then -- remove parent in same queue
            if parentPrefix == baseKey then
              removeParentDependencyKey(parentKey, hard, nil, baseKey, nil)
              removeJobKeys(parentKey)
              if debounceId then
                rcall("DEL", parentPrefix .. "de:" .. debounceId)
              end
            else
              _moveParentToWait(parentPrefix, parentId)
            end
          else
            _moveParentToWait(parentPrefix, parentId, true)
          end
        end
      end
      return true
    end
  else
    local parentAttributes = rcall("HMGET", jobKey, "parentKey", "deid")
    local missedParentKey = parentAttributes[1]
    if( (type(missedParentKey) == "string") and missedParentKey ~= ""
      and (rcall("EXISTS", missedParentKey) == 1)) then
      local parentDependenciesKey = missedParentKey .. ":dependencies"
      local result = rcall("SREM", parentDependenciesKey, jobKey)
      if result > 0 then
        local pendingDependencies = rcall("SCARD", parentDependenciesKey)
        if pendingDependencies == 0 then
          local parentId = getJobIdFromKey(missedParentKey)
          local parentPrefix = getJobKeyPrefix(missedParentKey, parentId)
          local numRemovedElements = rcall("ZREM", parentPrefix .. "waiting-children", parentId)
          if numRemovedElements == 1 then
            if hard then
              if parentPrefix == baseKey then
                removeParentDependencyKey(missedParentKey, hard, nil, baseKey, nil)
                removeJobKeys(missedParentKey)
                if parentAttributes[2] then
                  rcall("DEL", parentPrefix .. "de:" .. parentAttributes[2])
                end
              else
                _moveParentToWait(parentPrefix, parentId)
              end
            else
              _moveParentToWait(parentPrefix, parentId, true)
            end
          end
        end
        return true
      end
    end
  end
  return false
end
local function removeJob(jobId, hard, baseKey, shouldRemoveDeduplicationKey)
  local jobKey = baseKey .. jobId
  removeParentDependencyKey(jobKey, hard, nil, baseKey)
  if shouldRemoveDeduplicationKey then
    removeDeduplicationKeyIfNeededOnRemoval(baseKey, jobKey, jobId)
  end
  removeJobKeys(jobKey)
end
--[[
  Function to store a job scheduler
]]
local function storeJobScheduler(schedulerId, schedulerKey, repeatKey, nextMillis, opts,
  templateData, templateOpts)
  rcall("ZADD", repeatKey, nextMillis, schedulerId)
  local optionalValues = {}
  if opts['tz'] then
    table.insert(optionalValues, "tz")
    table.insert(optionalValues, opts['tz'])
  end
  if opts['limit'] then
    table.insert(optionalValues, "limit")
    table.insert(optionalValues, opts['limit'])
  end
  if opts['pattern'] then
    table.insert(optionalValues, "pattern")
    table.insert(optionalValues, opts['pattern'])
  end
  if opts['startDate'] then
    table.insert(optionalValues, "startDate")
    table.insert(optionalValues, opts['startDate'])
  end
  if opts['endDate'] then
    table.insert(optionalValues, "endDate")
    table.insert(optionalValues, opts['endDate'])
  end
  if opts['every'] then
    table.insert(optionalValues, "every")
    table.insert(optionalValues, opts['every'])
  end
  if opts['offset'] then
    table.insert(optionalValues, "offset")
    table.insert(optionalValues, opts['offset'])
  else
    local offset = rcall("HGET", schedulerKey, "offset")
    if offset then
      table.insert(optionalValues, "offset")
      table.insert(optionalValues, tonumber(offset))
    end
  end
  local jsonTemplateOpts = cjson.encode(templateOpts)
  if jsonTemplateOpts and jsonTemplateOpts ~= '{}' then
    table.insert(optionalValues, "opts")
    table.insert(optionalValues, jsonTemplateOpts)
  end
  if templateData and templateData ~= '{}' then
    table.insert(optionalValues, "data")
    table.insert(optionalValues, templateData)
  end
  table.insert(optionalValues, "ic")
  table.insert(optionalValues, rcall("HGET", schedulerKey, "ic") or 1)
  rcall("DEL", schedulerKey) -- remove all attributes and then re-insert new ones
  rcall("HMSET", schedulerKey, "name", opts['name'], unpack(optionalValues))
end
local function getJobSchedulerEveryNextMillis(prevMillis, every, now, offset, startDate)
    local nextMillis
    if not prevMillis then
        if startDate then
            -- Assuming startDate is passed as milliseconds from JavaScript
            nextMillis = tonumber(startDate)
            nextMillis = nextMillis > now and nextMillis or now
        else
            nextMillis = now
        end
    else
        nextMillis = prevMillis + every
        -- check if we may have missed some iterations
        if nextMillis < now then
            nextMillis = math.floor(now / every) * every + every + (offset or 0)
        end
    end
    if not offset or offset == 0 then
        local timeSlot = math.floor(nextMillis / every) * every;
        offset = nextMillis - timeSlot;
    end
    -- Return a tuple nextMillis, offset
    return math.floor(nextMillis), math.floor(offset)
end
-- If we are overriding a repeatable job we must delete the delayed job for
-- the next iteration.
local schedulerKey = repeatKey .. ":" .. jobSchedulerId
local maxEvents = getOrSetMaxEvents(metaKey)
local templateData = ARGV[4]
local prevMillis = rcall("ZSCORE", repeatKey, jobSchedulerId)
if prevMillis then
    prevMillis = tonumber(prevMillis)
end
local schedulerOpts = cmsgpack.unpack(ARGV[2])
local every = schedulerOpts['every']
-- For backwards compatibility we also check the offset from the job itself.
-- could be removed in future major versions.
local jobOffset = jobOpts['repeat'] and jobOpts['repeat']['offset'] or 0
local offset = schedulerOpts['offset'] or jobOffset or 0
local newOffset = offset
local updatedEvery = false
if every then
    -- if we changed the 'every' value we need to reset millis to nil
    local millis = prevMillis
    if prevMillis then
        local prevEvery = tonumber(rcall("HGET", schedulerKey, "every"))
        if prevEvery ~= every then
            millis = nil
            updatedEvery = true
        end
    end
    local startDate = schedulerOpts['startDate']
    nextMillis, newOffset = getJobSchedulerEveryNextMillis(millis, every, now, offset, startDate)
end
local function removeJobFromScheduler(prefixKey, delayedKey, prioritizedKey, waitKey, pausedKey, jobId, metaKey,
    eventsKey)
    if rcall("ZSCORE", delayedKey, jobId) then
        removeJob(jobId, true, prefixKey, true --[[remove debounce key]] )
        rcall("ZREM", delayedKey, jobId)
        return true
    elseif rcall("ZSCORE", prioritizedKey, jobId) then
        removeJob(jobId, true, prefixKey, true --[[remove debounce key]] )
        rcall("ZREM", prioritizedKey, jobId)
        return true
    else
        local pausedOrWaitKey = waitKey
        if isQueuePaused(metaKey) then
            pausedOrWaitKey = pausedKey
        end
        if rcall("LREM", pausedOrWaitKey, 1, jobId) > 0 then
            removeJob(jobId, true, prefixKey, true --[[remove debounce key]] )
            return true
        end
    end
    return false
end
local removedPrevJob = false
if prevMillis then
    local currentJobId = "repeat:" .. jobSchedulerId .. ":" .. prevMillis
    local currentJobKey = schedulerKey .. ":" .. prevMillis
    -- In theory it should always exist the currentJobKey if there is a prevMillis unless something has
    -- gone really wrong.
    if rcall("EXISTS", currentJobKey) == 1 then
        removedPrevJob = removeJobFromScheduler(prefixKey, delayedKey, prioritizedKey, waitKey, pausedKey, currentJobId,
            metaKey, eventsKey)
    end
end
if removedPrevJob then
    -- The jobs has been removed and we want to replace it, so lets use the same millis.
    if every and not updatedEvery then
        nextMillis = prevMillis
    end
else
    -- Special case where no job was removed, and we need to add the next iteration.
    schedulerOpts['offset'] = newOffset
end
-- Check for job ID collision with existing jobs (in any state)
local jobId = "repeat:" .. jobSchedulerId .. ":" .. nextMillis
local jobKey = prefixKey .. jobId
-- If there's already a job with this ID, in a state 
-- that is not updatable (active, completed, failed) we must 
-- handle the collision
local hasCollision = false
if rcall("EXISTS", jobKey) == 1 then
    if every then
        -- For 'every' case: try next time slot to avoid collision
        local nextSlotMillis = nextMillis + every
        local nextSlotJobId = "repeat:" .. jobSchedulerId .. ":" .. nextSlotMillis
        local nextSlotJobKey = prefixKey .. nextSlotJobId
        if rcall("EXISTS", nextSlotJobKey) == 0 then
            -- Next slot is free, use it
            nextMillis = nextSlotMillis
            jobId = nextSlotJobId
        else
            -- Next slot also has a job, return error code
            return -11 -- SchedulerJobSlotsBusy
        end
    else
        hasCollision = true
    end
end
local delay = nextMillis - now
-- Fast Clamp delay to minimum of 0
if delay < 0 then
    delay = 0
end
local nextJobKey = schedulerKey .. ":" .. nextMillis
if not hasCollision or removedPrevJob then
    -- jobId already calculated above during collision check
    storeJobScheduler(jobSchedulerId, schedulerKey, repeatKey, nextMillis, schedulerOpts, templateData, templateOpts)
    rcall("INCR", KEYS[8])
    addJobFromScheduler(nextJobKey, jobId, jobOpts, waitKey, pausedKey, KEYS[11], metaKey, prioritizedKey, KEYS[10],
        delayedKey, KEYS[7], eventsKey, schedulerOpts['name'], maxEvents, now, templateData, jobSchedulerId, delay)
elseif hasCollision then
    -- For 'pattern' case: return error code
    return -10 -- SchedulerJobIdCollision
end
if ARGV[9] ~= "" then
    rcall("HSET", ARGV[9], "nrjid", jobId)
end
return {jobId .. "", delay}
`;
const addJobScheduler = {
    name: 'addJobScheduler',
    content,
    keys: 11
}; //# sourceMappingURL=addJobScheduler-11.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/addLog-2.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "addLog",
    ()=>addLog
]);
const content = `--[[
  Add job log
  Input:
    KEYS[1] job id key
    KEYS[2] job logs key
    ARGV[1] id
    ARGV[2] log
    ARGV[3] keepLogs
  Output:
    -1 - Missing job.
]]
local rcall = redis.call
if rcall("EXISTS", KEYS[1]) == 1 then -- // Make sure job exists
  local logCount = rcall("RPUSH", KEYS[2], ARGV[2])
  if ARGV[3] ~= '' then
    local keepLogs = tonumber(ARGV[3])
    rcall("LTRIM", KEYS[2], -keepLogs, -1)
    return math.min(keepLogs, logCount)
  end
  return logCount
else
  return -1
end
`;
const addLog = {
    name: 'addLog',
    content,
    keys: 2
}; //# sourceMappingURL=addLog-2.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/addParentJob-6.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "addParentJob",
    ()=>addParentJob
]);
const content = `--[[
  Adds a parent job to the queue by doing the following:
    - Increases the job counter if needed.
    - Creates a new job key with the job data.
    - adds the job to the waiting-children zset
    Input:
      KEYS[1] 'meta'
      KEYS[2] 'id'
      KEYS[3] 'delayed'
      KEYS[4] 'waiting-children'
      KEYS[5] 'completed'
      KEYS[6] events stream key
      ARGV[1] msgpacked arguments array
            [1]  key prefix,
            [2]  custom id (will not generate one automatically)
            [3]  name
            [4]  timestamp
            [5]  parentKey?
            [6]  parent dependencies key.
            [7]  parent? {id, queueKey}
            [8]  repeat job key
            [9] deduplication key
      ARGV[2] Json stringified job data
      ARGV[3] msgpacked options
      Output:
        jobId  - OK
        -5     - Missing parent key
]]
local metaKey = KEYS[1]
local idKey = KEYS[2]
local completedKey = KEYS[5]
local eventsKey = KEYS[6]
local jobId
local jobIdKey
local rcall = redis.call
local args = cmsgpack.unpack(ARGV[1])
local data = ARGV[2]
local opts = cmsgpack.unpack(ARGV[3])
local parentKey = args[5]
local parent = args[7]
local repeatJobKey = args[8]
local deduplicationKey = args[9]
local parentData
-- Includes
--[[
  Function to debounce a job.
]]
-- Includes
--[[
  Function to remove job keys.
]]
local function removeJobKeys(jobKey)
  return rcall("DEL", jobKey, jobKey .. ':logs', jobKey .. ':dependencies',
    jobKey .. ':processed', jobKey .. ':failed', jobKey .. ':unsuccessful')
end
local function removeDelayedJob(delayedKey, deduplicationKey, eventsKey, maxEvents, currentDeduplicatedJobId,
    jobId, deduplicationId, prefix)
    if rcall("ZREM", delayedKey, currentDeduplicatedJobId) > 0 then
        removeJobKeys(prefix .. currentDeduplicatedJobId)
        rcall("XADD", eventsKey, "*", "event", "removed", "jobId", currentDeduplicatedJobId,
            "prev", "delayed")
        -- TODO remove debounced event in next breaking change
        rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "debounced", "jobId",
            jobId, "debounceId", deduplicationId)
        rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "deduplicated", "jobId",
            jobId, "deduplicationId", deduplicationId, "deduplicatedJobId", currentDeduplicatedJobId)
        return true
    end
    return false
end
local function deduplicateJob(deduplicationOpts, jobId, delayedKey, deduplicationKey, eventsKey, maxEvents,
    prefix)
    local deduplicationId = deduplicationOpts and deduplicationOpts['id']
    if deduplicationId then
        local ttl = deduplicationOpts['ttl']
        if deduplicationOpts['replace'] then
            if ttl and ttl > 0 then
                local currentDebounceJobId = rcall('GET', deduplicationKey)
                if currentDebounceJobId then
                    local isRemoved = removeDelayedJob(delayedKey, deduplicationKey, eventsKey, maxEvents,
                        currentDebounceJobId, jobId, deduplicationId, prefix)
                    if isRemoved then
                        if deduplicationOpts['extend'] then
                            rcall('SET', deduplicationKey, jobId, 'PX', ttl)
                        else
                            rcall('SET', deduplicationKey, jobId, 'KEEPTTL')
                        end
                        return
                    else
                        return currentDebounceJobId
                    end
                else
                    rcall('SET', deduplicationKey, jobId, 'PX', ttl)
                    return
                end
            else
                local currentDebounceJobId = rcall('GET', deduplicationKey)
                if currentDebounceJobId then
                    local isRemoved = removeDelayedJob(delayedKey, deduplicationKey, eventsKey, maxEvents,
                        currentDebounceJobId, jobId, deduplicationId, prefix)
                    if isRemoved then
                        rcall('SET', deduplicationKey, jobId)
                        return
                    else
                        return currentDebounceJobId
                    end
                else
                    rcall('SET', deduplicationKey, jobId)
                    return
                end
            end
        else
            local deduplicationKeyExists
            if ttl and ttl > 0 then
                if deduplicationOpts['extend'] then
                    local currentDebounceJobId = rcall('GET', deduplicationKey)
                    if currentDebounceJobId then
                        rcall('SET', deduplicationKey, currentDebounceJobId, 'PX', ttl)
                        rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "debounced",
                            "jobId", currentDebounceJobId, "debounceId", deduplicationId)
                        rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "deduplicated", "jobId",
                            currentDebounceJobId, "deduplicationId", deduplicationId, "deduplicatedJobId", jobId)
                        return currentDebounceJobId
                    else
                        rcall('SET', deduplicationKey, jobId, 'PX', ttl)
                        return
                    end
                else
                    deduplicationKeyExists = not rcall('SET', deduplicationKey, jobId, 'PX', ttl, 'NX')
                end
            else
                deduplicationKeyExists = not rcall('SET', deduplicationKey, jobId, 'NX')
            end
            if deduplicationKeyExists then
                local currentDebounceJobId = rcall('GET', deduplicationKey)
                -- TODO remove debounced event in next breaking change
                rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "debounced", "jobId",
                    currentDebounceJobId, "debounceId", deduplicationId)
                rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "deduplicated", "jobId",
                    currentDebounceJobId, "deduplicationId", deduplicationId, "deduplicatedJobId", jobId)
                return currentDebounceJobId
            end
        end
    end
end
--[[
  Function to get max events value or set by default 10000.
]]
local function getOrSetMaxEvents(metaKey)
  local maxEvents = rcall("HGET", metaKey, "opts.maxLenEvents")
  if not maxEvents then
    maxEvents = 10000
    rcall("HSET", metaKey, "opts.maxLenEvents", maxEvents)
  end
  return maxEvents
end
--[[
  Function to handle the case when job is duplicated.
]]
-- Includes
--[[
    This function is used to update the parent's dependencies if the job
    is already completed and about to be ignored. The parent must get its
    dependencies updated to avoid the parent job being stuck forever in 
    the waiting-children state.
]]
-- Includes
--[[
  Validate and move or add dependencies to parent.
]]
-- Includes
--[[
  Validate and move parent to a wait status (waiting, delayed or prioritized)
  if no pending dependencies.
]]
-- Includes
--[[
  Validate and move parent to a wait status (waiting, delayed or prioritized) if needed.
]]
-- Includes
--[[
  Move parent to a wait status (wait, prioritized or delayed)
]]
-- Includes
--[[
  Add delay marker if needed.
]]
-- Includes
--[[
  Function to return the next delayed job timestamp.
]]
local function getNextDelayedTimestamp(delayedKey)
  local result = rcall("ZRANGE", delayedKey, 0, 0, "WITHSCORES")
  if #result then
    local nextTimestamp = tonumber(result[2])
    if nextTimestamp ~= nil then
      return nextTimestamp / 0x1000
    end
  end
end
local function addDelayMarkerIfNeeded(markerKey, delayedKey)
  local nextTimestamp = getNextDelayedTimestamp(delayedKey)
  if nextTimestamp ~= nil then
    -- Replace the score of the marker with the newest known
    -- next timestamp.
    rcall("ZADD", markerKey, nextTimestamp, "1")
  end
end
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to add job considering priority.
]]
-- Includes
--[[
  Function to get priority score.
]]
local function getPriorityScore(priority, priorityCounterKey)
  local prioCounter = rcall("INCR", priorityCounterKey)
  return priority * 0x100000000 + prioCounter % 0x100000000
end
local function addJobWithPriority(markerKey, prioritizedKey, priority, jobId, priorityCounterKey,
  isPausedOrMaxed)
  local score = getPriorityScore(priority, priorityCounterKey)
  rcall("ZADD", prioritizedKey, score, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to check if queue is paused or maxed
  (since an empty list and !EXISTS are not really the same).
]]
local function isQueuePausedOrMaxed(queueMetaKey, activeKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency")
  if queueAttributes[1] then
    return true
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      return activeCount >= tonumber(queueAttributes[2])
    end
  end
  return false
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
local function moveParentToWait(parentQueueKey, parentKey, parentId, timestamp)
    local parentWaitKey = parentQueueKey .. ":wait"
    local parentPausedKey = parentQueueKey .. ":paused"
    local parentActiveKey = parentQueueKey .. ":active"
    local parentMetaKey = parentQueueKey .. ":meta"
    local parentMarkerKey = parentQueueKey .. ":marker"
    local jobAttributes = rcall("HMGET", parentKey, "priority", "delay")
    local priority = tonumber(jobAttributes[1]) or 0
    local delay = tonumber(jobAttributes[2]) or 0
    if delay > 0 then
        local delayedTimestamp = tonumber(timestamp) + delay
        local score = delayedTimestamp * 0x1000
        local parentDelayedKey = parentQueueKey .. ":delayed"
        rcall("ZADD", parentDelayedKey, score, parentId)
        rcall("XADD", parentQueueKey .. ":events", "*", "event", "delayed", "jobId", parentId, "delay",
            delayedTimestamp)
        addDelayMarkerIfNeeded(parentMarkerKey, parentDelayedKey)
    else
        if priority == 0 then
            local parentTarget, isParentPausedOrMaxed = getTargetQueueList(parentMetaKey, parentActiveKey,
                parentWaitKey, parentPausedKey)
            addJobInTargetList(parentTarget, parentMarkerKey, "RPUSH", isParentPausedOrMaxed, parentId)
        else
            local isPausedOrMaxed = isQueuePausedOrMaxed(parentMetaKey, parentActiveKey)
            addJobWithPriority(parentMarkerKey, parentQueueKey .. ":prioritized", priority, parentId,
                parentQueueKey .. ":pc", isPausedOrMaxed)
        end
        rcall("XADD", parentQueueKey .. ":events", "*", "event", "waiting", "jobId", parentId, "prev",
            "waiting-children")
    end
end
local function moveParentToWaitIfNeeded(parentQueueKey, parentKey, parentId, timestamp)
  if rcall("EXISTS", parentKey) == 1 then
    local parentWaitingChildrenKey = parentQueueKey .. ":waiting-children"
    if rcall("ZSCORE", parentWaitingChildrenKey, parentId) then    
      rcall("ZREM", parentWaitingChildrenKey, parentId)
      moveParentToWait(parentQueueKey, parentKey, parentId, timestamp)
    end
  end
end
local function moveParentToWaitIfNoPendingDependencies(parentQueueKey, parentDependenciesKey, parentKey,
  parentId, timestamp)
  local doNotHavePendingDependencies = rcall("SCARD", parentDependenciesKey) == 0
  if doNotHavePendingDependencies then
    moveParentToWaitIfNeeded(parentQueueKey, parentKey, parentId, timestamp)
  end
end
local function updateParentDepsIfNeeded(parentKey, parentQueueKey, parentDependenciesKey,
  parentId, jobIdKey, returnvalue, timestamp )
  local processedSet = parentKey .. ":processed"
  rcall("HSET", processedSet, jobIdKey, returnvalue)
  moveParentToWaitIfNoPendingDependencies(parentQueueKey, parentDependenciesKey, parentKey, parentId, timestamp)
end
local function updateExistingJobsParent(parentKey, parent, parentData,
                                        parentDependenciesKey, completedKey,
                                        jobIdKey, jobId, timestamp)
    if parentKey ~= nil then
        if rcall("ZSCORE", completedKey, jobId) then
            local returnvalue = rcall("HGET", jobIdKey, "returnvalue")
            updateParentDepsIfNeeded(parentKey, parent['queueKey'],
                                     parentDependenciesKey, parent['id'],
                                     jobIdKey, returnvalue, timestamp)
        else
            if parentDependenciesKey ~= nil then
                rcall("SADD", parentDependenciesKey, jobIdKey)
            end
        end
        rcall("HMSET", jobIdKey, "parentKey", parentKey, "parent", parentData)
    end
end
local function handleDuplicatedJob(jobKey, jobId, currentParentKey, currentParent,
  parentData, parentDependenciesKey, completedKey, eventsKey, maxEvents, timestamp)
  local existedParentKey = rcall("HGET", jobKey, "parentKey")
  if not existedParentKey or existedParentKey == currentParentKey then
    updateExistingJobsParent(currentParentKey, currentParent, parentData,
      parentDependenciesKey, completedKey, jobKey,
      jobId, timestamp)
  else
    if currentParentKey ~= nil and currentParentKey ~= existedParentKey
      and (rcall("EXISTS", existedParentKey) == 1) then
      return -7
    end
  end
  rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event",
    "duplicated", "jobId", jobId)
  return jobId .. "" -- convert to string
end
--[[
  Function to store a job
]]
local function storeJob(eventsKey, jobIdKey, jobId, name, data, opts, timestamp,
                        parentKey, parentData, repeatJobKey)
    local jsonOpts = cjson.encode(opts)
    local delay = opts['delay'] or 0
    local priority = opts['priority'] or 0
    local debounceId = opts['de'] and opts['de']['id']
    local optionalValues = {}
    if parentKey ~= nil then
        table.insert(optionalValues, "parentKey")
        table.insert(optionalValues, parentKey)
        table.insert(optionalValues, "parent")
        table.insert(optionalValues, parentData)
    end
    if repeatJobKey then
        table.insert(optionalValues, "rjk")
        table.insert(optionalValues, repeatJobKey)
    end
    if debounceId then
        table.insert(optionalValues, "deid")
        table.insert(optionalValues, debounceId)
    end
    rcall("HMSET", jobIdKey, "name", name, "data", data, "opts", jsonOpts,
          "timestamp", timestamp, "delay", delay, "priority", priority,
          unpack(optionalValues))
    rcall("XADD", eventsKey, "*", "event", "added", "jobId", jobId, "name", name)
    return delay, priority
end
if parentKey ~= nil then
    if rcall("EXISTS", parentKey) ~= 1 then return -5 end
    parentData = cjson.encode(parent)
end
local jobCounter = rcall("INCR", idKey)
local maxEvents = getOrSetMaxEvents(metaKey)
local parentDependenciesKey = args[6]
local timestamp = args[4]
if args[2] == "" then
    jobId = jobCounter
    jobIdKey = args[1] .. jobId
else
    jobId = args[2]
    jobIdKey = args[1] .. jobId
    if rcall("EXISTS", jobIdKey) == 1 then
        return handleDuplicatedJob(jobIdKey, jobId, parentKey, parent,
            parentData, parentDependenciesKey, completedKey, eventsKey,
            maxEvents, timestamp)
    end
end
local deduplicationJobId = deduplicateJob(opts['de'], jobId, KEYS[3],
  deduplicationKey, eventsKey, maxEvents, args[1])
if deduplicationJobId then
  return deduplicationJobId
end
-- Store the job.
storeJob(eventsKey, jobIdKey, jobId, args[3], ARGV[2], opts, timestamp,
         parentKey, parentData, repeatJobKey)
local waitChildrenKey = KEYS[4]
rcall("ZADD", waitChildrenKey, timestamp, jobId)
rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event",
      "waiting-children", "jobId", jobId)
-- Check if this job is a child of another job, if so add it to the parents dependencies
if parentDependenciesKey ~= nil then
    rcall("SADD", parentDependenciesKey, jobIdKey)
end
return jobId .. "" -- convert to string
`;
const addParentJob = {
    name: 'addParentJob',
    content,
    keys: 6
}; //# sourceMappingURL=addParentJob-6.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/addPrioritizedJob-9.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "addPrioritizedJob",
    ()=>addPrioritizedJob
]);
const content = `--[[
  Adds a priotitized job to the queue by doing the following:
    - Increases the job counter if needed.
    - Creates a new job key with the job data.
    - Adds the job to the "added" list so that workers gets notified.
    Input:
      KEYS[1] 'marker',
      KEYS[2] 'meta'
      KEYS[3] 'id'
      KEYS[4] 'prioritized'
      KEYS[5] 'delayed'
      KEYS[6] 'completed'
      KEYS[7] 'active'
      KEYS[8] events stream key
      KEYS[9] 'pc' priority counter
      ARGV[1] msgpacked arguments array
            [1]  key prefix,
            [2]  custom id (will not generate one automatically)
            [3]  name
            [4]  timestamp
            [5]  parentKey?
            [6]  parent dependencies key.
            [7]  parent? {id, queueKey}
            [8]  repeat job key
            [9] deduplication key
      ARGV[2] Json stringified job data
      ARGV[3] msgpacked options
      Output:
        jobId  - OK
        -5     - Missing parent key
]] 
local metaKey = KEYS[2]
local idKey = KEYS[3]
local priorityKey = KEYS[4]
local completedKey = KEYS[6]
local activeKey = KEYS[7]
local eventsKey = KEYS[8]
local priorityCounterKey = KEYS[9]
local jobId
local jobIdKey
local rcall = redis.call
local args = cmsgpack.unpack(ARGV[1])
local data = ARGV[2]
local opts = cmsgpack.unpack(ARGV[3])
local parentKey = args[5]
local parent = args[7]
local repeatJobKey = args[8]
local deduplicationKey = args[9]
local parentData
-- Includes
--[[
  Function to add job considering priority.
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
--[[
  Function to get priority score.
]]
local function getPriorityScore(priority, priorityCounterKey)
  local prioCounter = rcall("INCR", priorityCounterKey)
  return priority * 0x100000000 + prioCounter % 0x100000000
end
local function addJobWithPriority(markerKey, prioritizedKey, priority, jobId, priorityCounterKey,
  isPausedOrMaxed)
  local score = getPriorityScore(priority, priorityCounterKey)
  rcall("ZADD", prioritizedKey, score, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to debounce a job.
]]
-- Includes
--[[
  Function to remove job keys.
]]
local function removeJobKeys(jobKey)
  return rcall("DEL", jobKey, jobKey .. ':logs', jobKey .. ':dependencies',
    jobKey .. ':processed', jobKey .. ':failed', jobKey .. ':unsuccessful')
end
local function removeDelayedJob(delayedKey, deduplicationKey, eventsKey, maxEvents, currentDeduplicatedJobId,
    jobId, deduplicationId, prefix)
    if rcall("ZREM", delayedKey, currentDeduplicatedJobId) > 0 then
        removeJobKeys(prefix .. currentDeduplicatedJobId)
        rcall("XADD", eventsKey, "*", "event", "removed", "jobId", currentDeduplicatedJobId,
            "prev", "delayed")
        -- TODO remove debounced event in next breaking change
        rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "debounced", "jobId",
            jobId, "debounceId", deduplicationId)
        rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "deduplicated", "jobId",
            jobId, "deduplicationId", deduplicationId, "deduplicatedJobId", currentDeduplicatedJobId)
        return true
    end
    return false
end
local function deduplicateJob(deduplicationOpts, jobId, delayedKey, deduplicationKey, eventsKey, maxEvents,
    prefix)
    local deduplicationId = deduplicationOpts and deduplicationOpts['id']
    if deduplicationId then
        local ttl = deduplicationOpts['ttl']
        if deduplicationOpts['replace'] then
            if ttl and ttl > 0 then
                local currentDebounceJobId = rcall('GET', deduplicationKey)
                if currentDebounceJobId then
                    local isRemoved = removeDelayedJob(delayedKey, deduplicationKey, eventsKey, maxEvents,
                        currentDebounceJobId, jobId, deduplicationId, prefix)
                    if isRemoved then
                        if deduplicationOpts['extend'] then
                            rcall('SET', deduplicationKey, jobId, 'PX', ttl)
                        else
                            rcall('SET', deduplicationKey, jobId, 'KEEPTTL')
                        end
                        return
                    else
                        return currentDebounceJobId
                    end
                else
                    rcall('SET', deduplicationKey, jobId, 'PX', ttl)
                    return
                end
            else
                local currentDebounceJobId = rcall('GET', deduplicationKey)
                if currentDebounceJobId then
                    local isRemoved = removeDelayedJob(delayedKey, deduplicationKey, eventsKey, maxEvents,
                        currentDebounceJobId, jobId, deduplicationId, prefix)
                    if isRemoved then
                        rcall('SET', deduplicationKey, jobId)
                        return
                    else
                        return currentDebounceJobId
                    end
                else
                    rcall('SET', deduplicationKey, jobId)
                    return
                end
            end
        else
            local deduplicationKeyExists
            if ttl and ttl > 0 then
                if deduplicationOpts['extend'] then
                    local currentDebounceJobId = rcall('GET', deduplicationKey)
                    if currentDebounceJobId then
                        rcall('SET', deduplicationKey, currentDebounceJobId, 'PX', ttl)
                        rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "debounced",
                            "jobId", currentDebounceJobId, "debounceId", deduplicationId)
                        rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "deduplicated", "jobId",
                            currentDebounceJobId, "deduplicationId", deduplicationId, "deduplicatedJobId", jobId)
                        return currentDebounceJobId
                    else
                        rcall('SET', deduplicationKey, jobId, 'PX', ttl)
                        return
                    end
                else
                    deduplicationKeyExists = not rcall('SET', deduplicationKey, jobId, 'PX', ttl, 'NX')
                end
            else
                deduplicationKeyExists = not rcall('SET', deduplicationKey, jobId, 'NX')
            end
            if deduplicationKeyExists then
                local currentDebounceJobId = rcall('GET', deduplicationKey)
                -- TODO remove debounced event in next breaking change
                rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "debounced", "jobId",
                    currentDebounceJobId, "debounceId", deduplicationId)
                rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "deduplicated", "jobId",
                    currentDebounceJobId, "deduplicationId", deduplicationId, "deduplicatedJobId", jobId)
                return currentDebounceJobId
            end
        end
    end
end
--[[
  Function to store a job
]]
local function storeJob(eventsKey, jobIdKey, jobId, name, data, opts, timestamp,
                        parentKey, parentData, repeatJobKey)
    local jsonOpts = cjson.encode(opts)
    local delay = opts['delay'] or 0
    local priority = opts['priority'] or 0
    local debounceId = opts['de'] and opts['de']['id']
    local optionalValues = {}
    if parentKey ~= nil then
        table.insert(optionalValues, "parentKey")
        table.insert(optionalValues, parentKey)
        table.insert(optionalValues, "parent")
        table.insert(optionalValues, parentData)
    end
    if repeatJobKey then
        table.insert(optionalValues, "rjk")
        table.insert(optionalValues, repeatJobKey)
    end
    if debounceId then
        table.insert(optionalValues, "deid")
        table.insert(optionalValues, debounceId)
    end
    rcall("HMSET", jobIdKey, "name", name, "data", data, "opts", jsonOpts,
          "timestamp", timestamp, "delay", delay, "priority", priority,
          unpack(optionalValues))
    rcall("XADD", eventsKey, "*", "event", "added", "jobId", jobId, "name", name)
    return delay, priority
end
--[[
  Function to get max events value or set by default 10000.
]]
local function getOrSetMaxEvents(metaKey)
  local maxEvents = rcall("HGET", metaKey, "opts.maxLenEvents")
  if not maxEvents then
    maxEvents = 10000
    rcall("HSET", metaKey, "opts.maxLenEvents", maxEvents)
  end
  return maxEvents
end
--[[
  Function to handle the case when job is duplicated.
]]
-- Includes
--[[
    This function is used to update the parent's dependencies if the job
    is already completed and about to be ignored. The parent must get its
    dependencies updated to avoid the parent job being stuck forever in 
    the waiting-children state.
]]
-- Includes
--[[
  Validate and move or add dependencies to parent.
]]
-- Includes
--[[
  Validate and move parent to a wait status (waiting, delayed or prioritized)
  if no pending dependencies.
]]
-- Includes
--[[
  Validate and move parent to a wait status (waiting, delayed or prioritized) if needed.
]]
-- Includes
--[[
  Move parent to a wait status (wait, prioritized or delayed)
]]
-- Includes
--[[
  Add delay marker if needed.
]]
-- Includes
--[[
  Function to return the next delayed job timestamp.
]]
local function getNextDelayedTimestamp(delayedKey)
  local result = rcall("ZRANGE", delayedKey, 0, 0, "WITHSCORES")
  if #result then
    local nextTimestamp = tonumber(result[2])
    if nextTimestamp ~= nil then
      return nextTimestamp / 0x1000
    end
  end
end
local function addDelayMarkerIfNeeded(markerKey, delayedKey)
  local nextTimestamp = getNextDelayedTimestamp(delayedKey)
  if nextTimestamp ~= nil then
    -- Replace the score of the marker with the newest known
    -- next timestamp.
    rcall("ZADD", markerKey, nextTimestamp, "1")
  end
end
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to check if queue is paused or maxed
  (since an empty list and !EXISTS are not really the same).
]]
local function isQueuePausedOrMaxed(queueMetaKey, activeKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency")
  if queueAttributes[1] then
    return true
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      return activeCount >= tonumber(queueAttributes[2])
    end
  end
  return false
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
local function moveParentToWait(parentQueueKey, parentKey, parentId, timestamp)
    local parentWaitKey = parentQueueKey .. ":wait"
    local parentPausedKey = parentQueueKey .. ":paused"
    local parentActiveKey = parentQueueKey .. ":active"
    local parentMetaKey = parentQueueKey .. ":meta"
    local parentMarkerKey = parentQueueKey .. ":marker"
    local jobAttributes = rcall("HMGET", parentKey, "priority", "delay")
    local priority = tonumber(jobAttributes[1]) or 0
    local delay = tonumber(jobAttributes[2]) or 0
    if delay > 0 then
        local delayedTimestamp = tonumber(timestamp) + delay
        local score = delayedTimestamp * 0x1000
        local parentDelayedKey = parentQueueKey .. ":delayed"
        rcall("ZADD", parentDelayedKey, score, parentId)
        rcall("XADD", parentQueueKey .. ":events", "*", "event", "delayed", "jobId", parentId, "delay",
            delayedTimestamp)
        addDelayMarkerIfNeeded(parentMarkerKey, parentDelayedKey)
    else
        if priority == 0 then
            local parentTarget, isParentPausedOrMaxed = getTargetQueueList(parentMetaKey, parentActiveKey,
                parentWaitKey, parentPausedKey)
            addJobInTargetList(parentTarget, parentMarkerKey, "RPUSH", isParentPausedOrMaxed, parentId)
        else
            local isPausedOrMaxed = isQueuePausedOrMaxed(parentMetaKey, parentActiveKey)
            addJobWithPriority(parentMarkerKey, parentQueueKey .. ":prioritized", priority, parentId,
                parentQueueKey .. ":pc", isPausedOrMaxed)
        end
        rcall("XADD", parentQueueKey .. ":events", "*", "event", "waiting", "jobId", parentId, "prev",
            "waiting-children")
    end
end
local function moveParentToWaitIfNeeded(parentQueueKey, parentKey, parentId, timestamp)
  if rcall("EXISTS", parentKey) == 1 then
    local parentWaitingChildrenKey = parentQueueKey .. ":waiting-children"
    if rcall("ZSCORE", parentWaitingChildrenKey, parentId) then    
      rcall("ZREM", parentWaitingChildrenKey, parentId)
      moveParentToWait(parentQueueKey, parentKey, parentId, timestamp)
    end
  end
end
local function moveParentToWaitIfNoPendingDependencies(parentQueueKey, parentDependenciesKey, parentKey,
  parentId, timestamp)
  local doNotHavePendingDependencies = rcall("SCARD", parentDependenciesKey) == 0
  if doNotHavePendingDependencies then
    moveParentToWaitIfNeeded(parentQueueKey, parentKey, parentId, timestamp)
  end
end
local function updateParentDepsIfNeeded(parentKey, parentQueueKey, parentDependenciesKey,
  parentId, jobIdKey, returnvalue, timestamp )
  local processedSet = parentKey .. ":processed"
  rcall("HSET", processedSet, jobIdKey, returnvalue)
  moveParentToWaitIfNoPendingDependencies(parentQueueKey, parentDependenciesKey, parentKey, parentId, timestamp)
end
local function updateExistingJobsParent(parentKey, parent, parentData,
                                        parentDependenciesKey, completedKey,
                                        jobIdKey, jobId, timestamp)
    if parentKey ~= nil then
        if rcall("ZSCORE", completedKey, jobId) then
            local returnvalue = rcall("HGET", jobIdKey, "returnvalue")
            updateParentDepsIfNeeded(parentKey, parent['queueKey'],
                                     parentDependenciesKey, parent['id'],
                                     jobIdKey, returnvalue, timestamp)
        else
            if parentDependenciesKey ~= nil then
                rcall("SADD", parentDependenciesKey, jobIdKey)
            end
        end
        rcall("HMSET", jobIdKey, "parentKey", parentKey, "parent", parentData)
    end
end
local function handleDuplicatedJob(jobKey, jobId, currentParentKey, currentParent,
  parentData, parentDependenciesKey, completedKey, eventsKey, maxEvents, timestamp)
  local existedParentKey = rcall("HGET", jobKey, "parentKey")
  if not existedParentKey or existedParentKey == currentParentKey then
    updateExistingJobsParent(currentParentKey, currentParent, parentData,
      parentDependenciesKey, completedKey, jobKey,
      jobId, timestamp)
  else
    if currentParentKey ~= nil and currentParentKey ~= existedParentKey
      and (rcall("EXISTS", existedParentKey) == 1) then
      return -7
    end
  end
  rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event",
    "duplicated", "jobId", jobId)
  return jobId .. "" -- convert to string
end
if parentKey ~= nil then
    if rcall("EXISTS", parentKey) ~= 1 then return -5 end
    parentData = cjson.encode(parent)
end
local jobCounter = rcall("INCR", idKey)
local maxEvents = getOrSetMaxEvents(metaKey)
local parentDependenciesKey = args[6]
local timestamp = args[4]
if args[2] == "" then
    jobId = jobCounter
    jobIdKey = args[1] .. jobId
else
    jobId = args[2]
    jobIdKey = args[1] .. jobId
    if rcall("EXISTS", jobIdKey) == 1 then
        return handleDuplicatedJob(jobIdKey, jobId, parentKey, parent,
            parentData, parentDependenciesKey, completedKey, eventsKey,
            maxEvents, timestamp)
    end
end
local deduplicationJobId = deduplicateJob(opts['de'], jobId, KEYS[5],
  deduplicationKey, eventsKey, maxEvents, args[1])
if deduplicationJobId then
  return deduplicationJobId
end
-- Store the job.
local delay, priority = storeJob(eventsKey, jobIdKey, jobId, args[3], ARGV[2],
                                 opts, timestamp, parentKey, parentData,
                                 repeatJobKey)
-- Add the job to the prioritized set
local isPausedOrMaxed = isQueuePausedOrMaxed(metaKey, activeKey)
addJobWithPriority( KEYS[1], priorityKey, priority, jobId, priorityCounterKey, isPausedOrMaxed)
-- Emit waiting event
rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "waiting",
      "jobId", jobId)
-- Check if this job is a child of another job, if so add it to the parents dependencies
if parentDependenciesKey ~= nil then
    rcall("SADD", parentDependenciesKey, jobIdKey)
end
return jobId .. "" -- convert to string
`;
const addPrioritizedJob = {
    name: 'addPrioritizedJob',
    content,
    keys: 9
}; //# sourceMappingURL=addPrioritizedJob-9.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/addRepeatableJob-2.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "addRepeatableJob",
    ()=>addRepeatableJob
]);
const content = `--[[
  Adds a repeatable job
    Input:
      KEYS[1] 'repeat' key
      KEYS[2] 'delayed' key
      ARGV[1] next milliseconds
      ARGV[2] msgpacked options
            [1]  name
            [2]  tz?
            [3]  pattern?
            [4]  endDate?
            [5]  every?
      ARGV[3] legacy custom key TODO: remove this logic in next breaking change
      ARGV[4] custom key
      ARGV[5] prefix key
      Output:
        repeatableKey  - OK
]]
local rcall = redis.call
local repeatKey = KEYS[1]
local delayedKey = KEYS[2]
local nextMillis = ARGV[1]
local legacyCustomKey = ARGV[3]
local customKey = ARGV[4]
local prefixKey = ARGV[5]
-- Includes
--[[
  Function to remove job.
]]
-- Includes
--[[
  Function to remove deduplication key if needed
  when a job is being removed.
]]
local function removeDeduplicationKeyIfNeededOnRemoval(prefixKey,
  jobKey, jobId)
  local deduplicationId = rcall("HGET", jobKey, "deid")
  if deduplicationId then
    local deduplicationKey = prefixKey .. "de:" .. deduplicationId
    local currentJobId = rcall('GET', deduplicationKey)
    if currentJobId and currentJobId == jobId then
      return rcall("DEL", deduplicationKey)
    end
  end
end
--[[
  Function to remove job keys.
]]
local function removeJobKeys(jobKey)
  return rcall("DEL", jobKey, jobKey .. ':logs', jobKey .. ':dependencies',
    jobKey .. ':processed', jobKey .. ':failed', jobKey .. ':unsuccessful')
end
--[[
  Check if this job has a parent. If so we will just remove it from
  the parent child list, but if it is the last child we should move the parent to "wait/paused"
  which requires code from "moveToFinished"
]]
-- Includes
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Functions to destructure job key.
  Just a bit of warning, these functions may be a bit slow and affect performance significantly.
]]
local getJobIdFromKey = function (jobKey)
  return string.match(jobKey, ".*:(.*)")
end
local getJobKeyPrefix = function (jobKey, jobId)
  return string.sub(jobKey, 0, #jobKey - #jobId)
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
local function _moveParentToWait(parentPrefix, parentId, emitEvent)
  local parentTarget, isPausedOrMaxed = getTargetQueueList(parentPrefix .. "meta", parentPrefix .. "active",
    parentPrefix .. "wait", parentPrefix .. "paused")
  addJobInTargetList(parentTarget, parentPrefix .. "marker", "RPUSH", isPausedOrMaxed, parentId)
  if emitEvent then
    local parentEventStream = parentPrefix .. "events"
    rcall("XADD", parentEventStream, "*", "event", "waiting", "jobId", parentId, "prev", "waiting-children")
  end
end
local function removeParentDependencyKey(jobKey, hard, parentKey, baseKey, debounceId)
  if parentKey then
    local parentDependenciesKey = parentKey .. ":dependencies"
    local result = rcall("SREM", parentDependenciesKey, jobKey)
    if result > 0 then
      local pendingDependencies = rcall("SCARD", parentDependenciesKey)
      if pendingDependencies == 0 then
        local parentId = getJobIdFromKey(parentKey)
        local parentPrefix = getJobKeyPrefix(parentKey, parentId)
        local numRemovedElements = rcall("ZREM", parentPrefix .. "waiting-children", parentId)
        if numRemovedElements == 1 then
          if hard then -- remove parent in same queue
            if parentPrefix == baseKey then
              removeParentDependencyKey(parentKey, hard, nil, baseKey, nil)
              removeJobKeys(parentKey)
              if debounceId then
                rcall("DEL", parentPrefix .. "de:" .. debounceId)
              end
            else
              _moveParentToWait(parentPrefix, parentId)
            end
          else
            _moveParentToWait(parentPrefix, parentId, true)
          end
        end
      end
      return true
    end
  else
    local parentAttributes = rcall("HMGET", jobKey, "parentKey", "deid")
    local missedParentKey = parentAttributes[1]
    if( (type(missedParentKey) == "string") and missedParentKey ~= ""
      and (rcall("EXISTS", missedParentKey) == 1)) then
      local parentDependenciesKey = missedParentKey .. ":dependencies"
      local result = rcall("SREM", parentDependenciesKey, jobKey)
      if result > 0 then
        local pendingDependencies = rcall("SCARD", parentDependenciesKey)
        if pendingDependencies == 0 then
          local parentId = getJobIdFromKey(missedParentKey)
          local parentPrefix = getJobKeyPrefix(missedParentKey, parentId)
          local numRemovedElements = rcall("ZREM", parentPrefix .. "waiting-children", parentId)
          if numRemovedElements == 1 then
            if hard then
              if parentPrefix == baseKey then
                removeParentDependencyKey(missedParentKey, hard, nil, baseKey, nil)
                removeJobKeys(missedParentKey)
                if parentAttributes[2] then
                  rcall("DEL", parentPrefix .. "de:" .. parentAttributes[2])
                end
              else
                _moveParentToWait(parentPrefix, parentId)
              end
            else
              _moveParentToWait(parentPrefix, parentId, true)
            end
          end
        end
        return true
      end
    end
  end
  return false
end
local function removeJob(jobId, hard, baseKey, shouldRemoveDeduplicationKey)
  local jobKey = baseKey .. jobId
  removeParentDependencyKey(jobKey, hard, nil, baseKey)
  if shouldRemoveDeduplicationKey then
    removeDeduplicationKeyIfNeededOnRemoval(baseKey, jobKey, jobId)
  end
  removeJobKeys(jobKey)
end
local function storeRepeatableJob(repeatKey, customKey, nextMillis, rawOpts)
  rcall("ZADD", repeatKey, nextMillis, customKey)
  local opts = cmsgpack.unpack(rawOpts)
  local optionalValues = {}
  if opts['tz'] then
    table.insert(optionalValues, "tz")
    table.insert(optionalValues, opts['tz'])
  end
  if opts['pattern'] then
    table.insert(optionalValues, "pattern")
    table.insert(optionalValues, opts['pattern'])
  end
  if opts['endDate'] then
    table.insert(optionalValues, "endDate")
    table.insert(optionalValues, opts['endDate'])
  end
  if opts['every'] then
    table.insert(optionalValues, "every")
    table.insert(optionalValues, opts['every'])
  end
  rcall("HMSET", repeatKey .. ":" .. customKey, "name", opts['name'],
    unpack(optionalValues))
  return customKey
end
-- If we are overriding a repeatable job we must delete the delayed job for
-- the next iteration.
local prevMillis = rcall("ZSCORE", repeatKey, customKey)
if prevMillis then
  local delayedJobId =  "repeat:" .. customKey .. ":" .. prevMillis
  local nextDelayedJobId =  repeatKey .. ":" .. customKey .. ":" .. nextMillis
  if rcall("ZSCORE", delayedKey, delayedJobId)
   and rcall("EXISTS", nextDelayedJobId) ~= 1 then
    removeJob(delayedJobId, true, prefixKey, true --[[remove debounce key]])
    rcall("ZREM", delayedKey, delayedJobId)
  end
end
-- Keep backwards compatibility with old repeatable jobs (<= 3.0.0)
if rcall("ZSCORE", repeatKey, legacyCustomKey) ~= false then
  return storeRepeatableJob(repeatKey, legacyCustomKey, nextMillis, ARGV[2])
end
return storeRepeatableJob(repeatKey, customKey, nextMillis, ARGV[2])
`;
const addRepeatableJob = {
    name: 'addRepeatableJob',
    content,
    keys: 2
}; //# sourceMappingURL=addRepeatableJob-2.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/addStandardJob-9.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "addStandardJob",
    ()=>addStandardJob
]);
const content = `--[[
  Adds a job to the queue by doing the following:
    - Increases the job counter if needed.
    - Creates a new job key with the job data.
    - if delayed:
      - computes timestamp.
      - adds to delayed zset.
      - Emits a global event 'delayed' if the job is delayed.
    - if not delayed
      - Adds the jobId to the wait/paused list in one of three ways:
         - LIFO
         - FIFO
         - prioritized.
      - Adds the job to the "added" list so that workers gets notified.
    Input:
      KEYS[1] 'wait',
      KEYS[2] 'paused'
      KEYS[3] 'meta'
      KEYS[4] 'id'
      KEYS[5] 'completed'
      KEYS[6] 'delayed'
      KEYS[7] 'active'
      KEYS[8] events stream key
      KEYS[9] marker key
      ARGV[1] msgpacked arguments array
            [1]  key prefix,
            [2]  custom id (will not generate one automatically)
            [3]  name
            [4]  timestamp
            [5]  parentKey?
            [6]  parent dependencies key.
            [7]  parent? {id, queueKey}
            [8]  repeat job key
            [9] deduplication key
      ARGV[2] Json stringified job data
      ARGV[3] msgpacked options
      Output:
        jobId  - OK
        -5     - Missing parent key
]]
local eventsKey = KEYS[8]
local jobId
local jobIdKey
local rcall = redis.call
local args = cmsgpack.unpack(ARGV[1])
local data = ARGV[2]
local opts = cmsgpack.unpack(ARGV[3])
local parentKey = args[5]
local parent = args[7]
local repeatJobKey = args[8]
local deduplicationKey = args[9]
local parentData
-- Includes
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to debounce a job.
]]
-- Includes
--[[
  Function to remove job keys.
]]
local function removeJobKeys(jobKey)
  return rcall("DEL", jobKey, jobKey .. ':logs', jobKey .. ':dependencies',
    jobKey .. ':processed', jobKey .. ':failed', jobKey .. ':unsuccessful')
end
local function removeDelayedJob(delayedKey, deduplicationKey, eventsKey, maxEvents, currentDeduplicatedJobId,
    jobId, deduplicationId, prefix)
    if rcall("ZREM", delayedKey, currentDeduplicatedJobId) > 0 then
        removeJobKeys(prefix .. currentDeduplicatedJobId)
        rcall("XADD", eventsKey, "*", "event", "removed", "jobId", currentDeduplicatedJobId,
            "prev", "delayed")
        -- TODO remove debounced event in next breaking change
        rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "debounced", "jobId",
            jobId, "debounceId", deduplicationId)
        rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "deduplicated", "jobId",
            jobId, "deduplicationId", deduplicationId, "deduplicatedJobId", currentDeduplicatedJobId)
        return true
    end
    return false
end
local function deduplicateJob(deduplicationOpts, jobId, delayedKey, deduplicationKey, eventsKey, maxEvents,
    prefix)
    local deduplicationId = deduplicationOpts and deduplicationOpts['id']
    if deduplicationId then
        local ttl = deduplicationOpts['ttl']
        if deduplicationOpts['replace'] then
            if ttl and ttl > 0 then
                local currentDebounceJobId = rcall('GET', deduplicationKey)
                if currentDebounceJobId then
                    local isRemoved = removeDelayedJob(delayedKey, deduplicationKey, eventsKey, maxEvents,
                        currentDebounceJobId, jobId, deduplicationId, prefix)
                    if isRemoved then
                        if deduplicationOpts['extend'] then
                            rcall('SET', deduplicationKey, jobId, 'PX', ttl)
                        else
                            rcall('SET', deduplicationKey, jobId, 'KEEPTTL')
                        end
                        return
                    else
                        return currentDebounceJobId
                    end
                else
                    rcall('SET', deduplicationKey, jobId, 'PX', ttl)
                    return
                end
            else
                local currentDebounceJobId = rcall('GET', deduplicationKey)
                if currentDebounceJobId then
                    local isRemoved = removeDelayedJob(delayedKey, deduplicationKey, eventsKey, maxEvents,
                        currentDebounceJobId, jobId, deduplicationId, prefix)
                    if isRemoved then
                        rcall('SET', deduplicationKey, jobId)
                        return
                    else
                        return currentDebounceJobId
                    end
                else
                    rcall('SET', deduplicationKey, jobId)
                    return
                end
            end
        else
            local deduplicationKeyExists
            if ttl and ttl > 0 then
                if deduplicationOpts['extend'] then
                    local currentDebounceJobId = rcall('GET', deduplicationKey)
                    if currentDebounceJobId then
                        rcall('SET', deduplicationKey, currentDebounceJobId, 'PX', ttl)
                        rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "debounced",
                            "jobId", currentDebounceJobId, "debounceId", deduplicationId)
                        rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "deduplicated", "jobId",
                            currentDebounceJobId, "deduplicationId", deduplicationId, "deduplicatedJobId", jobId)
                        return currentDebounceJobId
                    else
                        rcall('SET', deduplicationKey, jobId, 'PX', ttl)
                        return
                    end
                else
                    deduplicationKeyExists = not rcall('SET', deduplicationKey, jobId, 'PX', ttl, 'NX')
                end
            else
                deduplicationKeyExists = not rcall('SET', deduplicationKey, jobId, 'NX')
            end
            if deduplicationKeyExists then
                local currentDebounceJobId = rcall('GET', deduplicationKey)
                -- TODO remove debounced event in next breaking change
                rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "debounced", "jobId",
                    currentDebounceJobId, "debounceId", deduplicationId)
                rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "deduplicated", "jobId",
                    currentDebounceJobId, "deduplicationId", deduplicationId, "deduplicatedJobId", jobId)
                return currentDebounceJobId
            end
        end
    end
end
--[[
  Function to get max events value or set by default 10000.
]]
local function getOrSetMaxEvents(metaKey)
  local maxEvents = rcall("HGET", metaKey, "opts.maxLenEvents")
  if not maxEvents then
    maxEvents = 10000
    rcall("HSET", metaKey, "opts.maxLenEvents", maxEvents)
  end
  return maxEvents
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
--[[
  Function to handle the case when job is duplicated.
]]
-- Includes
--[[
    This function is used to update the parent's dependencies if the job
    is already completed and about to be ignored. The parent must get its
    dependencies updated to avoid the parent job being stuck forever in 
    the waiting-children state.
]]
-- Includes
--[[
  Validate and move or add dependencies to parent.
]]
-- Includes
--[[
  Validate and move parent to a wait status (waiting, delayed or prioritized)
  if no pending dependencies.
]]
-- Includes
--[[
  Validate and move parent to a wait status (waiting, delayed or prioritized) if needed.
]]
-- Includes
--[[
  Move parent to a wait status (wait, prioritized or delayed)
]]
-- Includes
--[[
  Add delay marker if needed.
]]
-- Includes
--[[
  Function to return the next delayed job timestamp.
]]
local function getNextDelayedTimestamp(delayedKey)
  local result = rcall("ZRANGE", delayedKey, 0, 0, "WITHSCORES")
  if #result then
    local nextTimestamp = tonumber(result[2])
    if nextTimestamp ~= nil then
      return nextTimestamp / 0x1000
    end
  end
end
local function addDelayMarkerIfNeeded(markerKey, delayedKey)
  local nextTimestamp = getNextDelayedTimestamp(delayedKey)
  if nextTimestamp ~= nil then
    -- Replace the score of the marker with the newest known
    -- next timestamp.
    rcall("ZADD", markerKey, nextTimestamp, "1")
  end
end
--[[
  Function to add job considering priority.
]]
-- Includes
--[[
  Function to get priority score.
]]
local function getPriorityScore(priority, priorityCounterKey)
  local prioCounter = rcall("INCR", priorityCounterKey)
  return priority * 0x100000000 + prioCounter % 0x100000000
end
local function addJobWithPriority(markerKey, prioritizedKey, priority, jobId, priorityCounterKey,
  isPausedOrMaxed)
  local score = getPriorityScore(priority, priorityCounterKey)
  rcall("ZADD", prioritizedKey, score, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to check if queue is paused or maxed
  (since an empty list and !EXISTS are not really the same).
]]
local function isQueuePausedOrMaxed(queueMetaKey, activeKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency")
  if queueAttributes[1] then
    return true
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      return activeCount >= tonumber(queueAttributes[2])
    end
  end
  return false
end
local function moveParentToWait(parentQueueKey, parentKey, parentId, timestamp)
    local parentWaitKey = parentQueueKey .. ":wait"
    local parentPausedKey = parentQueueKey .. ":paused"
    local parentActiveKey = parentQueueKey .. ":active"
    local parentMetaKey = parentQueueKey .. ":meta"
    local parentMarkerKey = parentQueueKey .. ":marker"
    local jobAttributes = rcall("HMGET", parentKey, "priority", "delay")
    local priority = tonumber(jobAttributes[1]) or 0
    local delay = tonumber(jobAttributes[2]) or 0
    if delay > 0 then
        local delayedTimestamp = tonumber(timestamp) + delay
        local score = delayedTimestamp * 0x1000
        local parentDelayedKey = parentQueueKey .. ":delayed"
        rcall("ZADD", parentDelayedKey, score, parentId)
        rcall("XADD", parentQueueKey .. ":events", "*", "event", "delayed", "jobId", parentId, "delay",
            delayedTimestamp)
        addDelayMarkerIfNeeded(parentMarkerKey, parentDelayedKey)
    else
        if priority == 0 then
            local parentTarget, isParentPausedOrMaxed = getTargetQueueList(parentMetaKey, parentActiveKey,
                parentWaitKey, parentPausedKey)
            addJobInTargetList(parentTarget, parentMarkerKey, "RPUSH", isParentPausedOrMaxed, parentId)
        else
            local isPausedOrMaxed = isQueuePausedOrMaxed(parentMetaKey, parentActiveKey)
            addJobWithPriority(parentMarkerKey, parentQueueKey .. ":prioritized", priority, parentId,
                parentQueueKey .. ":pc", isPausedOrMaxed)
        end
        rcall("XADD", parentQueueKey .. ":events", "*", "event", "waiting", "jobId", parentId, "prev",
            "waiting-children")
    end
end
local function moveParentToWaitIfNeeded(parentQueueKey, parentKey, parentId, timestamp)
  if rcall("EXISTS", parentKey) == 1 then
    local parentWaitingChildrenKey = parentQueueKey .. ":waiting-children"
    if rcall("ZSCORE", parentWaitingChildrenKey, parentId) then    
      rcall("ZREM", parentWaitingChildrenKey, parentId)
      moveParentToWait(parentQueueKey, parentKey, parentId, timestamp)
    end
  end
end
local function moveParentToWaitIfNoPendingDependencies(parentQueueKey, parentDependenciesKey, parentKey,
  parentId, timestamp)
  local doNotHavePendingDependencies = rcall("SCARD", parentDependenciesKey) == 0
  if doNotHavePendingDependencies then
    moveParentToWaitIfNeeded(parentQueueKey, parentKey, parentId, timestamp)
  end
end
local function updateParentDepsIfNeeded(parentKey, parentQueueKey, parentDependenciesKey,
  parentId, jobIdKey, returnvalue, timestamp )
  local processedSet = parentKey .. ":processed"
  rcall("HSET", processedSet, jobIdKey, returnvalue)
  moveParentToWaitIfNoPendingDependencies(parentQueueKey, parentDependenciesKey, parentKey, parentId, timestamp)
end
local function updateExistingJobsParent(parentKey, parent, parentData,
                                        parentDependenciesKey, completedKey,
                                        jobIdKey, jobId, timestamp)
    if parentKey ~= nil then
        if rcall("ZSCORE", completedKey, jobId) then
            local returnvalue = rcall("HGET", jobIdKey, "returnvalue")
            updateParentDepsIfNeeded(parentKey, parent['queueKey'],
                                     parentDependenciesKey, parent['id'],
                                     jobIdKey, returnvalue, timestamp)
        else
            if parentDependenciesKey ~= nil then
                rcall("SADD", parentDependenciesKey, jobIdKey)
            end
        end
        rcall("HMSET", jobIdKey, "parentKey", parentKey, "parent", parentData)
    end
end
local function handleDuplicatedJob(jobKey, jobId, currentParentKey, currentParent,
  parentData, parentDependenciesKey, completedKey, eventsKey, maxEvents, timestamp)
  local existedParentKey = rcall("HGET", jobKey, "parentKey")
  if not existedParentKey or existedParentKey == currentParentKey then
    updateExistingJobsParent(currentParentKey, currentParent, parentData,
      parentDependenciesKey, completedKey, jobKey,
      jobId, timestamp)
  else
    if currentParentKey ~= nil and currentParentKey ~= existedParentKey
      and (rcall("EXISTS", existedParentKey) == 1) then
      return -7
    end
  end
  rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event",
    "duplicated", "jobId", jobId)
  return jobId .. "" -- convert to string
end
--[[
  Function to store a job
]]
local function storeJob(eventsKey, jobIdKey, jobId, name, data, opts, timestamp,
                        parentKey, parentData, repeatJobKey)
    local jsonOpts = cjson.encode(opts)
    local delay = opts['delay'] or 0
    local priority = opts['priority'] or 0
    local debounceId = opts['de'] and opts['de']['id']
    local optionalValues = {}
    if parentKey ~= nil then
        table.insert(optionalValues, "parentKey")
        table.insert(optionalValues, parentKey)
        table.insert(optionalValues, "parent")
        table.insert(optionalValues, parentData)
    end
    if repeatJobKey then
        table.insert(optionalValues, "rjk")
        table.insert(optionalValues, repeatJobKey)
    end
    if debounceId then
        table.insert(optionalValues, "deid")
        table.insert(optionalValues, debounceId)
    end
    rcall("HMSET", jobIdKey, "name", name, "data", data, "opts", jsonOpts,
          "timestamp", timestamp, "delay", delay, "priority", priority,
          unpack(optionalValues))
    rcall("XADD", eventsKey, "*", "event", "added", "jobId", jobId, "name", name)
    return delay, priority
end
if parentKey ~= nil then
    if rcall("EXISTS", parentKey) ~= 1 then return -5 end
    parentData = cjson.encode(parent)
end
local jobCounter = rcall("INCR", KEYS[4])
local metaKey = KEYS[3]
local maxEvents = getOrSetMaxEvents(metaKey)
local parentDependenciesKey = args[6]
local timestamp = args[4]
if args[2] == "" then
    jobId = jobCounter
    jobIdKey = args[1] .. jobId
else
    jobId = args[2]
    jobIdKey = args[1] .. jobId
    if rcall("EXISTS", jobIdKey) == 1 then
        return handleDuplicatedJob(jobIdKey, jobId, parentKey, parent,
            parentData, parentDependenciesKey, KEYS[5], eventsKey,
            maxEvents, timestamp)
    end
end
local deduplicationJobId = deduplicateJob(opts['de'], jobId, KEYS[6],
  deduplicationKey, eventsKey, maxEvents, args[1])
if deduplicationJobId then
  return deduplicationJobId
end
-- Store the job.
storeJob(eventsKey, jobIdKey, jobId, args[3], ARGV[2], opts, timestamp,
         parentKey, parentData, repeatJobKey)
local target, isPausedOrMaxed = getTargetQueueList(metaKey, KEYS[7], KEYS[1], KEYS[2])
-- LIFO or FIFO
local pushCmd = opts['lifo'] and 'RPUSH' or 'LPUSH'
addJobInTargetList(target, KEYS[9], pushCmd, isPausedOrMaxed, jobId)
-- Emit waiting event
rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "waiting",
      "jobId", jobId)
-- Check if this job is a child of another job, if so add it to the parents dependencies
if parentDependenciesKey ~= nil then
    rcall("SADD", parentDependenciesKey, jobIdKey)
end
return jobId .. "" -- convert to string
`;
const addStandardJob = {
    name: 'addStandardJob',
    content,
    keys: 9
}; //# sourceMappingURL=addStandardJob-9.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/changeDelay-4.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "changeDelay",
    ()=>changeDelay
]);
const content = `--[[
  Change job delay when it is in delayed set.
  Input:
    KEYS[1] delayed key
    KEYS[2] meta key
    KEYS[3] marker key
    KEYS[4] events stream
    ARGV[1] delay
    ARGV[2] timestamp
    ARGV[3] the id of the job
    ARGV[4] job key
  Output:
    0 - OK
   -1 - Missing job.
   -3 - Job not in delayed set.
  Events:
    - delayed key.
]]
local rcall = redis.call
-- Includes
--[[
  Add delay marker if needed.
]]
-- Includes
--[[
  Function to return the next delayed job timestamp.
]]
local function getNextDelayedTimestamp(delayedKey)
  local result = rcall("ZRANGE", delayedKey, 0, 0, "WITHSCORES")
  if #result then
    local nextTimestamp = tonumber(result[2])
    if nextTimestamp ~= nil then
      return nextTimestamp / 0x1000
    end
  end
end
local function addDelayMarkerIfNeeded(markerKey, delayedKey)
  local nextTimestamp = getNextDelayedTimestamp(delayedKey)
  if nextTimestamp ~= nil then
    -- Replace the score of the marker with the newest known
    -- next timestamp.
    rcall("ZADD", markerKey, nextTimestamp, "1")
  end
end
--[[
  Bake in the job id first 12 bits into the timestamp
  to guarantee correct execution order of delayed jobs
  (up to 4096 jobs per given timestamp or 4096 jobs apart per timestamp)
  WARNING: Jobs that are so far apart that they wrap around will cause FIFO to fail
]]
local function getDelayedScore(delayedKey, timestamp, delay)
  local delayedTimestamp = (delay > 0 and (tonumber(timestamp) + delay)) or tonumber(timestamp)
  local minScore = delayedTimestamp * 0x1000
  local maxScore = (delayedTimestamp + 1 ) * 0x1000 - 1
  local result = rcall("ZREVRANGEBYSCORE", delayedKey, maxScore,
    minScore, "WITHSCORES","LIMIT", 0, 1)
  if #result then
    local currentMaxScore = tonumber(result[2])
    if currentMaxScore ~= nil then
      if currentMaxScore >= maxScore then
        return maxScore, delayedTimestamp
      else
        return currentMaxScore + 1, delayedTimestamp
      end
    end
  end
  return minScore, delayedTimestamp
end
--[[
  Function to get max events value or set by default 10000.
]]
local function getOrSetMaxEvents(metaKey)
  local maxEvents = rcall("HGET", metaKey, "opts.maxLenEvents")
  if not maxEvents then
    maxEvents = 10000
    rcall("HSET", metaKey, "opts.maxLenEvents", maxEvents)
  end
  return maxEvents
end
if rcall("EXISTS", ARGV[4]) == 1 then
  local jobId = ARGV[3]
  local delay = tonumber(ARGV[1])
  local score, delayedTimestamp = getDelayedScore(KEYS[1], ARGV[2], delay)
  local numRemovedElements = rcall("ZREM", KEYS[1], jobId)
  if numRemovedElements < 1 then
    return -3
  end
  rcall("HSET", ARGV[4], "delay", delay)
  rcall("ZADD", KEYS[1], score, jobId)
  local maxEvents = getOrSetMaxEvents(KEYS[2])
  rcall("XADD", KEYS[4], "MAXLEN", "~", maxEvents, "*", "event", "delayed",
    "jobId", jobId, "delay", delayedTimestamp)
  -- mark that a delayed job is available
  addDelayMarkerIfNeeded(KEYS[3], KEYS[1])
  return 0
else
  return -1
end`;
const changeDelay = {
    name: 'changeDelay',
    content,
    keys: 4
}; //# sourceMappingURL=changeDelay-4.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/changePriority-7.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "changePriority",
    ()=>changePriority
]);
const content = `--[[
  Change job priority
  Input:
    KEYS[1] 'wait',
    KEYS[2] 'paused'
    KEYS[3] 'meta'
    KEYS[4] 'prioritized'
    KEYS[5] 'active'
    KEYS[6] 'pc' priority counter
    KEYS[7] 'marker'
    ARGV[1] priority value
    ARGV[2] prefix key
    ARGV[3] job id
    ARGV[4] lifo
    Output:
       0  - OK
      -1  - Missing job
]]
local jobId = ARGV[3]
local jobKey = ARGV[2] .. jobId
local priority = tonumber(ARGV[1])
local rcall = redis.call
-- Includes
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to add job considering priority.
]]
-- Includes
--[[
  Function to get priority score.
]]
local function getPriorityScore(priority, priorityCounterKey)
  local prioCounter = rcall("INCR", priorityCounterKey)
  return priority * 0x100000000 + prioCounter % 0x100000000
end
local function addJobWithPriority(markerKey, prioritizedKey, priority, jobId, priorityCounterKey,
  isPausedOrMaxed)
  local score = getPriorityScore(priority, priorityCounterKey)
  rcall("ZADD", prioritizedKey, score, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
--[[
  Function to push back job considering priority in front of same prioritized jobs.
]]
local function pushBackJobWithPriority(prioritizedKey, priority, jobId)
  -- in order to put it at front of same prioritized jobs
  -- we consider prioritized counter as 0
  local score = priority * 0x100000000
  rcall("ZADD", prioritizedKey, score, jobId)
end
local function reAddJobWithNewPriority( prioritizedKey, markerKey, targetKey,
    priorityCounter, lifo, priority, jobId, isPausedOrMaxed)
    if priority == 0 then
        local pushCmd = lifo and 'RPUSH' or 'LPUSH'
        addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
    else
        if lifo then
            pushBackJobWithPriority(prioritizedKey, priority, jobId)
        else
            addJobWithPriority(markerKey, prioritizedKey, priority, jobId,
                priorityCounter, isPausedOrMaxed)
        end
    end
end
if rcall("EXISTS", jobKey) == 1 then
    local metaKey = KEYS[3]
    local target, isPausedOrMaxed = getTargetQueueList(metaKey, KEYS[5], KEYS[1], KEYS[2])
    local prioritizedKey = KEYS[4]
    local priorityCounterKey = KEYS[6]
    local markerKey = KEYS[7]
    -- Re-add with the new priority
    if rcall("ZREM", prioritizedKey, jobId) > 0 then
        reAddJobWithNewPriority( prioritizedKey, markerKey, target,
            priorityCounterKey, ARGV[4] == '1', priority, jobId, isPausedOrMaxed)
    elseif rcall("LREM", target, -1, jobId) > 0 then
        reAddJobWithNewPriority( prioritizedKey, markerKey, target,
            priorityCounterKey, ARGV[4] == '1', priority, jobId, isPausedOrMaxed)
    end
    rcall("HSET", jobKey, "priority", priority)
    return 0
else
    return -1
end
`;
const changePriority = {
    name: 'changePriority',
    content,
    keys: 7
}; //# sourceMappingURL=changePriority-7.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/cleanJobsInSet-3.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "cleanJobsInSet",
    ()=>cleanJobsInSet
]);
const content = `--[[
  Remove jobs from the specific set.
  Input:
    KEYS[1]  set key,
    KEYS[2]  events stream key
    KEYS[3]  repeat key
    ARGV[1]  jobKey prefix
    ARGV[2]  timestamp
    ARGV[3]  limit the number of jobs to be removed. 0 is unlimited
    ARGV[4]  set name, can be any of 'wait', 'active', 'paused', 'delayed', 'completed', or 'failed'
]]
local rcall = redis.call
local repeatKey = KEYS[3]
local rangeStart = 0
local rangeEnd = -1
local limit = tonumber(ARGV[3])
-- If we're only deleting _n_ items, avoid retrieving all items
-- for faster performance
--
-- Start from the tail of the list, since that's where oldest elements
-- are generally added for FIFO lists
if limit > 0 then
  rangeStart = -1 - limit + 1
  rangeEnd = -1
end
-- Includes
--[[
  Function to clean job list.
  Returns jobIds and deleted count number.
]]
-- Includes
--[[
  Function to get the latest saved timestamp.
]]
local function getTimestamp(jobKey, attributes)
  if #attributes == 1 then
    return rcall("HGET", jobKey, attributes[1])
  end
  local jobTs
  for _, ts in ipairs(rcall("HMGET", jobKey, unpack(attributes))) do
    if (ts) then
      jobTs = ts
      break
    end
  end
  return jobTs
end
--[[
  Function to check if the job belongs to a job scheduler and
  current delayed job matches with jobId
]]
local function isJobSchedulerJob(jobId, jobKey, jobSchedulersKey)
  local repeatJobKey = rcall("HGET", jobKey, "rjk")
  if repeatJobKey  then
    local prevMillis = rcall("ZSCORE", jobSchedulersKey, repeatJobKey)
    if prevMillis then
      local currentDelayedJobId = "repeat:" .. repeatJobKey .. ":" .. prevMillis
      return jobId == currentDelayedJobId
    end
  end
  return false
end
--[[
  Function to remove job.
]]
-- Includes
--[[
  Function to remove deduplication key if needed
  when a job is being removed.
]]
local function removeDeduplicationKeyIfNeededOnRemoval(prefixKey,
  jobKey, jobId)
  local deduplicationId = rcall("HGET", jobKey, "deid")
  if deduplicationId then
    local deduplicationKey = prefixKey .. "de:" .. deduplicationId
    local currentJobId = rcall('GET', deduplicationKey)
    if currentJobId and currentJobId == jobId then
      return rcall("DEL", deduplicationKey)
    end
  end
end
--[[
  Function to remove job keys.
]]
local function removeJobKeys(jobKey)
  return rcall("DEL", jobKey, jobKey .. ':logs', jobKey .. ':dependencies',
    jobKey .. ':processed', jobKey .. ':failed', jobKey .. ':unsuccessful')
end
--[[
  Check if this job has a parent. If so we will just remove it from
  the parent child list, but if it is the last child we should move the parent to "wait/paused"
  which requires code from "moveToFinished"
]]
-- Includes
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Functions to destructure job key.
  Just a bit of warning, these functions may be a bit slow and affect performance significantly.
]]
local getJobIdFromKey = function (jobKey)
  return string.match(jobKey, ".*:(.*)")
end
local getJobKeyPrefix = function (jobKey, jobId)
  return string.sub(jobKey, 0, #jobKey - #jobId)
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
local function _moveParentToWait(parentPrefix, parentId, emitEvent)
  local parentTarget, isPausedOrMaxed = getTargetQueueList(parentPrefix .. "meta", parentPrefix .. "active",
    parentPrefix .. "wait", parentPrefix .. "paused")
  addJobInTargetList(parentTarget, parentPrefix .. "marker", "RPUSH", isPausedOrMaxed, parentId)
  if emitEvent then
    local parentEventStream = parentPrefix .. "events"
    rcall("XADD", parentEventStream, "*", "event", "waiting", "jobId", parentId, "prev", "waiting-children")
  end
end
local function removeParentDependencyKey(jobKey, hard, parentKey, baseKey, debounceId)
  if parentKey then
    local parentDependenciesKey = parentKey .. ":dependencies"
    local result = rcall("SREM", parentDependenciesKey, jobKey)
    if result > 0 then
      local pendingDependencies = rcall("SCARD", parentDependenciesKey)
      if pendingDependencies == 0 then
        local parentId = getJobIdFromKey(parentKey)
        local parentPrefix = getJobKeyPrefix(parentKey, parentId)
        local numRemovedElements = rcall("ZREM", parentPrefix .. "waiting-children", parentId)
        if numRemovedElements == 1 then
          if hard then -- remove parent in same queue
            if parentPrefix == baseKey then
              removeParentDependencyKey(parentKey, hard, nil, baseKey, nil)
              removeJobKeys(parentKey)
              if debounceId then
                rcall("DEL", parentPrefix .. "de:" .. debounceId)
              end
            else
              _moveParentToWait(parentPrefix, parentId)
            end
          else
            _moveParentToWait(parentPrefix, parentId, true)
          end
        end
      end
      return true
    end
  else
    local parentAttributes = rcall("HMGET", jobKey, "parentKey", "deid")
    local missedParentKey = parentAttributes[1]
    if( (type(missedParentKey) == "string") and missedParentKey ~= ""
      and (rcall("EXISTS", missedParentKey) == 1)) then
      local parentDependenciesKey = missedParentKey .. ":dependencies"
      local result = rcall("SREM", parentDependenciesKey, jobKey)
      if result > 0 then
        local pendingDependencies = rcall("SCARD", parentDependenciesKey)
        if pendingDependencies == 0 then
          local parentId = getJobIdFromKey(missedParentKey)
          local parentPrefix = getJobKeyPrefix(missedParentKey, parentId)
          local numRemovedElements = rcall("ZREM", parentPrefix .. "waiting-children", parentId)
          if numRemovedElements == 1 then
            if hard then
              if parentPrefix == baseKey then
                removeParentDependencyKey(missedParentKey, hard, nil, baseKey, nil)
                removeJobKeys(missedParentKey)
                if parentAttributes[2] then
                  rcall("DEL", parentPrefix .. "de:" .. parentAttributes[2])
                end
              else
                _moveParentToWait(parentPrefix, parentId)
              end
            else
              _moveParentToWait(parentPrefix, parentId, true)
            end
          end
        end
        return true
      end
    end
  end
  return false
end
local function removeJob(jobId, hard, baseKey, shouldRemoveDeduplicationKey)
  local jobKey = baseKey .. jobId
  removeParentDependencyKey(jobKey, hard, nil, baseKey)
  if shouldRemoveDeduplicationKey then
    removeDeduplicationKeyIfNeededOnRemoval(baseKey, jobKey, jobId)
  end
  removeJobKeys(jobKey)
end
local function cleanList(listKey, jobKeyPrefix, rangeStart, rangeEnd,
  timestamp, isWaiting, jobSchedulersKey)
  local jobs = rcall("LRANGE", listKey, rangeStart, rangeEnd)
  local deleted = {}
  local deletedCount = 0
  local jobTS
  local deletionMarker = ''
  local jobIdsLen = #jobs
  for i, job in ipairs(jobs) do
    if limit > 0 and deletedCount >= limit then
      break
    end
    local jobKey = jobKeyPrefix .. job
    if (isWaiting or rcall("EXISTS", jobKey .. ":lock") == 0) and
      not isJobSchedulerJob(job, jobKey, jobSchedulersKey) then
      -- Find the right timestamp of the job to compare to maxTimestamp:
      -- * finishedOn says when the job was completed, but it isn't set unless the job has actually completed
      -- * processedOn represents when the job was last attempted, but it doesn't get populated until
      --   the job is first tried
      -- * timestamp is the original job submission time
      -- Fetch all three of these (in that order) and use the first one that is set so that we'll leave jobs
      -- that have been active within the grace period:
      jobTS = getTimestamp(jobKey, {"finishedOn", "processedOn", "timestamp"})
      if (not jobTS or jobTS <= timestamp) then
        -- replace the entry with a deletion marker; the actual deletion will
        -- occur at the end of the script
        rcall("LSET", listKey, rangeEnd - jobIdsLen + i, deletionMarker)
        removeJob(job, true, jobKeyPrefix, true --[[remove debounce key]])
        deletedCount = deletedCount + 1
        table.insert(deleted, job)
      end
    end
  end
  rcall("LREM", listKey, 0, deletionMarker)
  return {deleted, deletedCount}
end
--[[
  Function to clean job set.
  Returns jobIds and deleted count number.
]] 
-- Includes
--[[
  Function to loop in batches.
  Just a bit of warning, some commands as ZREM
  could receive a maximum of 7000 parameters per call.
]]
local function batches(n, batchSize)
  local i = 0
  return function()
    local from = i * batchSize + 1
    i = i + 1
    if (from <= n) then
      local to = math.min(from + batchSize - 1, n)
      return from, to
    end
  end
end
--[[
  We use ZRANGEBYSCORE to make the case where we're deleting a limited number
  of items in a sorted set only run a single iteration. If we simply used
  ZRANGE, we may take a long time traversing through jobs that are within the
  grace period.
]]
local function getJobsInZset(zsetKey, rangeEnd, limit)
  if limit > 0 then
    return rcall("ZRANGEBYSCORE", zsetKey, 0, rangeEnd, "LIMIT", 0, limit)
  else
    return rcall("ZRANGEBYSCORE", zsetKey, 0, rangeEnd)
  end
end
local function cleanSet(
    setKey,
    jobKeyPrefix,
    rangeEnd,
    timestamp,
    limit,
    attributes,
    isFinished,
    jobSchedulersKey)
    local jobs = getJobsInZset(setKey, rangeEnd, limit)
    local deleted = {}
    local deletedCount = 0
    local jobTS
    for i, job in ipairs(jobs) do
        if limit > 0 and deletedCount >= limit then
            break
        end
        local jobKey = jobKeyPrefix .. job
        -- Extract a Job Scheduler Id from jobId ("repeat:job-scheduler-id:millis") 
        -- and check if it is in the scheduled jobs
        if not (jobSchedulersKey and isJobSchedulerJob(job, jobKey, jobSchedulersKey)) then
            if isFinished then
                removeJob(job, true, jobKeyPrefix, true --[[remove debounce key]] )
                deletedCount = deletedCount + 1
                table.insert(deleted, job)
            else
                -- * finishedOn says when the job was completed, but it isn't set unless the job has actually completed
                jobTS = getTimestamp(jobKey, attributes)
                if (not jobTS or jobTS <= timestamp) then
                    removeJob(job, true, jobKeyPrefix, true --[[remove debounce key]] )
                    deletedCount = deletedCount + 1
                    table.insert(deleted, job)
                end
            end
        end
    end
    if (#deleted > 0) then
        for from, to in batches(#deleted, 7000) do
            rcall("ZREM", setKey, unpack(deleted, from, to))
        end
    end
    return {deleted, deletedCount}
end
local result
if ARGV[4] == "active" then
  result = cleanList(KEYS[1], ARGV[1], rangeStart, rangeEnd, ARGV[2], false --[[ hasFinished ]],
                      repeatKey)
elseif ARGV[4] == "delayed" then
  rangeEnd = "+inf"
  result = cleanSet(KEYS[1], ARGV[1], rangeEnd, ARGV[2], limit,
                    {"processedOn", "timestamp"}, false  --[[ hasFinished ]], repeatKey)
elseif ARGV[4] == "prioritized" then
  rangeEnd = "+inf"
  result = cleanSet(KEYS[1], ARGV[1], rangeEnd, ARGV[2], limit,
                    {"timestamp"}, false  --[[ hasFinished ]], repeatKey)
elseif ARGV[4] == "wait" or ARGV[4] == "paused" then
  result = cleanList(KEYS[1], ARGV[1], rangeStart, rangeEnd, ARGV[2], true --[[ hasFinished ]],
                      repeatKey)
else
  rangeEnd = ARGV[2]
  -- No need to pass repeat key as in that moment job won't be related to a job scheduler
  result = cleanSet(KEYS[1], ARGV[1], rangeEnd, ARGV[2], limit,
                    {"finishedOn"}, true  --[[ hasFinished ]])
end
rcall("XADD", KEYS[2], "*", "event", "cleaned", "count", result[2])
return result[1]
`;
const cleanJobsInSet = {
    name: 'cleanJobsInSet',
    content,
    keys: 3
}; //# sourceMappingURL=cleanJobsInSet-3.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/drain-5.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "drain",
    ()=>drain
]);
const content = `--[[
  Drains the queue, removes all jobs that are waiting
  or delayed, but not active, completed or failed
  Input:
    KEYS[1] 'wait',
    KEYS[2] 'paused'
    KEYS[3] 'delayed'
    KEYS[4] 'prioritized'
    KEYS[5] 'jobschedulers' (repeat)
    ARGV[1]  queue key prefix
    ARGV[2]  should clean delayed jobs
]]
local rcall = redis.call
local queueBaseKey = ARGV[1]
--[[
  Functions to remove jobs.
]]
-- Includes
--[[
  Function to filter out jobs to ignore from a table.
]]
local function filterOutJobsToIgnore(jobs, jobsToIgnore)
  local filteredJobs = {}
  for i = 1, #jobs do
    if not jobsToIgnore[jobs[i]] then
      table.insert(filteredJobs, jobs[i])
    end
  end
  return filteredJobs
end
--[[
  Functions to remove jobs.
]]
-- Includes
--[[
  Function to remove job.
]]
-- Includes
--[[
  Function to remove deduplication key if needed
  when a job is being removed.
]]
local function removeDeduplicationKeyIfNeededOnRemoval(prefixKey,
  jobKey, jobId)
  local deduplicationId = rcall("HGET", jobKey, "deid")
  if deduplicationId then
    local deduplicationKey = prefixKey .. "de:" .. deduplicationId
    local currentJobId = rcall('GET', deduplicationKey)
    if currentJobId and currentJobId == jobId then
      return rcall("DEL", deduplicationKey)
    end
  end
end
--[[
  Function to remove job keys.
]]
local function removeJobKeys(jobKey)
  return rcall("DEL", jobKey, jobKey .. ':logs', jobKey .. ':dependencies',
    jobKey .. ':processed', jobKey .. ':failed', jobKey .. ':unsuccessful')
end
--[[
  Check if this job has a parent. If so we will just remove it from
  the parent child list, but if it is the last child we should move the parent to "wait/paused"
  which requires code from "moveToFinished"
]]
-- Includes
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Functions to destructure job key.
  Just a bit of warning, these functions may be a bit slow and affect performance significantly.
]]
local getJobIdFromKey = function (jobKey)
  return string.match(jobKey, ".*:(.*)")
end
local getJobKeyPrefix = function (jobKey, jobId)
  return string.sub(jobKey, 0, #jobKey - #jobId)
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
local function _moveParentToWait(parentPrefix, parentId, emitEvent)
  local parentTarget, isPausedOrMaxed = getTargetQueueList(parentPrefix .. "meta", parentPrefix .. "active",
    parentPrefix .. "wait", parentPrefix .. "paused")
  addJobInTargetList(parentTarget, parentPrefix .. "marker", "RPUSH", isPausedOrMaxed, parentId)
  if emitEvent then
    local parentEventStream = parentPrefix .. "events"
    rcall("XADD", parentEventStream, "*", "event", "waiting", "jobId", parentId, "prev", "waiting-children")
  end
end
local function removeParentDependencyKey(jobKey, hard, parentKey, baseKey, debounceId)
  if parentKey then
    local parentDependenciesKey = parentKey .. ":dependencies"
    local result = rcall("SREM", parentDependenciesKey, jobKey)
    if result > 0 then
      local pendingDependencies = rcall("SCARD", parentDependenciesKey)
      if pendingDependencies == 0 then
        local parentId = getJobIdFromKey(parentKey)
        local parentPrefix = getJobKeyPrefix(parentKey, parentId)
        local numRemovedElements = rcall("ZREM", parentPrefix .. "waiting-children", parentId)
        if numRemovedElements == 1 then
          if hard then -- remove parent in same queue
            if parentPrefix == baseKey then
              removeParentDependencyKey(parentKey, hard, nil, baseKey, nil)
              removeJobKeys(parentKey)
              if debounceId then
                rcall("DEL", parentPrefix .. "de:" .. debounceId)
              end
            else
              _moveParentToWait(parentPrefix, parentId)
            end
          else
            _moveParentToWait(parentPrefix, parentId, true)
          end
        end
      end
      return true
    end
  else
    local parentAttributes = rcall("HMGET", jobKey, "parentKey", "deid")
    local missedParentKey = parentAttributes[1]
    if( (type(missedParentKey) == "string") and missedParentKey ~= ""
      and (rcall("EXISTS", missedParentKey) == 1)) then
      local parentDependenciesKey = missedParentKey .. ":dependencies"
      local result = rcall("SREM", parentDependenciesKey, jobKey)
      if result > 0 then
        local pendingDependencies = rcall("SCARD", parentDependenciesKey)
        if pendingDependencies == 0 then
          local parentId = getJobIdFromKey(missedParentKey)
          local parentPrefix = getJobKeyPrefix(missedParentKey, parentId)
          local numRemovedElements = rcall("ZREM", parentPrefix .. "waiting-children", parentId)
          if numRemovedElements == 1 then
            if hard then
              if parentPrefix == baseKey then
                removeParentDependencyKey(missedParentKey, hard, nil, baseKey, nil)
                removeJobKeys(missedParentKey)
                if parentAttributes[2] then
                  rcall("DEL", parentPrefix .. "de:" .. parentAttributes[2])
                end
              else
                _moveParentToWait(parentPrefix, parentId)
              end
            else
              _moveParentToWait(parentPrefix, parentId, true)
            end
          end
        end
        return true
      end
    end
  end
  return false
end
local function removeJob(jobId, hard, baseKey, shouldRemoveDeduplicationKey)
  local jobKey = baseKey .. jobId
  removeParentDependencyKey(jobKey, hard, nil, baseKey)
  if shouldRemoveDeduplicationKey then
    removeDeduplicationKeyIfNeededOnRemoval(baseKey, jobKey, jobId)
  end
  removeJobKeys(jobKey)
end
local function removeJobs(keys, hard, baseKey, max)
  for i, key in ipairs(keys) do
    removeJob(key, hard, baseKey, true --[[remove debounce key]])
  end
  return max - #keys
end
local function getListItems(keyName, max)
  return rcall('LRANGE', keyName, 0, max - 1)
end
local function removeListJobs(keyName, hard, baseKey, max, jobsToIgnore)
  local jobs = getListItems(keyName, max)
  if jobsToIgnore then
    jobs = filterOutJobsToIgnore(jobs, jobsToIgnore)
  end
  local count = removeJobs(jobs, hard, baseKey, max)
  rcall("LTRIM", keyName, #jobs, -1)
  return count
end
-- Includes
--[[
  Function to loop in batches.
  Just a bit of warning, some commands as ZREM
  could receive a maximum of 7000 parameters per call.
]]
local function batches(n, batchSize)
  local i = 0
  return function()
    local from = i * batchSize + 1
    i = i + 1
    if (from <= n) then
      local to = math.min(from + batchSize - 1, n)
      return from, to
    end
  end
end
--[[
  Function to get ZSet items.
]]
local function getZSetItems(keyName, max)
  return rcall('ZRANGE', keyName, 0, max - 1)
end
local function removeZSetJobs(keyName, hard, baseKey, max, jobsToIgnore)
  local jobs = getZSetItems(keyName, max)
  if jobsToIgnore then
    jobs = filterOutJobsToIgnore(jobs, jobsToIgnore)
  end
  local count = removeJobs(jobs, hard, baseKey, max)
  if(#jobs > 0) then
    for from, to in batches(#jobs, 7000) do
      rcall("ZREM", keyName, unpack(jobs, from, to))
    end
  end
  return count
end
-- We must not remove delayed jobs if they are associated to a job scheduler.
local scheduledJobs = {}
local jobSchedulers = rcall("ZRANGE", KEYS[5], 0, -1, "WITHSCORES")
-- For every job scheduler, get the current delayed job id.
for i = 1, #jobSchedulers, 2 do
    local jobSchedulerId = jobSchedulers[i]
    local jobSchedulerMillis = jobSchedulers[i + 1]
    local delayedJobId = "repeat:" .. jobSchedulerId .. ":" .. jobSchedulerMillis
    scheduledJobs[delayedJobId] = true
end
removeListJobs(KEYS[1], true, queueBaseKey, 0, scheduledJobs) -- wait
removeListJobs(KEYS[2], true, queueBaseKey, 0, scheduledJobs) -- paused
if ARGV[2] == "1" then
  removeZSetJobs(KEYS[3], true, queueBaseKey, 0, scheduledJobs) -- delayed
end
removeZSetJobs(KEYS[4], true, queueBaseKey, 0, scheduledJobs) -- prioritized
`;
const drain = {
    name: 'drain',
    content,
    keys: 5
}; //# sourceMappingURL=drain-5.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/extendLock-2.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "extendLock",
    ()=>extendLock
]);
const content = `--[[
  Extend lock and removes the job from the stalled set.
  Input:
    KEYS[1] 'lock',
    KEYS[2] 'stalled'
    ARGV[1]  token
    ARGV[2]  lock duration in milliseconds
    ARGV[3]  jobid
  Output:
    "1" if lock extented succesfully.
]]
local rcall = redis.call
if rcall("GET", KEYS[1]) == ARGV[1] then
  --   if rcall("SET", KEYS[1], ARGV[1], "PX", ARGV[2], "XX") then
  if rcall("SET", KEYS[1], ARGV[1], "PX", ARGV[2]) then
    rcall("SREM", KEYS[2], ARGV[3])
    return 1
  end
end
return 0
`;
const extendLock = {
    name: 'extendLock',
    content,
    keys: 2
}; //# sourceMappingURL=extendLock-2.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/extendLocks-1.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "extendLocks",
    ()=>extendLocks
]);
const content = `--[[
  Extend locks for multiple jobs and remove them from the stalled set if successful.
  Return the list of job IDs for which the operation failed.
  KEYS[1] = stalled key
  ARGV[1] = baseKey
  ARGV[2] = tokens
  ARGV[3] = jobIds
  ARGV[4] = lockDuration (ms)
  Output:
    An array of failed job IDs. If empty, all succeeded.
]]
local rcall = redis.call
local stalledKey = KEYS[1]
local baseKey = ARGV[1]
local tokens = cmsgpack.unpack(ARGV[2])
local jobIds = cmsgpack.unpack(ARGV[3])
local lockDuration = ARGV[4]
local jobCount = #jobIds
local failedJobs = {}
for i = 1, jobCount, 1 do
    local lockKey = baseKey .. jobIds[i] .. ':lock'
    local jobId = jobIds[i]
    local token = tokens[i]
    local currentToken = rcall("GET", lockKey)
    if currentToken then
        if currentToken == token then
            local setResult = rcall("SET", lockKey, token, "PX", lockDuration)
            if setResult then
                rcall("SREM", stalledKey, jobId)
            else
                table.insert(failedJobs, jobId)
            end
        else
            table.insert(failedJobs, jobId)
        end
    else
        table.insert(failedJobs, jobId)
    end
end
return failedJobs
`;
const extendLocks = {
    name: 'extendLocks',
    content,
    keys: 1
}; //# sourceMappingURL=extendLocks-1.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/getCounts-1.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "getCounts",
    ()=>getCounts
]);
const content = `--[[
  Get counts per provided states
    Input:
      KEYS[1]    'prefix'
      ARGV[1...] types
]]
local rcall = redis.call;
local prefix = KEYS[1]
local results = {}
for i = 1, #ARGV do
  local stateKey = prefix .. ARGV[i]
  if ARGV[i] == "wait" or ARGV[i] == "paused" then
    -- Markers in waitlist DEPRECATED in v5: Remove in v6.
    local marker = rcall("LINDEX", stateKey, -1)
    if marker and string.sub(marker, 1, 2) == "0:" then
      local count = rcall("LLEN", stateKey)
      if count > 1 then
        rcall("RPOP", stateKey)
        results[#results+1] = count-1
      else
        results[#results+1] = 0
      end
    else
      results[#results+1] = rcall("LLEN", stateKey)
    end
  elseif ARGV[i] == "active" then
    results[#results+1] = rcall("LLEN", stateKey)
  else
    results[#results+1] = rcall("ZCARD", stateKey)
  end
end
return results
`;
const getCounts = {
    name: 'getCounts',
    content,
    keys: 1
}; //# sourceMappingURL=getCounts-1.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/getCountsPerPriority-4.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "getCountsPerPriority",
    ()=>getCountsPerPriority
]);
const content = `--[[
  Get counts per provided states
    Input:
      KEYS[1] wait key
      KEYS[2] paused key
      KEYS[3] meta key
      KEYS[4] prioritized key
      ARGV[1...] priorities
]]
local rcall = redis.call
local results = {}
local waitKey = KEYS[1]
local pausedKey = KEYS[2]
local prioritizedKey = KEYS[4]
-- Includes
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function isQueuePaused(queueMetaKey)
  return rcall("HEXISTS", queueMetaKey, "paused") == 1
end
for i = 1, #ARGV do
  local priority = tonumber(ARGV[i])
  if priority == 0 then
    if isQueuePaused(KEYS[3]) then
      results[#results+1] = rcall("LLEN", pausedKey)
    else
      results[#results+1] = rcall("LLEN", waitKey)
    end
  else
    results[#results+1] = rcall("ZCOUNT", prioritizedKey,
      priority * 0x100000000, (priority + 1)  * 0x100000000 - 1)
  end
end
return results
`;
const getCountsPerPriority = {
    name: 'getCountsPerPriority',
    content,
    keys: 4
}; //# sourceMappingURL=getCountsPerPriority-4.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/getDependencyCounts-4.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "getDependencyCounts",
    ()=>getDependencyCounts
]);
const content = `--[[
  Get counts per child states
    Input:
      KEYS[1]    processed key
      KEYS[2]    unprocessed key
      KEYS[3]    ignored key
      KEYS[4]    failed key
      ARGV[1...] types
]]
local rcall = redis.call;
local processedKey = KEYS[1]
local unprocessedKey = KEYS[2]
local ignoredKey = KEYS[3]
local failedKey = KEYS[4]
local results = {}
for i = 1, #ARGV do
  if ARGV[i] == "processed" then
    results[#results+1] = rcall("HLEN", processedKey)
  elseif ARGV[i] == "unprocessed" then
    results[#results+1] = rcall("SCARD", unprocessedKey)
  elseif ARGV[i] == "ignored" then
    results[#results+1] = rcall("HLEN", ignoredKey)
  else
    results[#results+1] = rcall("ZCARD", failedKey)
  end
end
return results
`;
const getDependencyCounts = {
    name: 'getDependencyCounts',
    content,
    keys: 4
}; //# sourceMappingURL=getDependencyCounts-4.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/getJobScheduler-1.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "getJobScheduler",
    ()=>getJobScheduler
]);
const content = `--[[
  Get job scheduler record.
  Input:
    KEYS[1] 'repeat' key
    ARGV[1] id
]]
local rcall = redis.call
local jobSchedulerKey = KEYS[1] .. ":" .. ARGV[1]
local score = rcall("ZSCORE", KEYS[1], ARGV[1])
if score then
  return {rcall("HGETALL", jobSchedulerKey), score} -- get job data
end
return {nil, nil}
`;
const getJobScheduler = {
    name: 'getJobScheduler',
    content,
    keys: 1
}; //# sourceMappingURL=getJobScheduler-1.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/getMetrics-2.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "getMetrics",
    ()=>getMetrics
]);
const content = `--[[
  Get metrics
  Input:
    KEYS[1] 'metrics' key
    KEYS[2] 'metrics data' key
    ARGV[1] start index
    ARGV[2] end index
]]
local rcall = redis.call;
local metricsKey = KEYS[1]
local dataKey = KEYS[2]
local metrics = rcall("HMGET", metricsKey, "count", "prevTS", "prevCount")
local data = rcall("LRANGE", dataKey, tonumber(ARGV[1]), tonumber(ARGV[2]))
local numPoints = rcall("LLEN", dataKey)
return {metrics, data, numPoints}
`;
const getMetrics = {
    name: 'getMetrics',
    content,
    keys: 2
}; //# sourceMappingURL=getMetrics-2.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/getRanges-1.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "getRanges",
    ()=>getRanges
]);
const content = `--[[
  Get job ids per provided states
    Input:
      KEYS[1]    'prefix'
      ARGV[1]    start
      ARGV[2]    end
      ARGV[3]    asc
      ARGV[4...] types
]]
local rcall = redis.call
local prefix = KEYS[1]
local rangeStart = tonumber(ARGV[1])
local rangeEnd = tonumber(ARGV[2])
local asc = ARGV[3]
local results = {}
local function getRangeInList(listKey, asc, rangeStart, rangeEnd, results)
  if asc == "1" then
    local modifiedRangeStart
    local modifiedRangeEnd
    if rangeStart == -1 then
      modifiedRangeStart = 0
    else
      modifiedRangeStart = -(rangeStart + 1)
    end
    if rangeEnd == -1 then
      modifiedRangeEnd = 0
    else
      modifiedRangeEnd = -(rangeEnd + 1)
    end
    results[#results+1] = rcall("LRANGE", listKey,
      modifiedRangeEnd,
      modifiedRangeStart)
  else
    results[#results+1] = rcall("LRANGE", listKey, rangeStart, rangeEnd)
  end
end
for i = 4, #ARGV do
  local stateKey = prefix .. ARGV[i]
  if ARGV[i] == "wait" or ARGV[i] == "paused" then
    -- Markers in waitlist DEPRECATED in v5: Remove in v6.
    local marker = rcall("LINDEX", stateKey, -1)
    if marker and string.sub(marker, 1, 2) == "0:" then
      local count = rcall("LLEN", stateKey)
      if count > 1 then
        rcall("RPOP", stateKey)
        getRangeInList(stateKey, asc, rangeStart, rangeEnd, results)
      else
        results[#results+1] = {}
      end
    else
      getRangeInList(stateKey, asc, rangeStart, rangeEnd, results)
    end
  elseif ARGV[i] == "active" then
    getRangeInList(stateKey, asc, rangeStart, rangeEnd, results)
  else
    if asc == "1" then
      results[#results+1] = rcall("ZRANGE", stateKey, rangeStart, rangeEnd)
    else
      results[#results+1] = rcall("ZREVRANGE", stateKey, rangeStart, rangeEnd)
    end
  end
end
return results
`;
const getRanges = {
    name: 'getRanges',
    content,
    keys: 1
}; //# sourceMappingURL=getRanges-1.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/getRateLimitTtl-2.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "getRateLimitTtl",
    ()=>getRateLimitTtl
]);
const content = `--[[
  Get rate limit ttl
    Input:
      KEYS[1] 'limiter'
      KEYS[2] 'meta'
      ARGV[1] maxJobs
]]
local rcall = redis.call
-- Includes
--[[
  Function to get current rate limit ttl.
]]
local function getRateLimitTTL(maxJobs, rateLimiterKey)
  if maxJobs and maxJobs <= tonumber(rcall("GET", rateLimiterKey) or 0) then
    local pttl = rcall("PTTL", rateLimiterKey)
    if pttl == 0 then
      rcall("DEL", rateLimiterKey)
    end
    if pttl > 0 then
      return pttl
    end
  end
  return 0
end
local rateLimiterKey = KEYS[1]
if ARGV[1] ~= "0" then
  return getRateLimitTTL(tonumber(ARGV[1]), rateLimiterKey)
else
  local rateLimitMax = rcall("HGET", KEYS[2], "max")
  if rateLimitMax then
    return getRateLimitTTL(tonumber(rateLimitMax), rateLimiterKey)
  end
  return rcall("PTTL", rateLimiterKey)
end
`;
const getRateLimitTtl = {
    name: 'getRateLimitTtl',
    content,
    keys: 2
}; //# sourceMappingURL=getRateLimitTtl-2.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/getState-8.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "getState",
    ()=>getState
]);
const content = `--[[
  Get a job state
  Input: 
    KEYS[1] 'completed' key,
    KEYS[2] 'failed' key
    KEYS[3] 'delayed' key
    KEYS[4] 'active' key
    KEYS[5] 'wait' key
    KEYS[6] 'paused' key
    KEYS[7] 'waiting-children' key
    KEYS[8] 'prioritized' key
    ARGV[1] job id
  Output:
    'completed'
    'failed'
    'delayed'
    'active'
    'prioritized'
    'waiting'
    'waiting-children'
    'unknown'
]]
local rcall = redis.call
if rcall("ZSCORE", KEYS[1], ARGV[1]) then
  return "completed"
end
if rcall("ZSCORE", KEYS[2], ARGV[1]) then
  return "failed"
end
if rcall("ZSCORE", KEYS[3], ARGV[1]) then
  return "delayed"
end
if rcall("ZSCORE", KEYS[8], ARGV[1]) then
  return "prioritized"
end
-- Includes
--[[
  Functions to check if a item belongs to a list.
]]
local function checkItemInList(list, item)
  for _, v in pairs(list) do
    if v == item then
      return 1
    end
  end
  return nil
end
local active_items = rcall("LRANGE", KEYS[4] , 0, -1)
if checkItemInList(active_items, ARGV[1]) ~= nil then
  return "active"
end
local wait_items = rcall("LRANGE", KEYS[5] , 0, -1)
if checkItemInList(wait_items, ARGV[1]) ~= nil then
  return "waiting"
end
local paused_items = rcall("LRANGE", KEYS[6] , 0, -1)
if checkItemInList(paused_items, ARGV[1]) ~= nil then
  return "waiting"
end
if rcall("ZSCORE", KEYS[7], ARGV[1]) then
  return "waiting-children"
end
return "unknown"
`;
const getState = {
    name: 'getState',
    content,
    keys: 8
}; //# sourceMappingURL=getState-8.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/getStateV2-8.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "getStateV2",
    ()=>getStateV2
]);
const content = `--[[
  Get a job state
  Input: 
    KEYS[1] 'completed' key,
    KEYS[2] 'failed' key
    KEYS[3] 'delayed' key
    KEYS[4] 'active' key
    KEYS[5] 'wait' key
    KEYS[6] 'paused' key
    KEYS[7] 'waiting-children' key
    KEYS[8] 'prioritized' key
    ARGV[1] job id
  Output:
    'completed'
    'failed'
    'delayed'
    'active'
    'waiting'
    'waiting-children'
    'unknown'
]]
local rcall = redis.call
if rcall("ZSCORE", KEYS[1], ARGV[1]) then
  return "completed"
end
if rcall("ZSCORE", KEYS[2], ARGV[1]) then
  return "failed"
end
if rcall("ZSCORE", KEYS[3], ARGV[1]) then
  return "delayed"
end
if rcall("ZSCORE", KEYS[8], ARGV[1]) then
  return "prioritized"
end
if rcall("LPOS", KEYS[4] , ARGV[1]) then
  return "active"
end
if rcall("LPOS", KEYS[5] , ARGV[1]) then
  return "waiting"
end
if rcall("LPOS", KEYS[6] , ARGV[1]) then
  return "waiting"
end
if rcall("ZSCORE", KEYS[7] , ARGV[1]) then
  return "waiting-children"
end
return "unknown"
`;
const getStateV2 = {
    name: 'getStateV2',
    content,
    keys: 8
}; //# sourceMappingURL=getStateV2-8.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/isFinished-3.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "isFinished",
    ()=>isFinished
]);
const content = `--[[
  Checks if a job is finished (.i.e. is in the completed or failed set)
  Input: 
    KEYS[1] completed key
    KEYS[2] failed key
    KEYS[3] job key
    ARGV[1] job id
    ARGV[2] return value?
  Output:
    0 - Not finished.
    1 - Completed.
    2 - Failed.
   -1 - Missing job. 
]]
local rcall = redis.call
if rcall("EXISTS", KEYS[3]) ~= 1 then
  if ARGV[2] == "1" then
    return {-1,"Missing key for job " .. KEYS[3] .. ". isFinished"}
  end  
  return -1
end
if rcall("ZSCORE", KEYS[1], ARGV[1]) then
  if ARGV[2] == "1" then
    local returnValue = rcall("HGET", KEYS[3], "returnvalue")
    return {1,returnValue}
  end
  return 1
end
if rcall("ZSCORE", KEYS[2], ARGV[1]) then
  if ARGV[2] == "1" then
    local failedReason = rcall("HGET", KEYS[3], "failedReason")
    return {2,failedReason}
  end
  return 2
end
if ARGV[2] == "1" then
  return {0}
end
return 0
`;
const isFinished = {
    name: 'isFinished',
    content,
    keys: 3
}; //# sourceMappingURL=isFinished-3.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/isJobInList-1.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "isJobInList",
    ()=>isJobInList
]);
const content = `--[[
  Checks if job is in a given list.
  Input:
    KEYS[1]
    ARGV[1]
  Output:
    1 if element found in the list.
]]
-- Includes
--[[
  Functions to check if a item belongs to a list.
]]
local function checkItemInList(list, item)
  for _, v in pairs(list) do
    if v == item then
      return 1
    end
  end
  return nil
end
local items = redis.call("LRANGE", KEYS[1] , 0, -1)
return checkItemInList(items, ARGV[1])
`;
const isJobInList = {
    name: 'isJobInList',
    content,
    keys: 1
}; //# sourceMappingURL=isJobInList-1.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/isMaxed-2.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "isMaxed",
    ()=>isMaxed
]);
const content = `--[[
  Checks if queue is maxed.
  Input:
    KEYS[1] meta key
    KEYS[2] active key
  Output:
    1 if element found in the list.
]]
local rcall = redis.call
-- Includes
--[[
  Function to check if queue is maxed or not.
]]
local function isQueueMaxed(queueMetaKey, activeKey)
  local maxConcurrency = rcall("HGET", queueMetaKey, "concurrency")
  if maxConcurrency then
    local activeCount = rcall("LLEN", activeKey)
    if activeCount >= tonumber(maxConcurrency) then
      return true
    end
  end
  return false
end
return isQueueMaxed(KEYS[1], KEYS[2])
`;
const isMaxed = {
    name: 'isMaxed',
    content,
    keys: 2
}; //# sourceMappingURL=isMaxed-2.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/moveJobFromActiveToWait-9.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "moveJobFromActiveToWait",
    ()=>moveJobFromActiveToWait
]);
const content = `--[[
  Function to move job from active state to wait.
  Input:
    KEYS[1]  active key
    KEYS[2]  wait key
    KEYS[3]  stalled key
    KEYS[4]  paused key
    KEYS[5]  meta key
    KEYS[6]  limiter key
    KEYS[7]  prioritized key
    KEYS[8]  marker key
    KEYS[9]  event key
    ARGV[1] job id
    ARGV[2] lock token
    ARGV[3] job id key
]]
local rcall = redis.call
-- Includes
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to push back job considering priority in front of same prioritized jobs.
]]
local function pushBackJobWithPriority(prioritizedKey, priority, jobId)
  -- in order to put it at front of same prioritized jobs
  -- we consider prioritized counter as 0
  local score = priority * 0x100000000
  rcall("ZADD", prioritizedKey, score, jobId)
end
--[[
  Function to get max events value or set by default 10000.
]]
local function getOrSetMaxEvents(metaKey)
  local maxEvents = rcall("HGET", metaKey, "opts.maxLenEvents")
  if not maxEvents then
    maxEvents = 10000
    rcall("HSET", metaKey, "opts.maxLenEvents", maxEvents)
  end
  return maxEvents
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
local function removeLock(jobKey, stalledKey, token, jobId)
  if token ~= "0" then
    local lockKey = jobKey .. ':lock'
    local lockToken = rcall("GET", lockKey)
    if lockToken == token then
      rcall("DEL", lockKey)
      rcall("SREM", stalledKey, jobId)
    else
      if lockToken then
        -- Lock exists but token does not match
        return -6
      else
        -- Lock is missing completely
        return -2
      end
    end
  end
  return 0
end
local jobId = ARGV[1]
local token = ARGV[2]
local jobKey = ARGV[3]
if rcall("EXISTS", jobKey) == 0 then
  return -1
end
local errorCode = removeLock(jobKey, KEYS[3], token, jobId)
if errorCode < 0 then
  return errorCode
end
local metaKey = KEYS[5]
local removed = rcall("LREM", KEYS[1], 1, jobId)
if removed > 0 then
  local target, isPausedOrMaxed = getTargetQueueList(metaKey, KEYS[1], KEYS[2], KEYS[4])
  local priority = tonumber(rcall("HGET", ARGV[3], "priority")) or 0
  if priority > 0 then
    pushBackJobWithPriority(KEYS[7], priority, jobId)
  else
    addJobInTargetList(target, KEYS[8], "RPUSH", isPausedOrMaxed, jobId)
  end
  local maxEvents = getOrSetMaxEvents(metaKey)
  -- Emit waiting event
  rcall("XADD", KEYS[9], "MAXLEN", "~", maxEvents, "*", "event", "waiting",
    "jobId", jobId, "prev", "active")
end
local pttl = rcall("PTTL", KEYS[6])
if pttl > 0 then
  return pttl
else
  return 0
end
`;
const moveJobFromActiveToWait = {
    name: 'moveJobFromActiveToWait',
    content,
    keys: 9
}; //# sourceMappingURL=moveJobFromActiveToWait-9.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/moveJobsToWait-8.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "moveJobsToWait",
    ()=>moveJobsToWait
]);
const content = `--[[
  Move completed, failed or delayed jobs to wait.
  Note: Does not support jobs with priorities.
  Input:
    KEYS[1] base key
    KEYS[2] events stream
    KEYS[3] state key (failed, completed, delayed)
    KEYS[4] 'wait'
    KEYS[5] 'paused'
    KEYS[6] 'meta'
    KEYS[7] 'active'
    KEYS[8] 'marker'
    ARGV[1] count
    ARGV[2] timestamp
    ARGV[3] prev state
  Output:
    1  means the operation is not completed
    0  means the operation is completed
]]
local maxCount = tonumber(ARGV[1])
local timestamp = tonumber(ARGV[2])
local rcall = redis.call;
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
--[[
  Function to loop in batches.
  Just a bit of warning, some commands as ZREM
  could receive a maximum of 7000 parameters per call.
]]
local function batches(n, batchSize)
  local i = 0
  return function()
    local from = i * batchSize + 1
    i = i + 1
    if (from <= n) then
      local to = math.min(from + batchSize - 1, n)
      return from, to
    end
  end
end
--[[
  Function to get max events value or set by default 10000.
]]
local function getOrSetMaxEvents(metaKey)
  local maxEvents = rcall("HGET", metaKey, "opts.maxLenEvents")
  if not maxEvents then
    maxEvents = 10000
    rcall("HSET", metaKey, "opts.maxLenEvents", maxEvents)
  end
  return maxEvents
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
local metaKey = KEYS[6]
local target, isPausedOrMaxed = getTargetQueueList(metaKey, KEYS[7], KEYS[4], KEYS[5])
local jobs = rcall('ZRANGEBYSCORE', KEYS[3], 0, timestamp, 'LIMIT', 0, maxCount)
if (#jobs > 0) then
    if ARGV[3] == "failed" then
        for i, key in ipairs(jobs) do
            local jobKey = KEYS[1] .. key
            rcall("HDEL", jobKey, "finishedOn", "processedOn", "failedReason")
        end
    elseif ARGV[3] == "completed" then
        for i, key in ipairs(jobs) do
            local jobKey = KEYS[1] .. key
            rcall("HDEL", jobKey, "finishedOn", "processedOn", "returnvalue")
        end
    end
    local maxEvents = getOrSetMaxEvents(metaKey)
    for i, key in ipairs(jobs) do
        -- Emit waiting event
        rcall("XADD", KEYS[2], "MAXLEN", "~", maxEvents, "*", "event",
              "waiting", "jobId", key, "prev", ARGV[3]);
    end
    for from, to in batches(#jobs, 7000) do
        rcall("ZREM", KEYS[3], unpack(jobs, from, to))
        rcall("LPUSH", target, unpack(jobs, from, to))
    end
    addBaseMarkerIfNeeded(KEYS[8], isPausedOrMaxed)
end
maxCount = maxCount - #jobs
if (maxCount <= 0) then return 1 end
return 0
`;
const moveJobsToWait = {
    name: 'moveJobsToWait',
    content,
    keys: 8
}; //# sourceMappingURL=moveJobsToWait-8.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/moveStalledJobsToWait-8.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "moveStalledJobsToWait",
    ()=>moveStalledJobsToWait
]);
const content = `--[[
  Move stalled jobs to wait.
    Input:
      KEYS[1] 'stalled' (SET)
      KEYS[2] 'wait',   (LIST)
      KEYS[3] 'active', (LIST)
      KEYS[4] 'stalled-check', (KEY)
      KEYS[5] 'meta', (KEY)
      KEYS[6] 'paused', (LIST)
      KEYS[7] 'marker'
      KEYS[8] 'event stream' (STREAM)
      ARGV[1]  Max stalled job count
      ARGV[2]  queue.toKey('')
      ARGV[3]  timestamp
      ARGV[4]  max check time
    Events:
      'stalled' with stalled job id.
]]
local rcall = redis.call
-- Includes
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to loop in batches.
  Just a bit of warning, some commands as ZREM
  could receive a maximum of 7000 parameters per call.
]]
local function batches(n, batchSize)
  local i = 0
  return function()
    local from = i * batchSize + 1
    i = i + 1
    if (from <= n) then
      local to = math.min(from + batchSize - 1, n)
      return from, to
    end
  end
end
--[[
  Function to move job to wait to be picked up by a waiting worker.
]]
-- Includes
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
local function moveJobToWait(metaKey, activeKey, waitKey, pausedKey, markerKey, eventStreamKey,
  jobId, pushCmd)
  local target, isPausedOrMaxed = getTargetQueueList(metaKey, activeKey, waitKey, pausedKey)
  addJobInTargetList(target, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall("XADD", eventStreamKey, "*", "event", "waiting", "jobId", jobId, 'prev', 'active')
end
--[[
  Function to trim events, default 10000.
]]
-- Includes
--[[
  Function to get max events value or set by default 10000.
]]
local function getOrSetMaxEvents(metaKey)
  local maxEvents = rcall("HGET", metaKey, "opts.maxLenEvents")
  if not maxEvents then
    maxEvents = 10000
    rcall("HSET", metaKey, "opts.maxLenEvents", maxEvents)
  end
  return maxEvents
end
local function trimEvents(metaKey, eventStreamKey)
  local maxEvents = getOrSetMaxEvents(metaKey)
  if maxEvents then
    rcall("XTRIM", eventStreamKey, "MAXLEN", "~", maxEvents)
  else
    rcall("XTRIM", eventStreamKey, "MAXLEN", "~", 10000)
  end
end
local stalledKey = KEYS[1]
local waitKey = KEYS[2]
local activeKey = KEYS[3]
local stalledCheckKey = KEYS[4]
local metaKey = KEYS[5]
local pausedKey = KEYS[6]
local markerKey = KEYS[7]
local eventStreamKey = KEYS[8]
local maxStalledJobCount = tonumber(ARGV[1])
local queueKeyPrefix = ARGV[2]
local timestamp = ARGV[3]
local maxCheckTime = ARGV[4]
if rcall("EXISTS", stalledCheckKey) == 1 then
    return {}
end
rcall("SET", stalledCheckKey, timestamp, "PX", maxCheckTime)
-- Trim events before emiting them to avoid trimming events emitted in this script
trimEvents(metaKey, eventStreamKey)
-- Move all stalled jobs to wait
local stalling = rcall('SMEMBERS', stalledKey)
local stalled = {}
if (#stalling > 0) then
    rcall('DEL', stalledKey)
    -- Remove from active list
    for i, jobId in ipairs(stalling) do
        -- Markers in waitlist DEPRECATED in v5: Remove in v6.
        if string.sub(jobId, 1, 2) == "0:" then
            -- If the jobId is a delay marker ID we just remove it.
            rcall("LREM", activeKey, 1, jobId)
        else
            local jobKey = queueKeyPrefix .. jobId
            -- Check that the lock is also missing, then we can handle this job as really stalled.
            if (rcall("EXISTS", jobKey .. ":lock") == 0) then
                --  Remove from the active queue.
                local removed = rcall("LREM", activeKey, 1, jobId)
                if (removed > 0) then
                    -- If this job has been stalled too many times, such as if it crashes the worker, then fail it.
                    local stalledCount = rcall("HINCRBY", jobKey, "stc", 1)
                    -- Check if this is a repeatable job by looking at job options
                    local jobOpts = rcall("HGET", jobKey, "opts")
                    local isRepeatableJob = false
                    if jobOpts then
                        local opts = cjson.decode(jobOpts)
                        if opts and opts["repeat"] then
                            isRepeatableJob = true
                        end
                    end
                    -- Only fail job if it exceeds stall limit AND is not a repeatable job
                    if stalledCount > maxStalledJobCount and not isRepeatableJob then
                        local failedReason = "job stalled more than allowable limit"
                        rcall("HSET", jobKey, "defa", failedReason)
                    end
                    moveJobToWait(metaKey, activeKey, waitKey, pausedKey, markerKey, eventStreamKey, jobId,
                        "RPUSH")
                    -- Emit the stalled event
                    rcall("XADD", eventStreamKey, "*", "event", "stalled", "jobId", jobId)
                    table.insert(stalled, jobId)
                end
            end
        end
    end
end
-- Mark potentially stalled jobs
local active = rcall('LRANGE', activeKey, 0, -1)
if (#active > 0) then
    for from, to in batches(#active, 7000) do
        rcall('SADD', stalledKey, unpack(active, from, to))
    end
end
return stalled
`;
const moveStalledJobsToWait = {
    name: 'moveStalledJobsToWait',
    content,
    keys: 8
}; //# sourceMappingURL=moveStalledJobsToWait-8.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/moveToActive-11.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "moveToActive",
    ()=>moveToActive
]);
const content = `--[[
  Move next job to be processed to active, lock it and fetch its data. The job
  may be delayed, in that case we need to move it to the delayed set instead.
  This operation guarantees that the worker owns the job during the lock
  expiration time. The worker is responsible of keeping the lock fresh
  so that no other worker picks this job again.
  Input:
    KEYS[1] wait key
    KEYS[2] active key
    KEYS[3] prioritized key
    KEYS[4] stream events key
    KEYS[5] stalled key
    -- Rate limiting
    KEYS[6] rate limiter key
    KEYS[7] delayed key
    -- Delayed jobs
    KEYS[8] paused key
    KEYS[9] meta key
    KEYS[10] pc priority counter
    -- Marker
    KEYS[11] marker key
    -- Arguments
    ARGV[1] key prefix
    ARGV[2] timestamp
    ARGV[3] opts
    opts - token - lock token
    opts - lockDuration
    opts - limiter
    opts - name - worker name
]]
local rcall = redis.call
local waitKey = KEYS[1]
local activeKey = KEYS[2]
local eventStreamKey = KEYS[4]
local rateLimiterKey = KEYS[6]
local delayedKey = KEYS[7]
local opts = cmsgpack.unpack(ARGV[3])
-- Includes
--[[
  Function to return the next delayed job timestamp.
]]
local function getNextDelayedTimestamp(delayedKey)
  local result = rcall("ZRANGE", delayedKey, 0, 0, "WITHSCORES")
  if #result then
    local nextTimestamp = tonumber(result[2])
    if nextTimestamp ~= nil then
      return nextTimestamp / 0x1000
    end
  end
end
--[[
  Function to get current rate limit ttl.
]]
local function getRateLimitTTL(maxJobs, rateLimiterKey)
  if maxJobs and maxJobs <= tonumber(rcall("GET", rateLimiterKey) or 0) then
    local pttl = rcall("PTTL", rateLimiterKey)
    if pttl == 0 then
      rcall("DEL", rateLimiterKey)
    end
    if pttl > 0 then
      return pttl
    end
  end
  return 0
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
--[[
  Function to move job from prioritized state to active.
]]
local function moveJobFromPrioritizedToActive(priorityKey, activeKey, priorityCounterKey)
  local prioritizedJob = rcall("ZPOPMIN", priorityKey)
  if #prioritizedJob > 0 then
    rcall("LPUSH", activeKey, prioritizedJob[1])
    return prioritizedJob[1]
  else
    rcall("DEL", priorityCounterKey)
  end
end
--[[
  Function to move job from wait state to active.
  Input:
    opts - token - lock token
    opts - lockDuration
    opts - limiter
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
local function prepareJobForProcessing(keyPrefix, rateLimiterKey, eventStreamKey,
    jobId, processedOn, maxJobs, limiterDuration, markerKey, opts)
  local jobKey = keyPrefix .. jobId
  -- Check if we need to perform rate limiting.
  if maxJobs then
    local jobCounter = tonumber(rcall("INCR", rateLimiterKey))
    if jobCounter == 1 then
      local integerDuration = math.floor(math.abs(limiterDuration))
      rcall("PEXPIRE", rateLimiterKey, integerDuration)
    end
  end
  -- get a lock
  if opts['token'] ~= "0" then
    local lockKey = jobKey .. ':lock'
    rcall("SET", lockKey, opts['token'], "PX", opts['lockDuration'])
  end
  local optionalValues = {}
  if opts['name'] then
    -- Set "processedBy" field to the worker name
    table.insert(optionalValues, "pb")
    table.insert(optionalValues, opts['name'])
  end
  rcall("XADD", eventStreamKey, "*", "event", "active", "jobId", jobId, "prev", "waiting")
  rcall("HMSET", jobKey, "processedOn", processedOn, unpack(optionalValues))
  rcall("HINCRBY", jobKey, "ats", 1)
  addBaseMarkerIfNeeded(markerKey, false)
  -- rate limit delay must be 0 in this case to prevent adding more delay
  -- when job that is moved to active needs to be processed
  return {rcall("HGETALL", jobKey), jobId, 0, 0} -- get job data
end
--[[
  Updates the delay set, by moving delayed jobs that should
  be processed now to "wait".
     Events:
      'waiting'
]]
-- Includes
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to add job considering priority.
]]
-- Includes
--[[
  Function to get priority score.
]]
local function getPriorityScore(priority, priorityCounterKey)
  local prioCounter = rcall("INCR", priorityCounterKey)
  return priority * 0x100000000 + prioCounter % 0x100000000
end
local function addJobWithPriority(markerKey, prioritizedKey, priority, jobId, priorityCounterKey,
  isPausedOrMaxed)
  local score = getPriorityScore(priority, priorityCounterKey)
  rcall("ZADD", prioritizedKey, score, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
-- Try to get as much as 1000 jobs at once
local function promoteDelayedJobs(delayedKey, markerKey, targetKey, prioritizedKey,
                                  eventStreamKey, prefix, timestamp, priorityCounterKey, isPaused)
    local jobs = rcall("ZRANGEBYSCORE", delayedKey, 0, (timestamp + 1) * 0x1000 - 1, "LIMIT", 0, 1000)
    if (#jobs > 0) then
        rcall("ZREM", delayedKey, unpack(jobs))
        for _, jobId in ipairs(jobs) do
            local jobKey = prefix .. jobId
            local priority =
                tonumber(rcall("HGET", jobKey, "priority")) or 0
            if priority == 0 then
                -- LIFO or FIFO
                rcall("LPUSH", targetKey, jobId)
            else
                local score = getPriorityScore(priority, priorityCounterKey)
                rcall("ZADD", prioritizedKey, score, jobId)
            end
            -- Emit waiting event
            rcall("XADD", eventStreamKey, "*", "event", "waiting", "jobId",
                  jobId, "prev", "delayed")
            rcall("HSET", jobKey, "delay", 0)
        end
        addBaseMarkerIfNeeded(markerKey, isPaused)
    end
end
local target, isPausedOrMaxed, rateLimitMax, rateLimitDuration = getTargetQueueList(KEYS[9],
    activeKey, waitKey, KEYS[8])
-- Check if there are delayed jobs that we can move to wait.
local markerKey = KEYS[11]
promoteDelayedJobs(delayedKey, markerKey, target, KEYS[3], eventStreamKey, ARGV[1],
                   ARGV[2], KEYS[10], isPausedOrMaxed)
local maxJobs = tonumber(rateLimitMax or (opts['limiter'] and opts['limiter']['max']))
local expireTime = getRateLimitTTL(maxJobs, rateLimiterKey)
-- Check if we are rate limited first.
if expireTime > 0 then return {0, 0, expireTime, 0} end
-- paused or maxed queue
if isPausedOrMaxed then return {0, 0, 0, 0} end
local limiterDuration = (opts['limiter'] and opts['limiter']['duration']) or rateLimitDuration
-- no job ID, try non-blocking move from wait to active
local jobId = rcall("RPOPLPUSH", waitKey, activeKey)
-- Markers in waitlist DEPRECATED in v5: Will be completely removed in v6.
if jobId and string.sub(jobId, 1, 2) == "0:" then
    rcall("LREM", activeKey, 1, jobId)
    jobId = rcall("RPOPLPUSH", waitKey, activeKey)
end
if jobId then
    return prepareJobForProcessing(ARGV[1], rateLimiterKey, eventStreamKey, jobId, ARGV[2],
                                   maxJobs, limiterDuration, markerKey, opts)
else
    jobId = moveJobFromPrioritizedToActive(KEYS[3], activeKey, KEYS[10])
    if jobId then
        return prepareJobForProcessing(ARGV[1], rateLimiterKey, eventStreamKey, jobId, ARGV[2],
                                       maxJobs, limiterDuration, markerKey, opts)
    end
end
-- Return the timestamp for the next delayed job if any.
local nextTimestamp = getNextDelayedTimestamp(delayedKey)
if nextTimestamp ~= nil then return {0, 0, 0, nextTimestamp} end
return {0, 0, 0, 0}
`;
const moveToActive = {
    name: 'moveToActive',
    content,
    keys: 11
}; //# sourceMappingURL=moveToActive-11.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/moveToDelayed-8.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "moveToDelayed",
    ()=>moveToDelayed
]);
const content = `--[[
  Moves job from active to delayed set.
  Input:
    KEYS[1] marker key
    KEYS[2] active key
    KEYS[3] prioritized key
    KEYS[4] delayed key
    KEYS[5] job key
    KEYS[6] events stream
    KEYS[7] meta key
    KEYS[8] stalled key
    ARGV[1] key prefix
    ARGV[2] timestamp
    ARGV[3] the id of the job
    ARGV[4] queue token
    ARGV[5] delay value
    ARGV[6] skip attempt
    ARGV[7] optional job fields to update
  Output:
    0 - OK
   -1 - Missing job.
   -3 - Job not in active set.
  Events:
    - delayed key.
]]
local rcall = redis.call
-- Includes
--[[
  Add delay marker if needed.
]]
-- Includes
--[[
  Function to return the next delayed job timestamp.
]]
local function getNextDelayedTimestamp(delayedKey)
  local result = rcall("ZRANGE", delayedKey, 0, 0, "WITHSCORES")
  if #result then
    local nextTimestamp = tonumber(result[2])
    if nextTimestamp ~= nil then
      return nextTimestamp / 0x1000
    end
  end
end
local function addDelayMarkerIfNeeded(markerKey, delayedKey)
  local nextTimestamp = getNextDelayedTimestamp(delayedKey)
  if nextTimestamp ~= nil then
    -- Replace the score of the marker with the newest known
    -- next timestamp.
    rcall("ZADD", markerKey, nextTimestamp, "1")
  end
end
--[[
  Bake in the job id first 12 bits into the timestamp
  to guarantee correct execution order of delayed jobs
  (up to 4096 jobs per given timestamp or 4096 jobs apart per timestamp)
  WARNING: Jobs that are so far apart that they wrap around will cause FIFO to fail
]]
local function getDelayedScore(delayedKey, timestamp, delay)
  local delayedTimestamp = (delay > 0 and (tonumber(timestamp) + delay)) or tonumber(timestamp)
  local minScore = delayedTimestamp * 0x1000
  local maxScore = (delayedTimestamp + 1 ) * 0x1000 - 1
  local result = rcall("ZREVRANGEBYSCORE", delayedKey, maxScore,
    minScore, "WITHSCORES","LIMIT", 0, 1)
  if #result then
    local currentMaxScore = tonumber(result[2])
    if currentMaxScore ~= nil then
      if currentMaxScore >= maxScore then
        return maxScore, delayedTimestamp
      else
        return currentMaxScore + 1, delayedTimestamp
      end
    end
  end
  return minScore, delayedTimestamp
end
--[[
  Function to get max events value or set by default 10000.
]]
local function getOrSetMaxEvents(metaKey)
  local maxEvents = rcall("HGET", metaKey, "opts.maxLenEvents")
  if not maxEvents then
    maxEvents = 10000
    rcall("HSET", metaKey, "opts.maxLenEvents", maxEvents)
  end
  return maxEvents
end
local function removeLock(jobKey, stalledKey, token, jobId)
  if token ~= "0" then
    local lockKey = jobKey .. ':lock'
    local lockToken = rcall("GET", lockKey)
    if lockToken == token then
      rcall("DEL", lockKey)
      rcall("SREM", stalledKey, jobId)
    else
      if lockToken then
        -- Lock exists but token does not match
        return -6
      else
        -- Lock is missing completely
        return -2
      end
    end
  end
  return 0
end
--[[
  Function to update a bunch of fields in a job.
]]
local function updateJobFields(jobKey, msgpackedFields)
  if msgpackedFields and #msgpackedFields > 0 then
    local fieldsToUpdate = cmsgpack.unpack(msgpackedFields)
    if fieldsToUpdate then
      rcall("HMSET", jobKey, unpack(fieldsToUpdate))
    end
  end
end
local jobKey = KEYS[5]
local metaKey = KEYS[7]
local token = ARGV[4] 
if rcall("EXISTS", jobKey) == 1 then
    local errorCode = removeLock(jobKey, KEYS[8], token, ARGV[3])
    if errorCode < 0 then
        return errorCode
    end
    updateJobFields(jobKey, ARGV[7])
    local delayedKey = KEYS[4]
    local jobId = ARGV[3]
    local delay = tonumber(ARGV[5])
    local numRemovedElements = rcall("LREM", KEYS[2], -1, jobId)
    if numRemovedElements < 1 then return -3 end
    local score, delayedTimestamp = getDelayedScore(delayedKey, ARGV[2], delay)
    if ARGV[6] == "0" then
        rcall("HINCRBY", jobKey, "atm", 1)
    end
    rcall("HSET", jobKey, "delay", ARGV[5])
    local maxEvents = getOrSetMaxEvents(metaKey)
    rcall("ZADD", delayedKey, score, jobId)
    rcall("XADD", KEYS[6], "MAXLEN", "~", maxEvents, "*", "event", "delayed",
          "jobId", jobId, "delay", delayedTimestamp)
    -- Check if we need to push a marker job to wake up sleeping workers.
    local markerKey = KEYS[1]
    addDelayMarkerIfNeeded(markerKey, delayedKey)
    return 0
else
    return -1
end
`;
const moveToDelayed = {
    name: 'moveToDelayed',
    content,
    keys: 8
}; //# sourceMappingURL=moveToDelayed-8.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/moveToFinished-14.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "moveToFinished",
    ()=>moveToFinished
]);
const content = `--[[
  Move job from active to a finished status (completed o failed)
  A job can only be moved to completed if it was active.
  The job must be locked before it can be moved to a finished status,
  and the lock must be released in this script.
    Input:
      KEYS[1] wait key
      KEYS[2] active key
      KEYS[3] prioritized key
      KEYS[4] event stream key
      KEYS[5] stalled key
      -- Rate limiting
      KEYS[6] rate limiter key
      KEYS[7] delayed key
      KEYS[8] paused key
      KEYS[9] meta key
      KEYS[10] pc priority counter
      KEYS[11] completed/failed key
      KEYS[12] jobId key
      KEYS[13] metrics key
      KEYS[14] marker key
      ARGV[1]  jobId
      ARGV[2]  timestamp
      ARGV[3]  msg property returnvalue / failedReason
      ARGV[4]  return value / failed reason
      ARGV[5]  target (completed/failed)
      ARGV[6]  fetch next?
      ARGV[7]  keys prefix
      ARGV[8]  opts
      ARGV[9]  job fields to update
      opts - token - lock token
      opts - keepJobs
      opts - lockDuration - lock duration in milliseconds
      opts - attempts max attempts
      opts - maxMetricsSize
      opts - fpof - fail parent on fail
      opts - cpof - continue parent on fail
      opts - idof - ignore dependency on fail
      opts - rdof - remove dependency on fail
      opts - name - worker name
    Output:
      0 OK
      -1 Missing key.
      -2 Missing lock.
      -3 Job not in active set
      -4 Job has pending children
      -6 Lock is not owned by this client
      -9 Job has failed children
    Events:
      'completed/failed'
]]
local rcall = redis.call
--- Includes
--[[
  Functions to collect metrics based on a current and previous count of jobs.
  Granualarity is fixed at 1 minute.
]]
--[[
  Function to loop in batches.
  Just a bit of warning, some commands as ZREM
  could receive a maximum of 7000 parameters per call.
]]
local function batches(n, batchSize)
  local i = 0
  return function()
    local from = i * batchSize + 1
    i = i + 1
    if (from <= n) then
      local to = math.min(from + batchSize - 1, n)
      return from, to
    end
  end
end
local function collectMetrics(metaKey, dataPointsList, maxDataPoints,
                                 timestamp)
    -- Increment current count
    local count = rcall("HINCRBY", metaKey, "count", 1) - 1
    -- Compute how many data points we need to add to the list, N.
    local prevTS = rcall("HGET", metaKey, "prevTS")
    if not prevTS then
        -- If prevTS is nil, set it to the current timestamp
        rcall("HSET", metaKey, "prevTS", timestamp, "prevCount", 0)
        return
    end
    local N = math.min(math.floor(timestamp / 60000) - math.floor(prevTS / 60000), tonumber(maxDataPoints))
    if N > 0 then
        local delta = count - rcall("HGET", metaKey, "prevCount")
        -- If N > 1, add N-1 zeros to the list
        if N > 1 then
            local points = {}
            points[1] = delta
            for i = 2, N do
                points[i] = 0
            end
            for from, to in batches(#points, 7000) do
                rcall("LPUSH", dataPointsList, unpack(points, from, to))
            end
        else
            -- LPUSH delta to the list
            rcall("LPUSH", dataPointsList, delta)
        end
        -- LTRIM to keep list to its max size
        rcall("LTRIM", dataPointsList, 0, maxDataPoints - 1)
        -- update prev count with current count
        rcall("HSET", metaKey, "prevCount", count, "prevTS", timestamp)
    end
end
--[[
  Function to return the next delayed job timestamp.
]]
local function getNextDelayedTimestamp(delayedKey)
  local result = rcall("ZRANGE", delayedKey, 0, 0, "WITHSCORES")
  if #result then
    local nextTimestamp = tonumber(result[2])
    if nextTimestamp ~= nil then
      return nextTimestamp / 0x1000
    end
  end
end
--[[
  Function to get current rate limit ttl.
]]
local function getRateLimitTTL(maxJobs, rateLimiterKey)
  if maxJobs and maxJobs <= tonumber(rcall("GET", rateLimiterKey) or 0) then
    local pttl = rcall("PTTL", rateLimiterKey)
    if pttl == 0 then
      rcall("DEL", rateLimiterKey)
    end
    if pttl > 0 then
      return pttl
    end
  end
  return 0
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
--[[
  Function to move job from prioritized state to active.
]]
local function moveJobFromPrioritizedToActive(priorityKey, activeKey, priorityCounterKey)
  local prioritizedJob = rcall("ZPOPMIN", priorityKey)
  if #prioritizedJob > 0 then
    rcall("LPUSH", activeKey, prioritizedJob[1])
    return prioritizedJob[1]
  else
    rcall("DEL", priorityCounterKey)
  end
end
--[[
  Function to recursively move from waitingChildren to failed.
]]
-- Includes
--[[
  Validate and move parent to a wait status (waiting, delayed or prioritized)
  if no pending dependencies.
]]
-- Includes
--[[
  Validate and move parent to a wait status (waiting, delayed or prioritized) if needed.
]]
-- Includes
--[[
  Move parent to a wait status (wait, prioritized or delayed)
]]
-- Includes
--[[
  Add delay marker if needed.
]]
-- Includes
local function addDelayMarkerIfNeeded(markerKey, delayedKey)
  local nextTimestamp = getNextDelayedTimestamp(delayedKey)
  if nextTimestamp ~= nil then
    -- Replace the score of the marker with the newest known
    -- next timestamp.
    rcall("ZADD", markerKey, nextTimestamp, "1")
  end
end
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to add job considering priority.
]]
-- Includes
--[[
  Function to get priority score.
]]
local function getPriorityScore(priority, priorityCounterKey)
  local prioCounter = rcall("INCR", priorityCounterKey)
  return priority * 0x100000000 + prioCounter % 0x100000000
end
local function addJobWithPriority(markerKey, prioritizedKey, priority, jobId, priorityCounterKey,
  isPausedOrMaxed)
  local score = getPriorityScore(priority, priorityCounterKey)
  rcall("ZADD", prioritizedKey, score, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to check if queue is paused or maxed
  (since an empty list and !EXISTS are not really the same).
]]
local function isQueuePausedOrMaxed(queueMetaKey, activeKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency")
  if queueAttributes[1] then
    return true
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      return activeCount >= tonumber(queueAttributes[2])
    end
  end
  return false
end
local function moveParentToWait(parentQueueKey, parentKey, parentId, timestamp)
    local parentWaitKey = parentQueueKey .. ":wait"
    local parentPausedKey = parentQueueKey .. ":paused"
    local parentActiveKey = parentQueueKey .. ":active"
    local parentMetaKey = parentQueueKey .. ":meta"
    local parentMarkerKey = parentQueueKey .. ":marker"
    local jobAttributes = rcall("HMGET", parentKey, "priority", "delay")
    local priority = tonumber(jobAttributes[1]) or 0
    local delay = tonumber(jobAttributes[2]) or 0
    if delay > 0 then
        local delayedTimestamp = tonumber(timestamp) + delay
        local score = delayedTimestamp * 0x1000
        local parentDelayedKey = parentQueueKey .. ":delayed"
        rcall("ZADD", parentDelayedKey, score, parentId)
        rcall("XADD", parentQueueKey .. ":events", "*", "event", "delayed", "jobId", parentId, "delay",
            delayedTimestamp)
        addDelayMarkerIfNeeded(parentMarkerKey, parentDelayedKey)
    else
        if priority == 0 then
            local parentTarget, isParentPausedOrMaxed = getTargetQueueList(parentMetaKey, parentActiveKey,
                parentWaitKey, parentPausedKey)
            addJobInTargetList(parentTarget, parentMarkerKey, "RPUSH", isParentPausedOrMaxed, parentId)
        else
            local isPausedOrMaxed = isQueuePausedOrMaxed(parentMetaKey, parentActiveKey)
            addJobWithPriority(parentMarkerKey, parentQueueKey .. ":prioritized", priority, parentId,
                parentQueueKey .. ":pc", isPausedOrMaxed)
        end
        rcall("XADD", parentQueueKey .. ":events", "*", "event", "waiting", "jobId", parentId, "prev",
            "waiting-children")
    end
end
local function moveParentToWaitIfNeeded(parentQueueKey, parentKey, parentId, timestamp)
  if rcall("EXISTS", parentKey) == 1 then
    local parentWaitingChildrenKey = parentQueueKey .. ":waiting-children"
    if rcall("ZSCORE", parentWaitingChildrenKey, parentId) then    
      rcall("ZREM", parentWaitingChildrenKey, parentId)
      moveParentToWait(parentQueueKey, parentKey, parentId, timestamp)
    end
  end
end
local function moveParentToWaitIfNoPendingDependencies(parentQueueKey, parentDependenciesKey, parentKey,
  parentId, timestamp)
  local doNotHavePendingDependencies = rcall("SCARD", parentDependenciesKey) == 0
  if doNotHavePendingDependencies then
    moveParentToWaitIfNeeded(parentQueueKey, parentKey, parentId, timestamp)
  end
end
--[[
  Functions to remove jobs when removeOnFail option is provided.
]]
-- Includes
--[[
  Function to remove job.
]]
-- Includes
--[[
  Function to remove deduplication key if needed
  when a job is being removed.
]]
local function removeDeduplicationKeyIfNeededOnRemoval(prefixKey,
  jobKey, jobId)
  local deduplicationId = rcall("HGET", jobKey, "deid")
  if deduplicationId then
    local deduplicationKey = prefixKey .. "de:" .. deduplicationId
    local currentJobId = rcall('GET', deduplicationKey)
    if currentJobId and currentJobId == jobId then
      return rcall("DEL", deduplicationKey)
    end
  end
end
--[[
  Function to remove job keys.
]]
local function removeJobKeys(jobKey)
  return rcall("DEL", jobKey, jobKey .. ':logs', jobKey .. ':dependencies',
    jobKey .. ':processed', jobKey .. ':failed', jobKey .. ':unsuccessful')
end
--[[
  Check if this job has a parent. If so we will just remove it from
  the parent child list, but if it is the last child we should move the parent to "wait/paused"
  which requires code from "moveToFinished"
]]
-- Includes
--[[
  Functions to destructure job key.
  Just a bit of warning, these functions may be a bit slow and affect performance significantly.
]]
local getJobIdFromKey = function (jobKey)
  return string.match(jobKey, ".*:(.*)")
end
local getJobKeyPrefix = function (jobKey, jobId)
  return string.sub(jobKey, 0, #jobKey - #jobId)
end
local function _moveParentToWait(parentPrefix, parentId, emitEvent)
  local parentTarget, isPausedOrMaxed = getTargetQueueList(parentPrefix .. "meta", parentPrefix .. "active",
    parentPrefix .. "wait", parentPrefix .. "paused")
  addJobInTargetList(parentTarget, parentPrefix .. "marker", "RPUSH", isPausedOrMaxed, parentId)
  if emitEvent then
    local parentEventStream = parentPrefix .. "events"
    rcall("XADD", parentEventStream, "*", "event", "waiting", "jobId", parentId, "prev", "waiting-children")
  end
end
local function removeParentDependencyKey(jobKey, hard, parentKey, baseKey, debounceId)
  if parentKey then
    local parentDependenciesKey = parentKey .. ":dependencies"
    local result = rcall("SREM", parentDependenciesKey, jobKey)
    if result > 0 then
      local pendingDependencies = rcall("SCARD", parentDependenciesKey)
      if pendingDependencies == 0 then
        local parentId = getJobIdFromKey(parentKey)
        local parentPrefix = getJobKeyPrefix(parentKey, parentId)
        local numRemovedElements = rcall("ZREM", parentPrefix .. "waiting-children", parentId)
        if numRemovedElements == 1 then
          if hard then -- remove parent in same queue
            if parentPrefix == baseKey then
              removeParentDependencyKey(parentKey, hard, nil, baseKey, nil)
              removeJobKeys(parentKey)
              if debounceId then
                rcall("DEL", parentPrefix .. "de:" .. debounceId)
              end
            else
              _moveParentToWait(parentPrefix, parentId)
            end
          else
            _moveParentToWait(parentPrefix, parentId, true)
          end
        end
      end
      return true
    end
  else
    local parentAttributes = rcall("HMGET", jobKey, "parentKey", "deid")
    local missedParentKey = parentAttributes[1]
    if( (type(missedParentKey) == "string") and missedParentKey ~= ""
      and (rcall("EXISTS", missedParentKey) == 1)) then
      local parentDependenciesKey = missedParentKey .. ":dependencies"
      local result = rcall("SREM", parentDependenciesKey, jobKey)
      if result > 0 then
        local pendingDependencies = rcall("SCARD", parentDependenciesKey)
        if pendingDependencies == 0 then
          local parentId = getJobIdFromKey(missedParentKey)
          local parentPrefix = getJobKeyPrefix(missedParentKey, parentId)
          local numRemovedElements = rcall("ZREM", parentPrefix .. "waiting-children", parentId)
          if numRemovedElements == 1 then
            if hard then
              if parentPrefix == baseKey then
                removeParentDependencyKey(missedParentKey, hard, nil, baseKey, nil)
                removeJobKeys(missedParentKey)
                if parentAttributes[2] then
                  rcall("DEL", parentPrefix .. "de:" .. parentAttributes[2])
                end
              else
                _moveParentToWait(parentPrefix, parentId)
              end
            else
              _moveParentToWait(parentPrefix, parentId, true)
            end
          end
        end
        return true
      end
    end
  end
  return false
end
local function removeJob(jobId, hard, baseKey, shouldRemoveDeduplicationKey)
  local jobKey = baseKey .. jobId
  removeParentDependencyKey(jobKey, hard, nil, baseKey)
  if shouldRemoveDeduplicationKey then
    removeDeduplicationKeyIfNeededOnRemoval(baseKey, jobKey, jobId)
  end
  removeJobKeys(jobKey)
end
--[[
  Functions to remove jobs by max age.
]]
-- Includes
local function removeJobsByMaxAge(timestamp, maxAge, targetSet, prefix,
  shouldRemoveDebounceKey)
  local start = timestamp - maxAge * 1000
  local jobIds = rcall("ZREVRANGEBYSCORE", targetSet, start, "-inf")
  for i, jobId in ipairs(jobIds) do
    removeJob(jobId, false, prefix, false --[[remove debounce key]])
  end
  rcall("ZREMRANGEBYSCORE", targetSet, "-inf", start)
end
--[[
  Functions to remove jobs by max count.
]]
-- Includes
local function removeJobsByMaxCount(maxCount, targetSet, prefix)
  local start = maxCount
  local jobIds = rcall("ZREVRANGE", targetSet, start, -1)
  for i, jobId in ipairs(jobIds) do
    removeJob(jobId, false, prefix, false --[[remove debounce key]])
  end
  rcall("ZREMRANGEBYRANK", targetSet, 0, -(maxCount + 1))
end
local function removeJobsOnFail(queueKeyPrefix, failedKey, jobId, opts, timestamp)
  local removeOnFailType = type(opts["removeOnFail"])
  if removeOnFailType == "number" then
    removeJobsByMaxCount(opts["removeOnFail"],
                        failedKey, queueKeyPrefix)
  elseif removeOnFailType == "boolean" then
    if opts["removeOnFail"] then
      removeJob(jobId, false, queueKeyPrefix,
                false --[[remove debounce key]])
      rcall("ZREM", failedKey, jobId)
    end
  elseif removeOnFailType ~= "nil" then
    local maxAge = opts["removeOnFail"]["age"]
    local maxCount = opts["removeOnFail"]["count"]
    if maxAge ~= nil then
      removeJobsByMaxAge(timestamp, maxAge,
                        failedKey, queueKeyPrefix)
    end
    if maxCount ~= nil and maxCount > 0 then
      removeJobsByMaxCount(maxCount, failedKey,
                            queueKeyPrefix)
    end
  end 
end
local moveParentToFailedIfNeeded = function (parentQueueKey, parentKey, parentId, jobIdKey, timestamp)
  if rcall("EXISTS", parentKey) == 1 then
    local parentWaitingChildrenKey = parentQueueKey .. ":waiting-children"
    local parentDelayedKey = parentQueueKey .. ":delayed"
    local parentPrioritizedKey = parentQueueKey .. ":prioritized"
    local parentWaitingChildrenOrDelayedKey
    local prevState
    if rcall("ZSCORE", parentWaitingChildrenKey, parentId) then
      parentWaitingChildrenOrDelayedKey = parentWaitingChildrenKey
      prevState = "waiting-children"
    elseif rcall("ZSCORE", parentDelayedKey, parentId) then
      parentWaitingChildrenOrDelayedKey = parentDelayedKey
      prevState = "delayed"
      rcall("HSET", parentKey, "delay", 0)
    end
    if parentWaitingChildrenOrDelayedKey then
      rcall("ZREM", parentWaitingChildrenOrDelayedKey, parentId)
      local parentQueuePrefix = parentQueueKey .. ":"
      local parentFailedKey = parentQueueKey .. ":failed"
      local deferredFailure = "child " .. jobIdKey .. " failed"
      rcall("HSET", parentKey, "defa", deferredFailure)
      moveParentToWait(parentQueueKey, parentKey, parentId, timestamp)
    else
      if not rcall("ZSCORE", parentQueueKey .. ":failed", parentId) then
        local deferredFailure = "child " .. jobIdKey .. " failed"
        rcall("HSET", parentKey, "defa", deferredFailure)
      end
    end
  end
end
local moveChildFromDependenciesIfNeeded = function (rawParentData, childKey, failedReason, timestamp)
  if rawParentData then
    local parentData = cjson.decode(rawParentData)
    local parentKey = parentData['queueKey'] .. ':' .. parentData['id']
    local parentDependenciesChildrenKey = parentKey .. ":dependencies"
    if parentData['fpof'] then
      if rcall("SREM", parentDependenciesChildrenKey, childKey) == 1 then
        local parentUnsuccesssfulChildrenKey = parentKey .. ":unsuccessful"
        rcall("ZADD", parentUnsuccesssfulChildrenKey, timestamp, childKey)
        moveParentToFailedIfNeeded(
          parentData['queueKey'],
          parentKey,
          parentData['id'],
          childKey,
          timestamp
        )
      end
    elseif parentData['cpof'] then
      if rcall("SREM", parentDependenciesChildrenKey, childKey) == 1 then
        local parentFailedChildrenKey = parentKey .. ":failed"
        rcall("HSET", parentFailedChildrenKey, childKey, failedReason)
        moveParentToWaitIfNeeded(parentData['queueKey'], parentKey, parentData['id'], timestamp)
      end
    elseif parentData['idof'] or parentData['rdof'] then
      if rcall("SREM", parentDependenciesChildrenKey, childKey) == 1 then
        moveParentToWaitIfNoPendingDependencies(parentData['queueKey'], parentDependenciesChildrenKey,
          parentKey, parentData['id'], timestamp)
        if parentData['idof'] then
          local parentFailedChildrenKey = parentKey .. ":failed"
          rcall("HSET", parentFailedChildrenKey, childKey, failedReason)
        end
      end
    end
  end
end
--[[
  Function to move job from wait state to active.
  Input:
    opts - token - lock token
    opts - lockDuration
    opts - limiter
]]
-- Includes
local function prepareJobForProcessing(keyPrefix, rateLimiterKey, eventStreamKey,
    jobId, processedOn, maxJobs, limiterDuration, markerKey, opts)
  local jobKey = keyPrefix .. jobId
  -- Check if we need to perform rate limiting.
  if maxJobs then
    local jobCounter = tonumber(rcall("INCR", rateLimiterKey))
    if jobCounter == 1 then
      local integerDuration = math.floor(math.abs(limiterDuration))
      rcall("PEXPIRE", rateLimiterKey, integerDuration)
    end
  end
  -- get a lock
  if opts['token'] ~= "0" then
    local lockKey = jobKey .. ':lock'
    rcall("SET", lockKey, opts['token'], "PX", opts['lockDuration'])
  end
  local optionalValues = {}
  if opts['name'] then
    -- Set "processedBy" field to the worker name
    table.insert(optionalValues, "pb")
    table.insert(optionalValues, opts['name'])
  end
  rcall("XADD", eventStreamKey, "*", "event", "active", "jobId", jobId, "prev", "waiting")
  rcall("HMSET", jobKey, "processedOn", processedOn, unpack(optionalValues))
  rcall("HINCRBY", jobKey, "ats", 1)
  addBaseMarkerIfNeeded(markerKey, false)
  -- rate limit delay must be 0 in this case to prevent adding more delay
  -- when job that is moved to active needs to be processed
  return {rcall("HGETALL", jobKey), jobId, 0, 0} -- get job data
end
--[[
  Updates the delay set, by moving delayed jobs that should
  be processed now to "wait".
     Events:
      'waiting'
]]
-- Includes
-- Try to get as much as 1000 jobs at once
local function promoteDelayedJobs(delayedKey, markerKey, targetKey, prioritizedKey,
                                  eventStreamKey, prefix, timestamp, priorityCounterKey, isPaused)
    local jobs = rcall("ZRANGEBYSCORE", delayedKey, 0, (timestamp + 1) * 0x1000 - 1, "LIMIT", 0, 1000)
    if (#jobs > 0) then
        rcall("ZREM", delayedKey, unpack(jobs))
        for _, jobId in ipairs(jobs) do
            local jobKey = prefix .. jobId
            local priority =
                tonumber(rcall("HGET", jobKey, "priority")) or 0
            if priority == 0 then
                -- LIFO or FIFO
                rcall("LPUSH", targetKey, jobId)
            else
                local score = getPriorityScore(priority, priorityCounterKey)
                rcall("ZADD", prioritizedKey, score, jobId)
            end
            -- Emit waiting event
            rcall("XADD", eventStreamKey, "*", "event", "waiting", "jobId",
                  jobId, "prev", "delayed")
            rcall("HSET", jobKey, "delay", 0)
        end
        addBaseMarkerIfNeeded(markerKey, isPaused)
    end
end
--[[
  Function to remove deduplication key if needed
  when a job is moved to completed or failed states.
]]
local function removeDeduplicationKeyIfNeededOnFinalization(prefixKey,
  deduplicationId, jobId)
  if deduplicationId then
    local deduplicationKey = prefixKey .. "de:" .. deduplicationId
    local pttl = rcall("PTTL", deduplicationKey)
    if pttl == 0 then
      return rcall("DEL", deduplicationKey)
    end
    if pttl == -1 then
      local currentJobId = rcall('GET', deduplicationKey)
      if currentJobId and currentJobId == jobId then
        return rcall("DEL", deduplicationKey)
      end
    end
  end
end
local function removeLock(jobKey, stalledKey, token, jobId)
  if token ~= "0" then
    local lockKey = jobKey .. ':lock'
    local lockToken = rcall("GET", lockKey)
    if lockToken == token then
      rcall("DEL", lockKey)
      rcall("SREM", stalledKey, jobId)
    else
      if lockToken then
        -- Lock exists but token does not match
        return -6
      else
        -- Lock is missing completely
        return -2
      end
    end
  end
  return 0
end
--[[
  Function to trim events, default 10000.
]]
-- Includes
--[[
  Function to get max events value or set by default 10000.
]]
local function getOrSetMaxEvents(metaKey)
  local maxEvents = rcall("HGET", metaKey, "opts.maxLenEvents")
  if not maxEvents then
    maxEvents = 10000
    rcall("HSET", metaKey, "opts.maxLenEvents", maxEvents)
  end
  return maxEvents
end
local function trimEvents(metaKey, eventStreamKey)
  local maxEvents = getOrSetMaxEvents(metaKey)
  if maxEvents then
    rcall("XTRIM", eventStreamKey, "MAXLEN", "~", maxEvents)
  else
    rcall("XTRIM", eventStreamKey, "MAXLEN", "~", 10000)
  end
end
--[[
  Validate and move or add dependencies to parent.
]]
-- Includes
local function updateParentDepsIfNeeded(parentKey, parentQueueKey, parentDependenciesKey,
  parentId, jobIdKey, returnvalue, timestamp )
  local processedSet = parentKey .. ":processed"
  rcall("HSET", processedSet, jobIdKey, returnvalue)
  moveParentToWaitIfNoPendingDependencies(parentQueueKey, parentDependenciesKey, parentKey, parentId, timestamp)
end
--[[
  Function to update a bunch of fields in a job.
]]
local function updateJobFields(jobKey, msgpackedFields)
  if msgpackedFields and #msgpackedFields > 0 then
    local fieldsToUpdate = cmsgpack.unpack(msgpackedFields)
    if fieldsToUpdate then
      rcall("HMSET", jobKey, unpack(fieldsToUpdate))
    end
  end
end
local jobIdKey = KEYS[12]
if rcall("EXISTS", jobIdKey) == 1 then -- Make sure job exists
    -- Make sure it does not have pending dependencies
    -- It must happen before removing lock
    if ARGV[5] == "completed" then
        if rcall("SCARD", jobIdKey .. ":dependencies") ~= 0 then
            return -4
        end
        if rcall("ZCARD", jobIdKey .. ":unsuccessful") ~= 0 then
            return -9
        end
    end
    local opts = cmsgpack.unpack(ARGV[8])
    local token = opts['token']
    local errorCode = removeLock(jobIdKey, KEYS[5], token, ARGV[1])
    if errorCode < 0 then
        return errorCode
    end
    updateJobFields(jobIdKey, ARGV[9]);
    local attempts = opts['attempts']
    local maxMetricsSize = opts['maxMetricsSize']
    local maxCount = opts['keepJobs']['count']
    local maxAge = opts['keepJobs']['age']
    local jobAttributes = rcall("HMGET", jobIdKey, "parentKey", "parent", "deid")
    local parentKey = jobAttributes[1] or ""
    local parentId = ""
    local parentQueueKey = ""
    if jobAttributes[2] then -- TODO: need to revisit this logic if it's still needed
        local jsonDecodedParent = cjson.decode(jobAttributes[2])
        parentId = jsonDecodedParent['id']
        parentQueueKey = jsonDecodedParent['queueKey']
    end
    local jobId = ARGV[1]
    local timestamp = ARGV[2]
    -- Remove from active list (if not active we shall return error)
    local numRemovedElements = rcall("LREM", KEYS[2], -1, jobId)
    if (numRemovedElements < 1) then
        return -3
    end
    local eventStreamKey = KEYS[4]
    local metaKey = KEYS[9]
    -- Trim events before emiting them to avoid trimming events emitted in this script
    trimEvents(metaKey, eventStreamKey)
    local prefix = ARGV[7]
    removeDeduplicationKeyIfNeededOnFinalization(prefix, jobAttributes[3], jobId)
    -- If job has a parent we need to
    -- 1) remove this job id from parents dependencies
    -- 2) move the job Id to parent "processed" set
    -- 3) push the results into parent "results" list
    -- 4) if parent's dependencies is empty, then move parent to "wait/paused". Note it may be a different queue!.
    if parentId == "" and parentKey ~= "" then
        parentId = getJobIdFromKey(parentKey)
        parentQueueKey = getJobKeyPrefix(parentKey, ":" .. parentId)
    end
    if parentId ~= "" then
        if ARGV[5] == "completed" then
            local dependenciesSet = parentKey .. ":dependencies"
            if rcall("SREM", dependenciesSet, jobIdKey) == 1 then
                updateParentDepsIfNeeded(parentKey, parentQueueKey, dependenciesSet, parentId, jobIdKey, ARGV[4],
                    timestamp)
            end
        else
            moveChildFromDependenciesIfNeeded(jobAttributes[2], jobIdKey, ARGV[4], timestamp)
        end
    end
    local attemptsMade = rcall("HINCRBY", jobIdKey, "atm", 1)
    -- Remove job?
    if maxCount ~= 0 then
        local targetSet = KEYS[11]
        -- Add to complete/failed set
        rcall("ZADD", targetSet, timestamp, jobId)
        rcall("HSET", jobIdKey, ARGV[3], ARGV[4], "finishedOn", timestamp)
        -- "returnvalue" / "failedReason" and "finishedOn"
        if ARGV[5] == "failed" then
            rcall("HDEL", jobIdKey, "defa")
        end
        -- Remove old jobs?
        if maxAge ~= nil then
            removeJobsByMaxAge(timestamp, maxAge, targetSet, prefix)
        end
        if maxCount ~= nil and maxCount > 0 then
            removeJobsByMaxCount(maxCount, targetSet, prefix)
        end
    else
        removeJobKeys(jobIdKey)
        if parentKey ~= "" then
            -- TODO: when a child is removed when finished, result or failure in parent
            -- must not be deleted, those value references should be deleted when the parent
            -- is deleted
            removeParentDependencyKey(jobIdKey, false, parentKey, jobAttributes[3])
        end
    end
    rcall("XADD", eventStreamKey, "*", "event", ARGV[5], "jobId", jobId, ARGV[3], ARGV[4], "prev", "active")
    if ARGV[5] == "failed" then
        if tonumber(attemptsMade) >= tonumber(attempts) then
            rcall("XADD", eventStreamKey, "*", "event", "retries-exhausted", "jobId", jobId, "attemptsMade",
                attemptsMade)
        end
    end
    -- Collect metrics
    if maxMetricsSize ~= "" then
        collectMetrics(KEYS[13], KEYS[13] .. ':data', maxMetricsSize, timestamp)
    end
    -- Try to get next job to avoid an extra roundtrip if the queue is not closing,
    -- and not rate limited.
    if (ARGV[6] == "1") then
        local target, isPausedOrMaxed, rateLimitMax, rateLimitDuration = getTargetQueueList(metaKey, KEYS[2],
            KEYS[1], KEYS[8])
        local markerKey = KEYS[14]
        -- Check if there are delayed jobs that can be promoted
        promoteDelayedJobs(KEYS[7], markerKey, target, KEYS[3], eventStreamKey, prefix, timestamp, KEYS[10],
            isPausedOrMaxed)
        local maxJobs = tonumber(rateLimitMax or (opts['limiter'] and opts['limiter']['max']))
        -- Check if we are rate limited first.
        local expireTime = getRateLimitTTL(maxJobs, KEYS[6])
        if expireTime > 0 then
            return {0, 0, expireTime, 0}
        end
        -- paused or maxed queue
        if isPausedOrMaxed then
            return {0, 0, 0, 0}
        end
        local limiterDuration = (opts['limiter'] and opts['limiter']['duration']) or rateLimitDuration
        jobId = rcall("RPOPLPUSH", KEYS[1], KEYS[2])
        if jobId then
            -- Markers in waitlist DEPRECATED in v5: Remove in v6.
            if string.sub(jobId, 1, 2) == "0:" then
                rcall("LREM", KEYS[2], 1, jobId)
                -- If jobId is special ID 0:delay (delay greater than 0), then there is no job to process
                -- but if ID is 0:0, then there is at least 1 prioritized job to process
                if jobId == "0:0" then
                    jobId = moveJobFromPrioritizedToActive(KEYS[3], KEYS[2], KEYS[10])
                    return prepareJobForProcessing(prefix, KEYS[6], eventStreamKey, jobId, timestamp, maxJobs,
                        limiterDuration, markerKey, opts)
                end
            else
                return prepareJobForProcessing(prefix, KEYS[6], eventStreamKey, jobId, timestamp, maxJobs,
                    limiterDuration, markerKey, opts)
            end
        else
            jobId = moveJobFromPrioritizedToActive(KEYS[3], KEYS[2], KEYS[10])
            if jobId then
                return prepareJobForProcessing(prefix, KEYS[6], eventStreamKey, jobId, timestamp, maxJobs,
                    limiterDuration, markerKey, opts)
            end
        end
        -- Return the timestamp for the next delayed job if any.
        local nextTimestamp = getNextDelayedTimestamp(KEYS[7])
        if nextTimestamp ~= nil then
            -- The result is guaranteed to be positive, since the
            -- ZRANGEBYSCORE command would have return a job otherwise.
            return {0, 0, 0, nextTimestamp}
        end
    end
    local waitLen = rcall("LLEN", KEYS[1])
    if waitLen == 0 then
        local activeLen = rcall("LLEN", KEYS[2])
        if activeLen == 0 then
            local prioritizedLen = rcall("ZCARD", KEYS[3])
            if prioritizedLen == 0 then
                rcall("XADD", eventStreamKey, "*", "event", "drained")
            end
        end
    end
    return 0
else
    return -1
end
`;
const moveToFinished = {
    name: 'moveToFinished',
    content,
    keys: 14
}; //# sourceMappingURL=moveToFinished-14.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/moveToWaitingChildren-7.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "moveToWaitingChildren",
    ()=>moveToWaitingChildren
]);
const content = `--[[
  Moves job from active to waiting children set.
  Input:
    KEYS[1] active key
    KEYS[2] wait-children key
    KEYS[3] job key
    KEYS[4] job dependencies key
    KEYS[5] job unsuccessful key
    KEYS[6] stalled key
    KEYS[7] events key
    ARGV[1] token
    ARGV[2] child key
    ARGV[3] timestamp
    ARGV[4] jobId
    ARGV[5] prefix
  Output:
    0 - OK
    1 - There are not pending dependencies.
   -1 - Missing job.
   -2 - Missing lock
   -3 - Job not in active set
   -9 - Job has failed children
]]
local rcall = redis.call
local activeKey = KEYS[1]
local waitingChildrenKey = KEYS[2]
local jobKey = KEYS[3]
local jobDependenciesKey = KEYS[4]
local jobUnsuccessfulKey = KEYS[5]
local stalledKey = KEYS[6]
local eventStreamKey = KEYS[7]
local token = ARGV[1]
local timestamp = ARGV[3]
local jobId = ARGV[4]
--- Includes
local function removeLock(jobKey, stalledKey, token, jobId)
  if token ~= "0" then
    local lockKey = jobKey .. ':lock'
    local lockToken = rcall("GET", lockKey)
    if lockToken == token then
      rcall("DEL", lockKey)
      rcall("SREM", stalledKey, jobId)
    else
      if lockToken then
        -- Lock exists but token does not match
        return -6
      else
        -- Lock is missing completely
        return -2
      end
    end
  end
  return 0
end
local function removeJobFromActive(activeKey, stalledKey, jobKey, jobId,
    token)
  local errorCode = removeLock(jobKey, stalledKey, token, jobId)
  if errorCode < 0 then
    return errorCode
  end
  local numRemovedElements = rcall("LREM", activeKey, -1, jobId)
  if numRemovedElements < 1 then
    return -3
  end
  return 0
end
local function moveToWaitingChildren(activeKey, waitingChildrenKey, stalledKey, eventStreamKey,
    jobKey, jobId, timestamp, token)
  local errorCode = removeJobFromActive(activeKey, stalledKey, jobKey, jobId, token)
  if errorCode < 0 then
    return errorCode
  end
  local score = tonumber(timestamp)
  rcall("ZADD", waitingChildrenKey, score, jobId)
  rcall("XADD", eventStreamKey, "*", "event", "waiting-children", "jobId", jobId, 'prev', 'active')
  return 0
end
if rcall("EXISTS", jobKey) == 1 then
  if rcall("ZCARD", jobUnsuccessfulKey) ~= 0 then
    return -9
  else
    if ARGV[2] ~= "" then
      if rcall("SISMEMBER", jobDependenciesKey, ARGV[2]) ~= 0 then
        return moveToWaitingChildren(activeKey, waitingChildrenKey, stalledKey, eventStreamKey,
          jobKey, jobId, timestamp, token)
      end
      return 1
    else
      if rcall("SCARD", jobDependenciesKey) ~= 0 then 
        return moveToWaitingChildren(activeKey, waitingChildrenKey, stalledKey, eventStreamKey,
          jobKey, jobId, timestamp, token)
      end
      return 1
    end    
  end
end
return -1
`;
const moveToWaitingChildren = {
    name: 'moveToWaitingChildren',
    content,
    keys: 7
}; //# sourceMappingURL=moveToWaitingChildren-7.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/obliterate-2.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "obliterate",
    ()=>obliterate
]);
const content = `--[[
  Completely obliterates a queue and all of its contents
  This command completely destroys a queue including all of its jobs, current or past 
  leaving no trace of its existence. Since this script needs to iterate to find all the job
  keys, consider that this call may be slow for very large queues.
  The queue needs to be "paused" or it will return an error
  If the queue has currently active jobs then the script by default will return error,
  however this behaviour can be overrided using the 'force' option.
  Input:
    KEYS[1] meta
    KEYS[2] base
    ARGV[1] count
    ARGV[2] force
]]
local maxCount = tonumber(ARGV[1])
local baseKey = KEYS[2]
local rcall = redis.call
-- Includes
--[[
  Functions to remove jobs.
]]
-- Includes
--[[
  Function to remove job.
]]
-- Includes
--[[
  Function to remove deduplication key if needed
  when a job is being removed.
]]
local function removeDeduplicationKeyIfNeededOnRemoval(prefixKey,
  jobKey, jobId)
  local deduplicationId = rcall("HGET", jobKey, "deid")
  if deduplicationId then
    local deduplicationKey = prefixKey .. "de:" .. deduplicationId
    local currentJobId = rcall('GET', deduplicationKey)
    if currentJobId and currentJobId == jobId then
      return rcall("DEL", deduplicationKey)
    end
  end
end
--[[
  Function to remove job keys.
]]
local function removeJobKeys(jobKey)
  return rcall("DEL", jobKey, jobKey .. ':logs', jobKey .. ':dependencies',
    jobKey .. ':processed', jobKey .. ':failed', jobKey .. ':unsuccessful')
end
--[[
  Check if this job has a parent. If so we will just remove it from
  the parent child list, but if it is the last child we should move the parent to "wait/paused"
  which requires code from "moveToFinished"
]]
-- Includes
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Functions to destructure job key.
  Just a bit of warning, these functions may be a bit slow and affect performance significantly.
]]
local getJobIdFromKey = function (jobKey)
  return string.match(jobKey, ".*:(.*)")
end
local getJobKeyPrefix = function (jobKey, jobId)
  return string.sub(jobKey, 0, #jobKey - #jobId)
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
local function _moveParentToWait(parentPrefix, parentId, emitEvent)
  local parentTarget, isPausedOrMaxed = getTargetQueueList(parentPrefix .. "meta", parentPrefix .. "active",
    parentPrefix .. "wait", parentPrefix .. "paused")
  addJobInTargetList(parentTarget, parentPrefix .. "marker", "RPUSH", isPausedOrMaxed, parentId)
  if emitEvent then
    local parentEventStream = parentPrefix .. "events"
    rcall("XADD", parentEventStream, "*", "event", "waiting", "jobId", parentId, "prev", "waiting-children")
  end
end
local function removeParentDependencyKey(jobKey, hard, parentKey, baseKey, debounceId)
  if parentKey then
    local parentDependenciesKey = parentKey .. ":dependencies"
    local result = rcall("SREM", parentDependenciesKey, jobKey)
    if result > 0 then
      local pendingDependencies = rcall("SCARD", parentDependenciesKey)
      if pendingDependencies == 0 then
        local parentId = getJobIdFromKey(parentKey)
        local parentPrefix = getJobKeyPrefix(parentKey, parentId)
        local numRemovedElements = rcall("ZREM", parentPrefix .. "waiting-children", parentId)
        if numRemovedElements == 1 then
          if hard then -- remove parent in same queue
            if parentPrefix == baseKey then
              removeParentDependencyKey(parentKey, hard, nil, baseKey, nil)
              removeJobKeys(parentKey)
              if debounceId then
                rcall("DEL", parentPrefix .. "de:" .. debounceId)
              end
            else
              _moveParentToWait(parentPrefix, parentId)
            end
          else
            _moveParentToWait(parentPrefix, parentId, true)
          end
        end
      end
      return true
    end
  else
    local parentAttributes = rcall("HMGET", jobKey, "parentKey", "deid")
    local missedParentKey = parentAttributes[1]
    if( (type(missedParentKey) == "string") and missedParentKey ~= ""
      and (rcall("EXISTS", missedParentKey) == 1)) then
      local parentDependenciesKey = missedParentKey .. ":dependencies"
      local result = rcall("SREM", parentDependenciesKey, jobKey)
      if result > 0 then
        local pendingDependencies = rcall("SCARD", parentDependenciesKey)
        if pendingDependencies == 0 then
          local parentId = getJobIdFromKey(missedParentKey)
          local parentPrefix = getJobKeyPrefix(missedParentKey, parentId)
          local numRemovedElements = rcall("ZREM", parentPrefix .. "waiting-children", parentId)
          if numRemovedElements == 1 then
            if hard then
              if parentPrefix == baseKey then
                removeParentDependencyKey(missedParentKey, hard, nil, baseKey, nil)
                removeJobKeys(missedParentKey)
                if parentAttributes[2] then
                  rcall("DEL", parentPrefix .. "de:" .. parentAttributes[2])
                end
              else
                _moveParentToWait(parentPrefix, parentId)
              end
            else
              _moveParentToWait(parentPrefix, parentId, true)
            end
          end
        end
        return true
      end
    end
  end
  return false
end
local function removeJob(jobId, hard, baseKey, shouldRemoveDeduplicationKey)
  local jobKey = baseKey .. jobId
  removeParentDependencyKey(jobKey, hard, nil, baseKey)
  if shouldRemoveDeduplicationKey then
    removeDeduplicationKeyIfNeededOnRemoval(baseKey, jobKey, jobId)
  end
  removeJobKeys(jobKey)
end
local function removeJobs(keys, hard, baseKey, max)
  for i, key in ipairs(keys) do
    removeJob(key, hard, baseKey, true --[[remove debounce key]])
  end
  return max - #keys
end
--[[
  Functions to remove jobs.
]]
-- Includes
--[[
  Function to filter out jobs to ignore from a table.
]]
local function filterOutJobsToIgnore(jobs, jobsToIgnore)
  local filteredJobs = {}
  for i = 1, #jobs do
    if not jobsToIgnore[jobs[i]] then
      table.insert(filteredJobs, jobs[i])
    end
  end
  return filteredJobs
end
local function getListItems(keyName, max)
  return rcall('LRANGE', keyName, 0, max - 1)
end
local function removeListJobs(keyName, hard, baseKey, max, jobsToIgnore)
  local jobs = getListItems(keyName, max)
  if jobsToIgnore then
    jobs = filterOutJobsToIgnore(jobs, jobsToIgnore)
  end
  local count = removeJobs(jobs, hard, baseKey, max)
  rcall("LTRIM", keyName, #jobs, -1)
  return count
end
-- Includes
--[[
  Function to loop in batches.
  Just a bit of warning, some commands as ZREM
  could receive a maximum of 7000 parameters per call.
]]
local function batches(n, batchSize)
  local i = 0
  return function()
    local from = i * batchSize + 1
    i = i + 1
    if (from <= n) then
      local to = math.min(from + batchSize - 1, n)
      return from, to
    end
  end
end
--[[
  Function to get ZSet items.
]]
local function getZSetItems(keyName, max)
  return rcall('ZRANGE', keyName, 0, max - 1)
end
local function removeZSetJobs(keyName, hard, baseKey, max, jobsToIgnore)
  local jobs = getZSetItems(keyName, max)
  if jobsToIgnore then
    jobs = filterOutJobsToIgnore(jobs, jobsToIgnore)
  end
  local count = removeJobs(jobs, hard, baseKey, max)
  if(#jobs > 0) then
    for from, to in batches(#jobs, 7000) do
      rcall("ZREM", keyName, unpack(jobs, from, to))
    end
  end
  return count
end
local function removeLockKeys(keys)
  for i, key in ipairs(keys) do
    rcall("DEL", baseKey .. key .. ':lock')
  end
end
-- 1) Check if paused, if not return with error.
if rcall("HEXISTS", KEYS[1], "paused") ~= 1 then
  return -1 -- Error, NotPaused
end
-- 2) Check if there are active jobs, if there are and not "force" return error.
local activeKey = baseKey .. 'active'
local activeJobs = getListItems(activeKey, maxCount)
if (#activeJobs > 0) then
  if(ARGV[2] == "") then 
    return -2 -- Error, ExistActiveJobs
  end
end
removeLockKeys(activeJobs)
maxCount = removeJobs(activeJobs, true, baseKey, maxCount)
rcall("LTRIM", activeKey, #activeJobs, -1)
if(maxCount <= 0) then
  return 1
end
local delayedKey = baseKey .. 'delayed'
maxCount = removeZSetJobs(delayedKey, true, baseKey, maxCount)
if(maxCount <= 0) then
  return 1
end
local repeatKey = baseKey .. 'repeat'
local repeatJobsIds = getZSetItems(repeatKey, maxCount)
for i, key in ipairs(repeatJobsIds) do
  local jobKey = repeatKey .. ":" .. key
  rcall("DEL", jobKey)
end
if(#repeatJobsIds > 0) then
  for from, to in batches(#repeatJobsIds, 7000) do
    rcall("ZREM", repeatKey, unpack(repeatJobsIds, from, to))
  end
end
maxCount = maxCount - #repeatJobsIds
if(maxCount <= 0) then
  return 1
end
local completedKey = baseKey .. 'completed'
maxCount = removeZSetJobs(completedKey, true, baseKey, maxCount)
if(maxCount <= 0) then
  return 1
end
local waitKey = baseKey .. 'paused'
maxCount = removeListJobs(waitKey, true, baseKey, maxCount)
if(maxCount <= 0) then
  return 1
end
local prioritizedKey = baseKey .. 'prioritized'
maxCount = removeZSetJobs(prioritizedKey, true, baseKey, maxCount)
if(maxCount <= 0) then
  return 1
end
local failedKey = baseKey .. 'failed'
maxCount = removeZSetJobs(failedKey, true, baseKey, maxCount)
if(maxCount <= 0) then
  return 1
end
if(maxCount > 0) then
  rcall("DEL",
    baseKey .. 'events',
    baseKey .. 'delay', 
    baseKey .. 'stalled-check',
    baseKey .. 'stalled',
    baseKey .. 'id',
    baseKey .. 'pc',
    baseKey .. 'meta',
    baseKey .. 'metrics:completed',
    baseKey .. 'metrics:completed:data',
    baseKey .. 'metrics:failed',
    baseKey .. 'metrics:failed:data')
  return 0
else
  return 1
end
`;
const obliterate = {
    name: 'obliterate',
    content,
    keys: 2
}; //# sourceMappingURL=obliterate-2.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/paginate-1.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "paginate",
    ()=>paginate
]);
const content = `--[[
    Paginate a set or hash
    Input:
      KEYS[1] key pointing to the set or hash to be paginated.
      ARGV[1]  page start offset
      ARGV[2]  page end offset (-1 for all the elements)
      ARGV[3]  cursor
      ARGV[4]  offset
      ARGV[5]  max iterations
      ARGV[6]  fetch jobs?
    Output:
      [cursor, offset, items, numItems]
]]
local rcall = redis.call
-- Includes
--[[
  Function to achieve pagination for a set or hash.
  This function simulates pagination in the most efficient way possible
  for a set using sscan or hscan.
  The main limitation is that sets are not order preserving, so the
  pagination is not stable. This means that if the set is modified
  between pages, the same element may appear in different pages.
]] -- Maximum number of elements to be returned by sscan per iteration.
local maxCount = 100
-- Finds the cursor, and returns the first elements available for the requested page.
local function findPage(key, command, pageStart, pageSize, cursor, offset,
                        maxIterations, fetchJobs)
    local items = {}
    local jobs = {}
    local iterations = 0
    repeat
        -- Iterate over the set using sscan/hscan.
        local result = rcall(command, key, cursor, "COUNT", maxCount)
        cursor = result[1]
        local members = result[2]
        local step = 1
        if command == "HSCAN" then
            step = 2
        end
        if #members == 0 then
            -- If the result is empty, we can return the result.
            return cursor, offset, items, jobs
        end
        local chunkStart = offset
        local chunkEnd = offset + #members / step
        local pageEnd = pageStart + pageSize
        if chunkEnd < pageStart then
            -- If the chunk is before the page, we can skip it.
            offset = chunkEnd
        elseif chunkStart > pageEnd then
            -- If the chunk is after the page, we can return the result.
            return cursor, offset, items, jobs
        else
            -- If the chunk is overlapping the page, we need to add the elements to the result.
            for i = 1, #members, step do
                if offset >= pageEnd then
                    return cursor, offset, items, jobs
                end
                if offset >= pageStart then
                    local index = #items + 1
                    if fetchJobs ~= nil then
                        jobs[#jobs+1] = rcall("HGETALL", members[i])
                    end
                    if step == 2 then
                        items[index] = {members[i], members[i + 1]}
                    else
                        items[index] = members[i]
                    end
                end
                offset = offset + 1
            end
        end
        iterations = iterations + 1
    until cursor == "0" or iterations >= maxIterations
    return cursor, offset, items, jobs
end
local key = KEYS[1]
local scanCommand = "SSCAN"
local countCommand = "SCARD"
local type = rcall("TYPE", key)["ok"]
if type == "none" then
    return {0, 0, {}, 0}
elseif type == "hash" then
    scanCommand = "HSCAN"
    countCommand = "HLEN"
elseif type ~= "set" then
    return
        redis.error_reply("Pagination is only supported for sets and hashes.")
end
local numItems = rcall(countCommand, key)
local startOffset = tonumber(ARGV[1])
local endOffset = tonumber(ARGV[2])
if endOffset == -1 then 
  endOffset = numItems
end
local pageSize = (endOffset - startOffset) + 1
local cursor, offset, items, jobs = findPage(key, scanCommand, startOffset,
                                       pageSize, ARGV[3], tonumber(ARGV[4]),
                                       tonumber(ARGV[5]), ARGV[6])
return {cursor, offset, items, numItems, jobs}
`;
const paginate = {
    name: 'paginate',
    content,
    keys: 1
}; //# sourceMappingURL=paginate-1.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/pause-7.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "pause",
    ()=>pause
]);
const content = `--[[
  Pauses or resumes a queue globably.
  Input:
    KEYS[1] 'wait' or 'paused''
    KEYS[2] 'paused' or 'wait'
    KEYS[3] 'meta'
    KEYS[4] 'prioritized'
    KEYS[5] events stream key
    KEYS[6] 'delayed'
    KEYS|7] 'marker'
    ARGV[1] 'paused' or 'resumed'
  Event:
    publish paused or resumed event.
]]
local rcall = redis.call
-- Includes
--[[
  Add delay marker if needed.
]]
-- Includes
--[[
  Function to return the next delayed job timestamp.
]]
local function getNextDelayedTimestamp(delayedKey)
  local result = rcall("ZRANGE", delayedKey, 0, 0, "WITHSCORES")
  if #result then
    local nextTimestamp = tonumber(result[2])
    if nextTimestamp ~= nil then
      return nextTimestamp / 0x1000
    end
  end
end
local function addDelayMarkerIfNeeded(markerKey, delayedKey)
  local nextTimestamp = getNextDelayedTimestamp(delayedKey)
  if nextTimestamp ~= nil then
    -- Replace the score of the marker with the newest known
    -- next timestamp.
    rcall("ZADD", markerKey, nextTimestamp, "1")
  end
end
local markerKey = KEYS[7]
local hasJobs = rcall("EXISTS", KEYS[1]) == 1
--TODO: check this logic to be reused when changing a delay
if hasJobs then rcall("RENAME", KEYS[1], KEYS[2]) end
if ARGV[1] == "paused" then
    rcall("HSET", KEYS[3], "paused", 1)
    rcall("DEL", markerKey)
else
    rcall("HDEL", KEYS[3], "paused")
    if hasJobs or rcall("ZCARD", KEYS[4]) > 0 then
        -- Add marker if there are waiting or priority jobs
        rcall("ZADD", markerKey, 0, "0")
    else
        addDelayMarkerIfNeeded(markerKey, KEYS[6])
    end
end
rcall("XADD", KEYS[5], "*", "event", ARGV[1]);
`;
const pause = {
    name: 'pause',
    content,
    keys: 7
}; //# sourceMappingURL=pause-7.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/promote-9.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "promote",
    ()=>promote
]);
const content = `--[[
  Promotes a job that is currently "delayed" to the "waiting" state
    Input:
      KEYS[1] 'delayed'
      KEYS[2] 'wait'
      KEYS[3] 'paused'
      KEYS[4] 'meta'
      KEYS[5] 'prioritized'
      KEYS[6] 'active'
      KEYS[7] 'pc' priority counter
      KEYS[8] 'event stream'
      KEYS[9] 'marker'
      ARGV[1]  queue.toKey('')
      ARGV[2]  jobId
    Output:
       0 - OK
      -3 - Job not in delayed zset.
    Events:
      'waiting'
]]
local rcall = redis.call
local jobId = ARGV[2]
-- Includes
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to add job considering priority.
]]
-- Includes
--[[
  Function to get priority score.
]]
local function getPriorityScore(priority, priorityCounterKey)
  local prioCounter = rcall("INCR", priorityCounterKey)
  return priority * 0x100000000 + prioCounter % 0x100000000
end
local function addJobWithPriority(markerKey, prioritizedKey, priority, jobId, priorityCounterKey,
  isPausedOrMaxed)
  local score = getPriorityScore(priority, priorityCounterKey)
  rcall("ZADD", prioritizedKey, score, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
if rcall("ZREM", KEYS[1], jobId) == 1 then
    local jobKey = ARGV[1] .. jobId
    local priority = tonumber(rcall("HGET", jobKey, "priority")) or 0
    local metaKey = KEYS[4]
    local markerKey = KEYS[9]
    -- Remove delayed "marker" from the wait list if there is any.
    -- Since we are adding a job we do not need the marker anymore.
    -- Markers in waitlist DEPRECATED in v5: Remove in v6.
    local target, isPausedOrMaxed = getTargetQueueList(metaKey, KEYS[6], KEYS[2], KEYS[3])
    local marker = rcall("LINDEX", target, 0)
    if marker and string.sub(marker, 1, 2) == "0:" then rcall("LPOP", target) end
    if priority == 0 then
        -- LIFO or FIFO
        addJobInTargetList(target, markerKey, "LPUSH", isPausedOrMaxed, jobId)
    else
        addJobWithPriority(markerKey, KEYS[5], priority, jobId, KEYS[7], isPausedOrMaxed)
    end
    rcall("XADD", KEYS[8], "*", "event", "waiting", "jobId", jobId, "prev",
          "delayed");
    rcall("HSET", jobKey, "delay", 0)
    return 0
else
    return -3
end
`;
const promote = {
    name: 'promote',
    content,
    keys: 9
}; //# sourceMappingURL=promote-9.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/releaseLock-1.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "releaseLock",
    ()=>releaseLock
]);
const content = `--[[
  Release lock
    Input:
      KEYS[1] 'lock',
      ARGV[1]  token
      ARGV[2]  lock duration in milliseconds
    Output:
      "OK" if lock extented succesfully.
]]
local rcall = redis.call
if rcall("GET", KEYS[1]) == ARGV[1] then
  return rcall("DEL", KEYS[1])
else
  return 0
end
`;
const releaseLock = {
    name: 'releaseLock',
    content,
    keys: 1
}; //# sourceMappingURL=releaseLock-1.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/removeChildDependency-1.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "removeChildDependency",
    ()=>removeChildDependency
]);
const content = `--[[
  Break parent-child dependency by removing
  child reference from parent
  Input:
    KEYS[1] 'key' prefix,
    ARGV[1] job key
    ARGV[2] parent key
    Output:
       0  - OK
       1  - There is not relationship.
      -1  - Missing job key
      -5  - Missing parent key
]]
local rcall = redis.call
local jobKey = ARGV[1]
local parentKey = ARGV[2]
-- Includes
--[[
  Check if this job has a parent. If so we will just remove it from
  the parent child list, but if it is the last child we should move the parent to "wait/paused"
  which requires code from "moveToFinished"
]]
-- Includes
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Functions to destructure job key.
  Just a bit of warning, these functions may be a bit slow and affect performance significantly.
]]
local getJobIdFromKey = function (jobKey)
  return string.match(jobKey, ".*:(.*)")
end
local getJobKeyPrefix = function (jobKey, jobId)
  return string.sub(jobKey, 0, #jobKey - #jobId)
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
--[[
  Function to remove job keys.
]]
local function removeJobKeys(jobKey)
  return rcall("DEL", jobKey, jobKey .. ':logs', jobKey .. ':dependencies',
    jobKey .. ':processed', jobKey .. ':failed', jobKey .. ':unsuccessful')
end
local function _moveParentToWait(parentPrefix, parentId, emitEvent)
  local parentTarget, isPausedOrMaxed = getTargetQueueList(parentPrefix .. "meta", parentPrefix .. "active",
    parentPrefix .. "wait", parentPrefix .. "paused")
  addJobInTargetList(parentTarget, parentPrefix .. "marker", "RPUSH", isPausedOrMaxed, parentId)
  if emitEvent then
    local parentEventStream = parentPrefix .. "events"
    rcall("XADD", parentEventStream, "*", "event", "waiting", "jobId", parentId, "prev", "waiting-children")
  end
end
local function removeParentDependencyKey(jobKey, hard, parentKey, baseKey, debounceId)
  if parentKey then
    local parentDependenciesKey = parentKey .. ":dependencies"
    local result = rcall("SREM", parentDependenciesKey, jobKey)
    if result > 0 then
      local pendingDependencies = rcall("SCARD", parentDependenciesKey)
      if pendingDependencies == 0 then
        local parentId = getJobIdFromKey(parentKey)
        local parentPrefix = getJobKeyPrefix(parentKey, parentId)
        local numRemovedElements = rcall("ZREM", parentPrefix .. "waiting-children", parentId)
        if numRemovedElements == 1 then
          if hard then -- remove parent in same queue
            if parentPrefix == baseKey then
              removeParentDependencyKey(parentKey, hard, nil, baseKey, nil)
              removeJobKeys(parentKey)
              if debounceId then
                rcall("DEL", parentPrefix .. "de:" .. debounceId)
              end
            else
              _moveParentToWait(parentPrefix, parentId)
            end
          else
            _moveParentToWait(parentPrefix, parentId, true)
          end
        end
      end
      return true
    end
  else
    local parentAttributes = rcall("HMGET", jobKey, "parentKey", "deid")
    local missedParentKey = parentAttributes[1]
    if( (type(missedParentKey) == "string") and missedParentKey ~= ""
      and (rcall("EXISTS", missedParentKey) == 1)) then
      local parentDependenciesKey = missedParentKey .. ":dependencies"
      local result = rcall("SREM", parentDependenciesKey, jobKey)
      if result > 0 then
        local pendingDependencies = rcall("SCARD", parentDependenciesKey)
        if pendingDependencies == 0 then
          local parentId = getJobIdFromKey(missedParentKey)
          local parentPrefix = getJobKeyPrefix(missedParentKey, parentId)
          local numRemovedElements = rcall("ZREM", parentPrefix .. "waiting-children", parentId)
          if numRemovedElements == 1 then
            if hard then
              if parentPrefix == baseKey then
                removeParentDependencyKey(missedParentKey, hard, nil, baseKey, nil)
                removeJobKeys(missedParentKey)
                if parentAttributes[2] then
                  rcall("DEL", parentPrefix .. "de:" .. parentAttributes[2])
                end
              else
                _moveParentToWait(parentPrefix, parentId)
              end
            else
              _moveParentToWait(parentPrefix, parentId, true)
            end
          end
        end
        return true
      end
    end
  end
  return false
end
if rcall("EXISTS", jobKey) ~= 1 then return -1 end
if rcall("EXISTS", parentKey) ~= 1 then return -5 end
if removeParentDependencyKey(jobKey, false, parentKey, KEYS[1], nil) then
  rcall("HDEL", jobKey, "parentKey", "parent")
  return 0
else
  return 1
end`;
const removeChildDependency = {
    name: 'removeChildDependency',
    content,
    keys: 1
}; //# sourceMappingURL=removeChildDependency-1.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/removeDeduplicationKey-1.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "removeDeduplicationKey",
    ()=>removeDeduplicationKey
]);
const content = `--[[
  Remove deduplication key if it matches the job id.
  Input:
    KEYS[1] deduplication key
    ARGV[1] job id
  Output:
    0 - false
    1 - true
]]
local rcall = redis.call
local deduplicationKey = KEYS[1]
local jobId = ARGV[1]
local currentJobId = rcall('GET', deduplicationKey)
if currentJobId and currentJobId == jobId then
  return rcall("DEL", deduplicationKey)
end
return 0
`;
const removeDeduplicationKey = {
    name: 'removeDeduplicationKey',
    content,
    keys: 1
}; //# sourceMappingURL=removeDeduplicationKey-1.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/removeJob-2.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "removeJob",
    ()=>removeJob
]);
const content = `--[[
    Remove a job from all the statuses it may be in as well as all its data.
    In order to be able to remove a job, it cannot be active.
    Input:
      KEYS[1] jobKey
      KEYS[2] repeat key
      ARGV[1] jobId
      ARGV[2] remove children
      ARGV[3] queue prefix
    Events:
      'removed'
]]
local rcall = redis.call
-- Includes
--[[
  Function to check if the job belongs to a job scheduler and
  current delayed job matches with jobId
]]
local function isJobSchedulerJob(jobId, jobKey, jobSchedulersKey)
  local repeatJobKey = rcall("HGET", jobKey, "rjk")
  if repeatJobKey  then
    local prevMillis = rcall("ZSCORE", jobSchedulersKey, repeatJobKey)
    if prevMillis then
      local currentDelayedJobId = "repeat:" .. repeatJobKey .. ":" .. prevMillis
      return jobId == currentDelayedJobId
    end
  end
  return false
end
--[[
  Function to recursively check if there are no locks
  on the jobs to be removed.
  returns:
    boolean
]]
--[[
  Functions to destructure job key.
  Just a bit of warning, these functions may be a bit slow and affect performance significantly.
]]
local getJobIdFromKey = function (jobKey)
  return string.match(jobKey, ".*:(.*)")
end
local getJobKeyPrefix = function (jobKey, jobId)
  return string.sub(jobKey, 0, #jobKey - #jobId)
end
local function isLocked( prefix, jobId, removeChildren)
  local jobKey = prefix .. jobId;
  -- Check if this job is locked
  local lockKey = jobKey .. ':lock'
  local lock = rcall("GET", lockKey)
  if not lock then
    if removeChildren == "1" then
      local dependencies = rcall("SMEMBERS", jobKey .. ":dependencies")
      if (#dependencies > 0) then
        for i, childJobKey in ipairs(dependencies) do
          -- We need to get the jobId for this job.
          local childJobId = getJobIdFromKey(childJobKey)
          local childJobPrefix = getJobKeyPrefix(childJobKey, childJobId)
          local result = isLocked( childJobPrefix, childJobId, removeChildren )
          if result then
            return true
          end
        end
      end
    end
    return false
  end
  return true
end
--[[
    Remove a job from all the statuses it may be in as well as all its data,
    including its children. Active children can be ignored.
    Events:
      'removed'
]]
local rcall = redis.call
-- Includes
--[[
  Function to get max events value or set by default 10000.
]]
local function getOrSetMaxEvents(metaKey)
  local maxEvents = rcall("HGET", metaKey, "opts.maxLenEvents")
  if not maxEvents then
    maxEvents = 10000
    rcall("HSET", metaKey, "opts.maxLenEvents", maxEvents)
  end
  return maxEvents
end
--[[
  Function to remove deduplication key if needed
  when a job is being removed.
]]
local function removeDeduplicationKeyIfNeededOnRemoval(prefixKey,
  jobKey, jobId)
  local deduplicationId = rcall("HGET", jobKey, "deid")
  if deduplicationId then
    local deduplicationKey = prefixKey .. "de:" .. deduplicationId
    local currentJobId = rcall('GET', deduplicationKey)
    if currentJobId and currentJobId == jobId then
      return rcall("DEL", deduplicationKey)
    end
  end
end
--[[
  Function to remove from any state.
  returns:
    prev state
]]
local function removeJobFromAnyState( prefix, jobId)
  -- We start with the ZSCORE checks, since they have O(1) complexity
  if rcall("ZSCORE", prefix .. "completed", jobId) then
    rcall("ZREM", prefix .. "completed", jobId)
    return "completed"
  elseif rcall("ZSCORE", prefix .. "waiting-children", jobId) then
    rcall("ZREM", prefix .. "waiting-children", jobId)
    return "waiting-children"
  elseif rcall("ZSCORE", prefix .. "delayed", jobId) then
    rcall("ZREM", prefix .. "delayed", jobId)
    return "delayed"
  elseif rcall("ZSCORE", prefix .. "failed", jobId) then
    rcall("ZREM", prefix .. "failed", jobId)
    return "failed"
  elseif rcall("ZSCORE", prefix .. "prioritized", jobId) then
    rcall("ZREM", prefix .. "prioritized", jobId)
    return "prioritized"
  -- We remove only 1 element from the list, since we assume they are not added multiple times
  elseif rcall("LREM", prefix .. "wait", 1, jobId) == 1 then
    return "wait"
  elseif rcall("LREM", prefix .. "paused", 1, jobId) == 1 then
    return "paused"
  elseif rcall("LREM", prefix .. "active", 1, jobId) == 1 then
    return "active"
  end
  return "unknown"
end
--[[
  Function to remove job keys.
]]
local function removeJobKeys(jobKey)
  return rcall("DEL", jobKey, jobKey .. ':logs', jobKey .. ':dependencies',
    jobKey .. ':processed', jobKey .. ':failed', jobKey .. ':unsuccessful')
end
--[[
  Check if this job has a parent. If so we will just remove it from
  the parent child list, but if it is the last child we should move the parent to "wait/paused"
  which requires code from "moveToFinished"
]]
-- Includes
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
local function _moveParentToWait(parentPrefix, parentId, emitEvent)
  local parentTarget, isPausedOrMaxed = getTargetQueueList(parentPrefix .. "meta", parentPrefix .. "active",
    parentPrefix .. "wait", parentPrefix .. "paused")
  addJobInTargetList(parentTarget, parentPrefix .. "marker", "RPUSH", isPausedOrMaxed, parentId)
  if emitEvent then
    local parentEventStream = parentPrefix .. "events"
    rcall("XADD", parentEventStream, "*", "event", "waiting", "jobId", parentId, "prev", "waiting-children")
  end
end
local function removeParentDependencyKey(jobKey, hard, parentKey, baseKey, debounceId)
  if parentKey then
    local parentDependenciesKey = parentKey .. ":dependencies"
    local result = rcall("SREM", parentDependenciesKey, jobKey)
    if result > 0 then
      local pendingDependencies = rcall("SCARD", parentDependenciesKey)
      if pendingDependencies == 0 then
        local parentId = getJobIdFromKey(parentKey)
        local parentPrefix = getJobKeyPrefix(parentKey, parentId)
        local numRemovedElements = rcall("ZREM", parentPrefix .. "waiting-children", parentId)
        if numRemovedElements == 1 then
          if hard then -- remove parent in same queue
            if parentPrefix == baseKey then
              removeParentDependencyKey(parentKey, hard, nil, baseKey, nil)
              removeJobKeys(parentKey)
              if debounceId then
                rcall("DEL", parentPrefix .. "de:" .. debounceId)
              end
            else
              _moveParentToWait(parentPrefix, parentId)
            end
          else
            _moveParentToWait(parentPrefix, parentId, true)
          end
        end
      end
      return true
    end
  else
    local parentAttributes = rcall("HMGET", jobKey, "parentKey", "deid")
    local missedParentKey = parentAttributes[1]
    if( (type(missedParentKey) == "string") and missedParentKey ~= ""
      and (rcall("EXISTS", missedParentKey) == 1)) then
      local parentDependenciesKey = missedParentKey .. ":dependencies"
      local result = rcall("SREM", parentDependenciesKey, jobKey)
      if result > 0 then
        local pendingDependencies = rcall("SCARD", parentDependenciesKey)
        if pendingDependencies == 0 then
          local parentId = getJobIdFromKey(missedParentKey)
          local parentPrefix = getJobKeyPrefix(missedParentKey, parentId)
          local numRemovedElements = rcall("ZREM", parentPrefix .. "waiting-children", parentId)
          if numRemovedElements == 1 then
            if hard then
              if parentPrefix == baseKey then
                removeParentDependencyKey(missedParentKey, hard, nil, baseKey, nil)
                removeJobKeys(missedParentKey)
                if parentAttributes[2] then
                  rcall("DEL", parentPrefix .. "de:" .. parentAttributes[2])
                end
              else
                _moveParentToWait(parentPrefix, parentId)
              end
            else
              _moveParentToWait(parentPrefix, parentId, true)
            end
          end
        end
        return true
      end
    end
  end
  return false
end
local removeJobChildren
local removeJobWithChildren
removeJobChildren = function(prefix, jobKey, options)
    -- Check if this job has children
    -- If so, we are going to try to remove the children recursively in a depth-first way
    -- because if some job is locked, we must exit with an error.
    if not options.ignoreProcessed then
        local processed = rcall("HGETALL", jobKey .. ":processed")
        if #processed > 0 then
            for i = 1, #processed, 2 do
                local childJobId = getJobIdFromKey(processed[i])
                local childJobPrefix = getJobKeyPrefix(processed[i], childJobId)
                removeJobWithChildren(childJobPrefix, childJobId, jobKey, options)
            end
        end
        local failed = rcall("HGETALL", jobKey .. ":failed")
        if #failed > 0 then
            for i = 1, #failed, 2 do
                local childJobId = getJobIdFromKey(failed[i])
                local childJobPrefix = getJobKeyPrefix(failed[i], childJobId)
                removeJobWithChildren(childJobPrefix, childJobId, jobKey, options)
            end
        end
        local unsuccessful = rcall("ZRANGE", jobKey .. ":unsuccessful", 0, -1)
        if #unsuccessful > 0 then
            for i = 1, #unsuccessful, 1 do
                local childJobId = getJobIdFromKey(unsuccessful[i])
                local childJobPrefix = getJobKeyPrefix(unsuccessful[i], childJobId)
                removeJobWithChildren(childJobPrefix, childJobId, jobKey, options)
            end
        end
    end
    local dependencies = rcall("SMEMBERS", jobKey .. ":dependencies")
    if #dependencies > 0 then
        for i, childJobKey in ipairs(dependencies) do
            local childJobId = getJobIdFromKey(childJobKey)
            local childJobPrefix = getJobKeyPrefix(childJobKey, childJobId)
            removeJobWithChildren(childJobPrefix, childJobId, jobKey, options)
        end
    end
end
removeJobWithChildren = function(prefix, jobId, parentKey, options)
    local jobKey = prefix .. jobId
    if options.ignoreLocked then
        if isLocked(prefix, jobId) then
            return
        end
    end
    -- Check if job is in the failed zset
    local failedSet = prefix .. "failed"
    if not (options.ignoreProcessed and rcall("ZSCORE", failedSet, jobId)) then
        removeParentDependencyKey(jobKey, false, parentKey, nil)
        if options.removeChildren then
            removeJobChildren(prefix, jobKey, options)
        end
        local prev = removeJobFromAnyState(prefix, jobId)
        removeDeduplicationKeyIfNeededOnRemoval(prefix, jobKey, jobId)
        if removeJobKeys(jobKey) > 0 then
            local metaKey = prefix .. "meta"
            local maxEvents = getOrSetMaxEvents(metaKey)
            rcall("XADD", prefix .. "events", "MAXLEN", "~", maxEvents, "*", "event", "removed",
                "jobId", jobId, "prev", prev)
        end
    end
end
local jobId = ARGV[1]
local shouldRemoveChildren = ARGV[2]
local prefix = ARGV[3]
local jobKey = KEYS[1]
local repeatKey = KEYS[2]
if isJobSchedulerJob(jobId, jobKey, repeatKey) then
    return -8
end
if not isLocked(prefix, jobId, shouldRemoveChildren) then
    local options = {
        removeChildren = shouldRemoveChildren == "1",
        ignoreProcessed = false,
        ignoreLocked = false
    }
    removeJobWithChildren(prefix, jobId, nil, options)
    return 1
end
return 0
`;
const removeJob = {
    name: 'removeJob',
    content,
    keys: 2
}; //# sourceMappingURL=removeJob-2.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/removeJobScheduler-3.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "removeJobScheduler",
    ()=>removeJobScheduler
]);
const content = `--[[
  Removes a job scheduler and its next scheduled job.
  Input:
    KEYS[1] job schedulers key
    KEYS[2] delayed jobs key
    KEYS[3] events key
    ARGV[1] job scheduler id
    ARGV[2] prefix key
  Output:
    0 - OK
    1 - Missing repeat job
  Events:
    'removed'
]]
local rcall = redis.call
-- Includes
--[[
  Function to remove job keys.
]]
local function removeJobKeys(jobKey)
  return rcall("DEL", jobKey, jobKey .. ':logs', jobKey .. ':dependencies',
    jobKey .. ':processed', jobKey .. ':failed', jobKey .. ':unsuccessful')
end
local jobSchedulerId = ARGV[1]
local prefix = ARGV[2]
local millis = rcall("ZSCORE", KEYS[1], jobSchedulerId)
if millis then
  -- Delete next programmed job.
  local delayedJobId = "repeat:" .. jobSchedulerId .. ":" .. millis
  if(rcall("ZREM", KEYS[2], delayedJobId) == 1) then
    removeJobKeys(prefix .. delayedJobId)
    rcall("XADD", KEYS[3], "*", "event", "removed", "jobId", delayedJobId, "prev", "delayed")
  end
end
if(rcall("ZREM", KEYS[1], jobSchedulerId) == 1) then
  rcall("DEL", KEYS[1] .. ":" .. jobSchedulerId)
  return 0
end
return 1
`;
const removeJobScheduler = {
    name: 'removeJobScheduler',
    content,
    keys: 3
}; //# sourceMappingURL=removeJobScheduler-3.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/removeRepeatable-3.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "removeRepeatable",
    ()=>removeRepeatable
]);
const content = `--[[
  Removes a repeatable job
  Input:
    KEYS[1] repeat jobs key
    KEYS[2] delayed jobs key
    KEYS[3] events key
    ARGV[1] old repeat job id
    ARGV[2] options concat
    ARGV[3] repeat job key
    ARGV[4] prefix key
  Output:
    0 - OK
    1 - Missing repeat job
  Events:
    'removed'
]]
local rcall = redis.call
local millis = rcall("ZSCORE", KEYS[1], ARGV[2])
-- Includes
--[[
  Function to remove job keys.
]]
local function removeJobKeys(jobKey)
  return rcall("DEL", jobKey, jobKey .. ':logs', jobKey .. ':dependencies',
    jobKey .. ':processed', jobKey .. ':failed', jobKey .. ':unsuccessful')
end
-- legacy removal TODO: remove in next breaking change
if millis then
  -- Delete next programmed job.
  local repeatJobId = ARGV[1] .. millis
  if(rcall("ZREM", KEYS[2], repeatJobId) == 1) then
    removeJobKeys(ARGV[4] .. repeatJobId)
    rcall("XADD", KEYS[3], "*", "event", "removed", "jobId", repeatJobId, "prev", "delayed");
  end
end
if(rcall("ZREM", KEYS[1], ARGV[2]) == 1) then
  return 0
end
-- new removal
millis = rcall("ZSCORE", KEYS[1], ARGV[3])
if millis then
  -- Delete next programmed job.
  local repeatJobId = "repeat:" .. ARGV[3] .. ":" .. millis
  if(rcall("ZREM", KEYS[2], repeatJobId) == 1) then
    removeJobKeys(ARGV[4] .. repeatJobId)
    rcall("XADD", KEYS[3], "*", "event", "removed", "jobId", repeatJobId, "prev", "delayed")
  end
end
if(rcall("ZREM", KEYS[1], ARGV[3]) == 1) then
  rcall("DEL", KEYS[1] .. ":" .. ARGV[3])
  return 0
end
return 1
`;
const removeRepeatable = {
    name: 'removeRepeatable',
    content,
    keys: 3
}; //# sourceMappingURL=removeRepeatable-3.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/removeUnprocessedChildren-2.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "removeUnprocessedChildren",
    ()=>removeUnprocessedChildren
]);
const content = `--[[
    Remove a job from all the statuses it may be in as well as all its data.
    In order to be able to remove a job, it cannot be active.
    Input:
      KEYS[1] jobKey
      KEYS[2] meta key
      ARGV[1] prefix
      ARGV[2] jobId
    Events:
      'removed' for every children removed
]]
-- Includes
--[[
    Remove a job from all the statuses it may be in as well as all its data,
    including its children. Active children can be ignored.
    Events:
      'removed'
]]
local rcall = redis.call
-- Includes
--[[
  Functions to destructure job key.
  Just a bit of warning, these functions may be a bit slow and affect performance significantly.
]]
local getJobIdFromKey = function (jobKey)
  return string.match(jobKey, ".*:(.*)")
end
local getJobKeyPrefix = function (jobKey, jobId)
  return string.sub(jobKey, 0, #jobKey - #jobId)
end
--[[
  Function to get max events value or set by default 10000.
]]
local function getOrSetMaxEvents(metaKey)
  local maxEvents = rcall("HGET", metaKey, "opts.maxLenEvents")
  if not maxEvents then
    maxEvents = 10000
    rcall("HSET", metaKey, "opts.maxLenEvents", maxEvents)
  end
  return maxEvents
end
--[[
  Function to check if the job belongs to a job scheduler and
  current delayed job matches with jobId
]]
local function isJobSchedulerJob(jobId, jobKey, jobSchedulersKey)
  local repeatJobKey = rcall("HGET", jobKey, "rjk")
  if repeatJobKey  then
    local prevMillis = rcall("ZSCORE", jobSchedulersKey, repeatJobKey)
    if prevMillis then
      local currentDelayedJobId = "repeat:" .. repeatJobKey .. ":" .. prevMillis
      return jobId == currentDelayedJobId
    end
  end
  return false
end
--[[
  Function to remove deduplication key if needed
  when a job is being removed.
]]
local function removeDeduplicationKeyIfNeededOnRemoval(prefixKey,
  jobKey, jobId)
  local deduplicationId = rcall("HGET", jobKey, "deid")
  if deduplicationId then
    local deduplicationKey = prefixKey .. "de:" .. deduplicationId
    local currentJobId = rcall('GET', deduplicationKey)
    if currentJobId and currentJobId == jobId then
      return rcall("DEL", deduplicationKey)
    end
  end
end
--[[
  Function to remove from any state.
  returns:
    prev state
]]
local function removeJobFromAnyState( prefix, jobId)
  -- We start with the ZSCORE checks, since they have O(1) complexity
  if rcall("ZSCORE", prefix .. "completed", jobId) then
    rcall("ZREM", prefix .. "completed", jobId)
    return "completed"
  elseif rcall("ZSCORE", prefix .. "waiting-children", jobId) then
    rcall("ZREM", prefix .. "waiting-children", jobId)
    return "waiting-children"
  elseif rcall("ZSCORE", prefix .. "delayed", jobId) then
    rcall("ZREM", prefix .. "delayed", jobId)
    return "delayed"
  elseif rcall("ZSCORE", prefix .. "failed", jobId) then
    rcall("ZREM", prefix .. "failed", jobId)
    return "failed"
  elseif rcall("ZSCORE", prefix .. "prioritized", jobId) then
    rcall("ZREM", prefix .. "prioritized", jobId)
    return "prioritized"
  -- We remove only 1 element from the list, since we assume they are not added multiple times
  elseif rcall("LREM", prefix .. "wait", 1, jobId) == 1 then
    return "wait"
  elseif rcall("LREM", prefix .. "paused", 1, jobId) == 1 then
    return "paused"
  elseif rcall("LREM", prefix .. "active", 1, jobId) == 1 then
    return "active"
  end
  return "unknown"
end
--[[
  Function to remove job keys.
]]
local function removeJobKeys(jobKey)
  return rcall("DEL", jobKey, jobKey .. ':logs', jobKey .. ':dependencies',
    jobKey .. ':processed', jobKey .. ':failed', jobKey .. ':unsuccessful')
end
--[[
  Check if this job has a parent. If so we will just remove it from
  the parent child list, but if it is the last child we should move the parent to "wait/paused"
  which requires code from "moveToFinished"
]]
-- Includes
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
local function _moveParentToWait(parentPrefix, parentId, emitEvent)
  local parentTarget, isPausedOrMaxed = getTargetQueueList(parentPrefix .. "meta", parentPrefix .. "active",
    parentPrefix .. "wait", parentPrefix .. "paused")
  addJobInTargetList(parentTarget, parentPrefix .. "marker", "RPUSH", isPausedOrMaxed, parentId)
  if emitEvent then
    local parentEventStream = parentPrefix .. "events"
    rcall("XADD", parentEventStream, "*", "event", "waiting", "jobId", parentId, "prev", "waiting-children")
  end
end
local function removeParentDependencyKey(jobKey, hard, parentKey, baseKey, debounceId)
  if parentKey then
    local parentDependenciesKey = parentKey .. ":dependencies"
    local result = rcall("SREM", parentDependenciesKey, jobKey)
    if result > 0 then
      local pendingDependencies = rcall("SCARD", parentDependenciesKey)
      if pendingDependencies == 0 then
        local parentId = getJobIdFromKey(parentKey)
        local parentPrefix = getJobKeyPrefix(parentKey, parentId)
        local numRemovedElements = rcall("ZREM", parentPrefix .. "waiting-children", parentId)
        if numRemovedElements == 1 then
          if hard then -- remove parent in same queue
            if parentPrefix == baseKey then
              removeParentDependencyKey(parentKey, hard, nil, baseKey, nil)
              removeJobKeys(parentKey)
              if debounceId then
                rcall("DEL", parentPrefix .. "de:" .. debounceId)
              end
            else
              _moveParentToWait(parentPrefix, parentId)
            end
          else
            _moveParentToWait(parentPrefix, parentId, true)
          end
        end
      end
      return true
    end
  else
    local parentAttributes = rcall("HMGET", jobKey, "parentKey", "deid")
    local missedParentKey = parentAttributes[1]
    if( (type(missedParentKey) == "string") and missedParentKey ~= ""
      and (rcall("EXISTS", missedParentKey) == 1)) then
      local parentDependenciesKey = missedParentKey .. ":dependencies"
      local result = rcall("SREM", parentDependenciesKey, jobKey)
      if result > 0 then
        local pendingDependencies = rcall("SCARD", parentDependenciesKey)
        if pendingDependencies == 0 then
          local parentId = getJobIdFromKey(missedParentKey)
          local parentPrefix = getJobKeyPrefix(missedParentKey, parentId)
          local numRemovedElements = rcall("ZREM", parentPrefix .. "waiting-children", parentId)
          if numRemovedElements == 1 then
            if hard then
              if parentPrefix == baseKey then
                removeParentDependencyKey(missedParentKey, hard, nil, baseKey, nil)
                removeJobKeys(missedParentKey)
                if parentAttributes[2] then
                  rcall("DEL", parentPrefix .. "de:" .. parentAttributes[2])
                end
              else
                _moveParentToWait(parentPrefix, parentId)
              end
            else
              _moveParentToWait(parentPrefix, parentId, true)
            end
          end
        end
        return true
      end
    end
  end
  return false
end
--[[
  Function to recursively check if there are no locks
  on the jobs to be removed.
  returns:
    boolean
]]
local function isLocked( prefix, jobId, removeChildren)
  local jobKey = prefix .. jobId;
  -- Check if this job is locked
  local lockKey = jobKey .. ':lock'
  local lock = rcall("GET", lockKey)
  if not lock then
    if removeChildren == "1" then
      local dependencies = rcall("SMEMBERS", jobKey .. ":dependencies")
      if (#dependencies > 0) then
        for i, childJobKey in ipairs(dependencies) do
          -- We need to get the jobId for this job.
          local childJobId = getJobIdFromKey(childJobKey)
          local childJobPrefix = getJobKeyPrefix(childJobKey, childJobId)
          local result = isLocked( childJobPrefix, childJobId, removeChildren )
          if result then
            return true
          end
        end
      end
    end
    return false
  end
  return true
end
local removeJobChildren
local removeJobWithChildren
removeJobChildren = function(prefix, jobKey, options)
    -- Check if this job has children
    -- If so, we are going to try to remove the children recursively in a depth-first way
    -- because if some job is locked, we must exit with an error.
    if not options.ignoreProcessed then
        local processed = rcall("HGETALL", jobKey .. ":processed")
        if #processed > 0 then
            for i = 1, #processed, 2 do
                local childJobId = getJobIdFromKey(processed[i])
                local childJobPrefix = getJobKeyPrefix(processed[i], childJobId)
                removeJobWithChildren(childJobPrefix, childJobId, jobKey, options)
            end
        end
        local failed = rcall("HGETALL", jobKey .. ":failed")
        if #failed > 0 then
            for i = 1, #failed, 2 do
                local childJobId = getJobIdFromKey(failed[i])
                local childJobPrefix = getJobKeyPrefix(failed[i], childJobId)
                removeJobWithChildren(childJobPrefix, childJobId, jobKey, options)
            end
        end
        local unsuccessful = rcall("ZRANGE", jobKey .. ":unsuccessful", 0, -1)
        if #unsuccessful > 0 then
            for i = 1, #unsuccessful, 1 do
                local childJobId = getJobIdFromKey(unsuccessful[i])
                local childJobPrefix = getJobKeyPrefix(unsuccessful[i], childJobId)
                removeJobWithChildren(childJobPrefix, childJobId, jobKey, options)
            end
        end
    end
    local dependencies = rcall("SMEMBERS", jobKey .. ":dependencies")
    if #dependencies > 0 then
        for i, childJobKey in ipairs(dependencies) do
            local childJobId = getJobIdFromKey(childJobKey)
            local childJobPrefix = getJobKeyPrefix(childJobKey, childJobId)
            removeJobWithChildren(childJobPrefix, childJobId, jobKey, options)
        end
    end
end
removeJobWithChildren = function(prefix, jobId, parentKey, options)
    local jobKey = prefix .. jobId
    if options.ignoreLocked then
        if isLocked(prefix, jobId) then
            return
        end
    end
    -- Check if job is in the failed zset
    local failedSet = prefix .. "failed"
    if not (options.ignoreProcessed and rcall("ZSCORE", failedSet, jobId)) then
        removeParentDependencyKey(jobKey, false, parentKey, nil)
        if options.removeChildren then
            removeJobChildren(prefix, jobKey, options)
        end
        local prev = removeJobFromAnyState(prefix, jobId)
        removeDeduplicationKeyIfNeededOnRemoval(prefix, jobKey, jobId)
        if removeJobKeys(jobKey) > 0 then
            local metaKey = prefix .. "meta"
            local maxEvents = getOrSetMaxEvents(metaKey)
            rcall("XADD", prefix .. "events", "MAXLEN", "~", maxEvents, "*", "event", "removed",
                "jobId", jobId, "prev", prev)
        end
    end
end
local prefix = ARGV[1]
local jobId = ARGV[2]
local jobKey = KEYS[1]
local metaKey = KEYS[2]
local options = {
  removeChildren = "1",
  ignoreProcessed = true,
  ignoreLocked = true
}
removeJobChildren(prefix, jobKey, options) 
`;
const removeUnprocessedChildren = {
    name: 'removeUnprocessedChildren',
    content,
    keys: 2
}; //# sourceMappingURL=removeUnprocessedChildren-2.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/reprocessJob-8.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "reprocessJob",
    ()=>reprocessJob
]);
const content = `--[[
  Attempts to reprocess a job
  Input:
    KEYS[1] job key
    KEYS[2] events stream
    KEYS[3] job state
    KEYS[4] wait key
    KEYS[5] meta
    KEYS[6] paused key
    KEYS[7] active key
    KEYS[8] marker key
    ARGV[1] job.id
    ARGV[2] (job.opts.lifo ? 'R' : 'L') + 'PUSH'
    ARGV[3] propVal - failedReason/returnvalue
    ARGV[4] prev state - failed/completed
  Output:
     1 means the operation was a success
    -1 means the job does not exist
    -3 means the job was not found in the expected set.
]]
local rcall = redis.call;
-- Includes
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to get max events value or set by default 10000.
]]
local function getOrSetMaxEvents(metaKey)
  local maxEvents = rcall("HGET", metaKey, "opts.maxLenEvents")
  if not maxEvents then
    maxEvents = 10000
    rcall("HSET", metaKey, "opts.maxLenEvents", maxEvents)
  end
  return maxEvents
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
local jobKey = KEYS[1]
if rcall("EXISTS", jobKey) == 1 then
  local jobId = ARGV[1]
  if (rcall("ZREM", KEYS[3], jobId) == 1) then
    rcall("HDEL", jobKey, "finishedOn", "processedOn", ARGV[3])
    local target, isPausedOrMaxed = getTargetQueueList(KEYS[5], KEYS[7], KEYS[4], KEYS[6])
    addJobInTargetList(target, KEYS[8], ARGV[2], isPausedOrMaxed, jobId)
    local parentKey = rcall("HGET", jobKey, "parentKey")
    if parentKey and rcall("EXISTS", parentKey) == 1 then
      if ARGV[4] == "failed" then
        if rcall("ZREM", parentKey .. ":unsuccessful", jobKey) == 1 or
          rcall("ZREM", parentKey .. ":failed", jobKey) == 1 then
          rcall("SADD", parentKey .. ":dependencies", jobKey)
        end
      else
        if rcall("HDEL", parentKey .. ":processed", jobKey) == 1 then
          rcall("SADD", parentKey .. ":dependencies", jobKey)
        end
      end
    end
    local maxEvents = getOrSetMaxEvents(KEYS[5])
    -- Emit waiting event
    rcall("XADD", KEYS[2], "MAXLEN", "~", maxEvents, "*", "event", "waiting",
      "jobId", jobId, "prev", ARGV[4]);
    return 1
  else
    return -3
  end
else
  return -1
end
`;
const reprocessJob = {
    name: 'reprocessJob',
    content,
    keys: 8
}; //# sourceMappingURL=reprocessJob-8.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/retryJob-11.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "retryJob",
    ()=>retryJob
]);
const content = `--[[
  Retries a failed job by moving it back to the wait queue.
    Input:
      KEYS[1]  'active',
      KEYS[2]  'wait'
      KEYS[3]  'paused'
      KEYS[4]  job key
      KEYS[5]  'meta'
      KEYS[6]  events stream
      KEYS[7]  delayed key
      KEYS[8]  prioritized key
      KEYS[9]  'pc' priority counter
      KEYS[10] 'marker'
      KEYS[11] 'stalled'
      ARGV[1]  key prefix
      ARGV[2]  timestamp
      ARGV[3]  pushCmd
      ARGV[4]  jobId
      ARGV[5]  token
      ARGV[6]  optional job fields to update
    Events:
      'waiting'
    Output:
     0  - OK
     -1 - Missing key
     -2 - Missing lock
     -3 - Job not in active set
]]
local rcall = redis.call
-- Includes
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to add job considering priority.
]]
-- Includes
--[[
  Function to get priority score.
]]
local function getPriorityScore(priority, priorityCounterKey)
  local prioCounter = rcall("INCR", priorityCounterKey)
  return priority * 0x100000000 + prioCounter % 0x100000000
end
local function addJobWithPriority(markerKey, prioritizedKey, priority, jobId, priorityCounterKey,
  isPausedOrMaxed)
  local score = getPriorityScore(priority, priorityCounterKey)
  rcall("ZADD", prioritizedKey, score, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to get max events value or set by default 10000.
]]
local function getOrSetMaxEvents(metaKey)
  local maxEvents = rcall("HGET", metaKey, "opts.maxLenEvents")
  if not maxEvents then
    maxEvents = 10000
    rcall("HSET", metaKey, "opts.maxLenEvents", maxEvents)
  end
  return maxEvents
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
--[[
  Function to check if queue is paused or maxed
  (since an empty list and !EXISTS are not really the same).
]]
local function isQueuePausedOrMaxed(queueMetaKey, activeKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency")
  if queueAttributes[1] then
    return true
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      return activeCount >= tonumber(queueAttributes[2])
    end
  end
  return false
end
--[[
  Updates the delay set, by moving delayed jobs that should
  be processed now to "wait".
     Events:
      'waiting'
]]
-- Includes
-- Try to get as much as 1000 jobs at once
local function promoteDelayedJobs(delayedKey, markerKey, targetKey, prioritizedKey,
                                  eventStreamKey, prefix, timestamp, priorityCounterKey, isPaused)
    local jobs = rcall("ZRANGEBYSCORE", delayedKey, 0, (timestamp + 1) * 0x1000 - 1, "LIMIT", 0, 1000)
    if (#jobs > 0) then
        rcall("ZREM", delayedKey, unpack(jobs))
        for _, jobId in ipairs(jobs) do
            local jobKey = prefix .. jobId
            local priority =
                tonumber(rcall("HGET", jobKey, "priority")) or 0
            if priority == 0 then
                -- LIFO or FIFO
                rcall("LPUSH", targetKey, jobId)
            else
                local score = getPriorityScore(priority, priorityCounterKey)
                rcall("ZADD", prioritizedKey, score, jobId)
            end
            -- Emit waiting event
            rcall("XADD", eventStreamKey, "*", "event", "waiting", "jobId",
                  jobId, "prev", "delayed")
            rcall("HSET", jobKey, "delay", 0)
        end
        addBaseMarkerIfNeeded(markerKey, isPaused)
    end
end
local function removeLock(jobKey, stalledKey, token, jobId)
  if token ~= "0" then
    local lockKey = jobKey .. ':lock'
    local lockToken = rcall("GET", lockKey)
    if lockToken == token then
      rcall("DEL", lockKey)
      rcall("SREM", stalledKey, jobId)
    else
      if lockToken then
        -- Lock exists but token does not match
        return -6
      else
        -- Lock is missing completely
        return -2
      end
    end
  end
  return 0
end
--[[
  Function to update a bunch of fields in a job.
]]
local function updateJobFields(jobKey, msgpackedFields)
  if msgpackedFields and #msgpackedFields > 0 then
    local fieldsToUpdate = cmsgpack.unpack(msgpackedFields)
    if fieldsToUpdate then
      rcall("HMSET", jobKey, unpack(fieldsToUpdate))
    end
  end
end
local target, isPausedOrMaxed = getTargetQueueList(KEYS[5], KEYS[1], KEYS[2], KEYS[3])
local markerKey = KEYS[10]
-- Check if there are delayed jobs that we can move to wait.
-- test example: when there are delayed jobs between retries
promoteDelayedJobs(KEYS[7], markerKey, target, KEYS[8], KEYS[6], ARGV[1], ARGV[2], KEYS[9], isPausedOrMaxed)
local jobKey = KEYS[4]
if rcall("EXISTS", jobKey) == 1 then
  local errorCode = removeLock(jobKey, KEYS[11], ARGV[5], ARGV[4]) 
  if errorCode < 0 then
    return errorCode
  end
  updateJobFields(jobKey, ARGV[6])
  local numRemovedElements = rcall("LREM", KEYS[1], -1, ARGV[4])
  if (numRemovedElements < 1) then return -3 end
  local priority = tonumber(rcall("HGET", jobKey, "priority")) or 0
  --need to re-evaluate after removing job from active
  isPausedOrMaxed = isQueuePausedOrMaxed(KEYS[5], KEYS[1])
  -- Standard or priority add
  if priority == 0 then
    addJobInTargetList(target, markerKey, ARGV[3], isPausedOrMaxed, ARGV[4])
  else
    addJobWithPriority(markerKey, KEYS[8], priority, ARGV[4], KEYS[9], isPausedOrMaxed)
  end
  rcall("HINCRBY", jobKey, "atm", 1)
  local maxEvents = getOrSetMaxEvents(KEYS[5])
  -- Emit waiting event
  rcall("XADD", KEYS[6], "MAXLEN", "~", maxEvents, "*", "event", "waiting",
    "jobId", ARGV[4], "prev", "active")
  return 0
else
  return -1
end
`;
const retryJob = {
    name: 'retryJob',
    content,
    keys: 11
}; //# sourceMappingURL=retryJob-11.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/saveStacktrace-1.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "saveStacktrace",
    ()=>saveStacktrace
]);
const content = `--[[
  Save stacktrace and failedReason.
  Input:
    KEYS[1] job key
    ARGV[1]  stacktrace
    ARGV[2]  failedReason
  Output:
     0 - OK
    -1 - Missing key
]]
local rcall = redis.call
if rcall("EXISTS", KEYS[1]) == 1 then
  rcall("HMSET", KEYS[1], "stacktrace", ARGV[1], "failedReason", ARGV[2])
  return 0
else
  return -1
end
`;
const saveStacktrace = {
    name: 'saveStacktrace',
    content,
    keys: 1
}; //# sourceMappingURL=saveStacktrace-1.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/updateData-1.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "updateData",
    ()=>updateData
]);
const content = `--[[
  Update job data
  Input:
    KEYS[1] Job id key
    ARGV[1] data
  Output:
    0 - OK
   -1 - Missing job.
]]
local rcall = redis.call
if rcall("EXISTS",KEYS[1]) == 1 then -- // Make sure job exists
  rcall("HSET", KEYS[1], "data", ARGV[1])
  return 0
else
  return -1
end
`;
const updateData = {
    name: 'updateData',
    content,
    keys: 1
}; //# sourceMappingURL=updateData-1.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/updateJobScheduler-12.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "updateJobScheduler",
    ()=>updateJobScheduler
]);
const content = `--[[
  Updates a job scheduler and adds next delayed job
  Input:
    KEYS[1]  'repeat' key
    KEYS[2]  'delayed'
    KEYS[3]  'wait' key
    KEYS[4]  'paused' key
    KEYS[5]  'meta'
    KEYS[6]  'prioritized' key
    KEYS[7]  'marker',
    KEYS[8]  'id'
    KEYS[9]  events stream key
    KEYS[10] 'pc' priority counter
    KEYS[11] producer key
    KEYS[12] 'active' key
    ARGV[1] next milliseconds
    ARGV[2] jobs scheduler id
    ARGV[3] Json stringified delayed data
    ARGV[4] msgpacked delayed opts
    ARGV[5] timestamp
    ARGV[6] prefix key
    ARGV[7] producer id
    Output:
      next delayed job id  - OK
]] local rcall = redis.call
local repeatKey = KEYS[1]
local delayedKey = KEYS[2]
local waitKey = KEYS[3]
local pausedKey = KEYS[4]
local metaKey = KEYS[5]
local prioritizedKey = KEYS[6]
local nextMillis = tonumber(ARGV[1])
local jobSchedulerId = ARGV[2]
local timestamp = tonumber(ARGV[5])
local prefixKey = ARGV[6]
local producerId = ARGV[7]
local jobOpts = cmsgpack.unpack(ARGV[4])
-- Includes
--[[
  Add delay marker if needed.
]]
-- Includes
--[[
  Adds a delayed job to the queue by doing the following:
    - Creates a new job key with the job data.
    - adds to delayed zset.
    - Emits a global event 'delayed' if the job is delayed.
]]
-- Includes
--[[
  Add delay marker if needed.
]]
-- Includes
--[[
  Function to return the next delayed job timestamp.
]]
local function getNextDelayedTimestamp(delayedKey)
  local result = rcall("ZRANGE", delayedKey, 0, 0, "WITHSCORES")
  if #result then
    local nextTimestamp = tonumber(result[2])
    if nextTimestamp ~= nil then
      return nextTimestamp / 0x1000
    end
  end
end
local function addDelayMarkerIfNeeded(markerKey, delayedKey)
  local nextTimestamp = getNextDelayedTimestamp(delayedKey)
  if nextTimestamp ~= nil then
    -- Replace the score of the marker with the newest known
    -- next timestamp.
    rcall("ZADD", markerKey, nextTimestamp, "1")
  end
end
--[[
  Bake in the job id first 12 bits into the timestamp
  to guarantee correct execution order of delayed jobs
  (up to 4096 jobs per given timestamp or 4096 jobs apart per timestamp)
  WARNING: Jobs that are so far apart that they wrap around will cause FIFO to fail
]]
local function getDelayedScore(delayedKey, timestamp, delay)
  local delayedTimestamp = (delay > 0 and (tonumber(timestamp) + delay)) or tonumber(timestamp)
  local minScore = delayedTimestamp * 0x1000
  local maxScore = (delayedTimestamp + 1 ) * 0x1000 - 1
  local result = rcall("ZREVRANGEBYSCORE", delayedKey, maxScore,
    minScore, "WITHSCORES","LIMIT", 0, 1)
  if #result then
    local currentMaxScore = tonumber(result[2])
    if currentMaxScore ~= nil then
      if currentMaxScore >= maxScore then
        return maxScore, delayedTimestamp
      else
        return currentMaxScore + 1, delayedTimestamp
      end
    end
  end
  return minScore, delayedTimestamp
end
local function addDelayedJob(jobId, delayedKey, eventsKey, timestamp,
  maxEvents, markerKey, delay)
  local score, delayedTimestamp = getDelayedScore(delayedKey, timestamp, tonumber(delay))
  rcall("ZADD", delayedKey, score, jobId)
  rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "delayed",
    "jobId", jobId, "delay", delayedTimestamp)
  -- mark that a delayed job is available
  addDelayMarkerIfNeeded(markerKey, delayedKey)
end
--[[
  Function to add job considering priority.
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
--[[
  Function to get priority score.
]]
local function getPriorityScore(priority, priorityCounterKey)
  local prioCounter = rcall("INCR", priorityCounterKey)
  return priority * 0x100000000 + prioCounter % 0x100000000
end
local function addJobWithPriority(markerKey, prioritizedKey, priority, jobId, priorityCounterKey,
  isPausedOrMaxed)
  local score = getPriorityScore(priority, priorityCounterKey)
  rcall("ZADD", prioritizedKey, score, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function isQueuePaused(queueMetaKey)
  return rcall("HEXISTS", queueMetaKey, "paused") == 1
end
--[[
  Function to store a job
]]
local function storeJob(eventsKey, jobIdKey, jobId, name, data, opts, timestamp,
                        parentKey, parentData, repeatJobKey)
    local jsonOpts = cjson.encode(opts)
    local delay = opts['delay'] or 0
    local priority = opts['priority'] or 0
    local debounceId = opts['de'] and opts['de']['id']
    local optionalValues = {}
    if parentKey ~= nil then
        table.insert(optionalValues, "parentKey")
        table.insert(optionalValues, parentKey)
        table.insert(optionalValues, "parent")
        table.insert(optionalValues, parentData)
    end
    if repeatJobKey then
        table.insert(optionalValues, "rjk")
        table.insert(optionalValues, repeatJobKey)
    end
    if debounceId then
        table.insert(optionalValues, "deid")
        table.insert(optionalValues, debounceId)
    end
    rcall("HMSET", jobIdKey, "name", name, "data", data, "opts", jsonOpts,
          "timestamp", timestamp, "delay", delay, "priority", priority,
          unpack(optionalValues))
    rcall("XADD", eventsKey, "*", "event", "added", "jobId", jobId, "name", name)
    return delay, priority
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency", "max", "duration")
  if queueAttributes[1] then
    return pausedKey, true, queueAttributes[3], queueAttributes[4]
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true, queueAttributes[3], queueAttributes[4]
      else
        return waitKey, false, queueAttributes[3], queueAttributes[4]
      end
    end
  end
  return waitKey, false, queueAttributes[3], queueAttributes[4]
end
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
local function addJobFromScheduler(jobKey, jobId, opts, waitKey, pausedKey, activeKey, metaKey, 
  prioritizedKey, priorityCounter, delayedKey, markerKey, eventsKey, name, maxEvents, timestamp,
  data, jobSchedulerId, repeatDelay)
  opts['delay'] = repeatDelay
  opts['jobId'] = jobId
  local delay, priority = storeJob(eventsKey, jobKey, jobId, name, data,
    opts, timestamp, nil, nil, jobSchedulerId)
  if delay ~= 0 then
    addDelayedJob(jobId, delayedKey, eventsKey, timestamp, maxEvents, markerKey, delay)
  else
    local target, isPausedOrMaxed = getTargetQueueList(metaKey, activeKey, waitKey, pausedKey)
    -- Standard or priority add
    if priority == 0 then
      local pushCmd = opts['lifo'] and 'RPUSH' or 'LPUSH'
      addJobInTargetList(target, markerKey, pushCmd, isPausedOrMaxed, jobId)
    else
      -- Priority add
      addJobWithPriority(markerKey, prioritizedKey, priority, jobId, priorityCounter, isPausedOrMaxed)
    end
    -- Emit waiting event
    rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents,  "*", "event", "waiting", "jobId", jobId)
  end
end
--[[
  Function to get max events value or set by default 10000.
]]
local function getOrSetMaxEvents(metaKey)
  local maxEvents = rcall("HGET", metaKey, "opts.maxLenEvents")
  if not maxEvents then
    maxEvents = 10000
    rcall("HSET", metaKey, "opts.maxLenEvents", maxEvents)
  end
  return maxEvents
end
local function getJobSchedulerEveryNextMillis(prevMillis, every, now, offset, startDate)
    local nextMillis
    if not prevMillis then
        if startDate then
            -- Assuming startDate is passed as milliseconds from JavaScript
            nextMillis = tonumber(startDate)
            nextMillis = nextMillis > now and nextMillis or now
        else
            nextMillis = now
        end
    else
        nextMillis = prevMillis + every
        -- check if we may have missed some iterations
        if nextMillis < now then
            nextMillis = math.floor(now / every) * every + every + (offset or 0)
        end
    end
    if not offset or offset == 0 then
        local timeSlot = math.floor(nextMillis / every) * every;
        offset = nextMillis - timeSlot;
    end
    -- Return a tuple nextMillis, offset
    return math.floor(nextMillis), math.floor(offset)
end
local prevMillis = rcall("ZSCORE", repeatKey, jobSchedulerId)
-- Validate that scheduler exists.
-- If it does not exist we should not iterate anymore.
if prevMillis then
    prevMillis = tonumber(prevMillis)
    local schedulerKey = repeatKey .. ":" .. jobSchedulerId
    local schedulerAttributes = rcall("HMGET", schedulerKey, "name", "data", "every", "startDate", "offset")
    local every = tonumber(schedulerAttributes[3])
    local now = tonumber(timestamp)
    -- If every is not found in scheduler attributes, try to get it from job options
    if not every and jobOpts['repeat'] and jobOpts['repeat']['every'] then
        every = tonumber(jobOpts['repeat']['every'])
    end
    if every then
        local startDate = schedulerAttributes[4]
        local jobOptsOffset = jobOpts['repeat'] and jobOpts['repeat']['offset'] or 0
        local offset = schedulerAttributes[5] or jobOptsOffset or 0
        local newOffset
        nextMillis, newOffset = getJobSchedulerEveryNextMillis(prevMillis, every, now, offset, startDate)
        if not offset then
            rcall("HSET", schedulerKey, "offset", newOffset)
            jobOpts['repeat']['offset'] = newOffset
        end
    end
    local nextDelayedJobId = "repeat:" .. jobSchedulerId .. ":" .. nextMillis
    local nextDelayedJobKey = schedulerKey .. ":" .. nextMillis
    local currentDelayedJobId = "repeat:" .. jobSchedulerId .. ":" .. prevMillis
    if producerId == currentDelayedJobId then
        local eventsKey = KEYS[9]
        local maxEvents = getOrSetMaxEvents(metaKey)
        if rcall("EXISTS", nextDelayedJobKey) ~= 1 then
            rcall("ZADD", repeatKey, nextMillis, jobSchedulerId)
            rcall("HINCRBY", schedulerKey, "ic", 1)
            rcall("INCR", KEYS[8])
            -- TODO: remove this workaround in next breaking change,
            -- all job-schedulers must save job data
            local templateData = schedulerAttributes[2] or ARGV[3]
            if templateData and templateData ~= '{}' then
                rcall("HSET", schedulerKey, "data", templateData)
            end
            local delay = nextMillis - now
            -- Fast Clamp delay to minimum of 0
            if delay < 0 then
                delay = 0
            end
            jobOpts["delay"] = delay
            addJobFromScheduler(nextDelayedJobKey, nextDelayedJobId, jobOpts, waitKey, pausedKey, KEYS[12], metaKey,
                prioritizedKey, KEYS[10], delayedKey, KEYS[7], eventsKey, schedulerAttributes[1], maxEvents, ARGV[5],
                templateData or '{}', jobSchedulerId, delay)
            -- TODO: remove this workaround in next breaking change
            if KEYS[11] ~= "" then
                rcall("HSET", KEYS[11], "nrjid", nextDelayedJobId)
            end
            return nextDelayedJobId .. "" -- convert to string
        else
            rcall("XADD", eventsKey, "MAXLEN", "~", maxEvents, "*", "event", "duplicated", "jobId", nextDelayedJobId)
        end
    end
end
`;
const updateJobScheduler = {
    name: 'updateJobScheduler',
    content,
    keys: 12
}; //# sourceMappingURL=updateJobScheduler-12.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/updateProgress-3.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "updateProgress",
    ()=>updateProgress
]);
const content = `--[[
  Update job progress
  Input:
    KEYS[1] Job id key
    KEYS[2] event stream key
    KEYS[3] meta key
    ARGV[1] id
    ARGV[2] progress
  Output:
     0 - OK
    -1 - Missing job.
  Event:
    progress(jobId, progress)
]]
local rcall = redis.call
-- Includes
--[[
  Function to get max events value or set by default 10000.
]]
local function getOrSetMaxEvents(metaKey)
  local maxEvents = rcall("HGET", metaKey, "opts.maxLenEvents")
  if not maxEvents then
    maxEvents = 10000
    rcall("HSET", metaKey, "opts.maxLenEvents", maxEvents)
  end
  return maxEvents
end
if rcall("EXISTS", KEYS[1]) == 1 then -- // Make sure job exists
    local maxEvents = getOrSetMaxEvents(KEYS[3])
    rcall("HSET", KEYS[1], "progress", ARGV[2])
    rcall("XADD", KEYS[2], "MAXLEN", "~", maxEvents, "*", "event", "progress",
          "jobId", ARGV[1], "data", ARGV[2]);
    return 0
else
    return -1
end
`;
const updateProgress = {
    name: 'updateProgress',
    content,
    keys: 3
}; //# sourceMappingURL=updateProgress-3.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/updateRepeatableJobMillis-1.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "updateRepeatableJobMillis",
    ()=>updateRepeatableJobMillis
]);
const content = `--[[
  Adds a repeatable job
    Input:
      KEYS[1] 'repeat' key
      ARGV[1] next milliseconds
      ARGV[2] custom key
      ARGV[3] legacy custom key TODO: remove this logic in next breaking change
      Output:
        repeatableKey  - OK
]]
local rcall = redis.call
local repeatKey = KEYS[1]
local nextMillis = ARGV[1]
local customKey = ARGV[2]
local legacyCustomKey = ARGV[3]
if rcall("ZSCORE", repeatKey, customKey) then
    rcall("ZADD", repeatKey, nextMillis, customKey)
    return customKey
elseif rcall("ZSCORE", repeatKey, legacyCustomKey) ~= false then
    rcall("ZADD", repeatKey, nextMillis, legacyCustomKey)
    return legacyCustomKey
end
return ''
`;
const updateRepeatableJobMillis = {
    name: 'updateRepeatableJobMillis',
    content,
    keys: 1
}; //# sourceMappingURL=updateRepeatableJobMillis-1.js.map
}),
"[project]/node_modules/bullmq/dist/esm/scripts/index.js [app-route] (ecmascript) <locals>", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$addDelayedJob$2d$6$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/addDelayedJob-6.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$addJobScheduler$2d$11$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/addJobScheduler-11.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$addLog$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/addLog-2.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$addParentJob$2d$6$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/addParentJob-6.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$addPrioritizedJob$2d$9$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/addPrioritizedJob-9.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$addRepeatableJob$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/addRepeatableJob-2.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$addStandardJob$2d$9$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/addStandardJob-9.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$changeDelay$2d$4$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/changeDelay-4.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$changePriority$2d$7$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/changePriority-7.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$cleanJobsInSet$2d$3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/cleanJobsInSet-3.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$drain$2d$5$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/drain-5.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$extendLock$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/extendLock-2.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$extendLocks$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/extendLocks-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getCounts$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/getCounts-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getCountsPerPriority$2d$4$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/getCountsPerPriority-4.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getDependencyCounts$2d$4$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/getDependencyCounts-4.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getJobScheduler$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/getJobScheduler-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getMetrics$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/getMetrics-2.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getRanges$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/getRanges-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getRateLimitTtl$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/getRateLimitTtl-2.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getState$2d$8$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/getState-8.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getStateV2$2d$8$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/getStateV2-8.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$isFinished$2d$3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/isFinished-3.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$isJobInList$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/isJobInList-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$isMaxed$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/isMaxed-2.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$moveJobFromActiveToWait$2d$9$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/moveJobFromActiveToWait-9.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$moveJobsToWait$2d$8$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/moveJobsToWait-8.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$moveStalledJobsToWait$2d$8$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/moveStalledJobsToWait-8.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$moveToActive$2d$11$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/moveToActive-11.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$moveToDelayed$2d$8$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/moveToDelayed-8.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$moveToFinished$2d$14$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/moveToFinished-14.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$moveToWaitingChildren$2d$7$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/moveToWaitingChildren-7.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$obliterate$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/obliterate-2.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$paginate$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/paginate-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$pause$2d$7$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/pause-7.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$promote$2d$9$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/promote-9.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$releaseLock$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/releaseLock-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$removeChildDependency$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/removeChildDependency-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$removeDeduplicationKey$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/removeDeduplicationKey-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$removeJob$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/removeJob-2.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$removeJobScheduler$2d$3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/removeJobScheduler-3.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$removeRepeatable$2d$3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/removeRepeatable-3.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$removeUnprocessedChildren$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/removeUnprocessedChildren-2.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$reprocessJob$2d$8$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/reprocessJob-8.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$retryJob$2d$11$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/retryJob-11.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$saveStacktrace$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/saveStacktrace-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$updateData$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/updateData-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$updateJobScheduler$2d$12$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/updateJobScheduler-12.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$updateProgress$2d$3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/updateProgress-3.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$updateRepeatableJobMillis$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/updateRepeatableJobMillis-1.js [app-route] (ecmascript)"); //# sourceMappingURL=index.js.map
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
}),
"[project]/node_modules/bullmq/dist/esm/scripts/index.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "addDelayedJob",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$addDelayedJob$2d$6$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["addDelayedJob"],
    "addJobScheduler",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$addJobScheduler$2d$11$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["addJobScheduler"],
    "addLog",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$addLog$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["addLog"],
    "addParentJob",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$addParentJob$2d$6$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["addParentJob"],
    "addPrioritizedJob",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$addPrioritizedJob$2d$9$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["addPrioritizedJob"],
    "addRepeatableJob",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$addRepeatableJob$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["addRepeatableJob"],
    "addStandardJob",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$addStandardJob$2d$9$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["addStandardJob"],
    "changeDelay",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$changeDelay$2d$4$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["changeDelay"],
    "changePriority",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$changePriority$2d$7$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["changePriority"],
    "cleanJobsInSet",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$cleanJobsInSet$2d$3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["cleanJobsInSet"],
    "drain",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$drain$2d$5$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["drain"],
    "extendLock",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$extendLock$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["extendLock"],
    "extendLocks",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$extendLocks$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["extendLocks"],
    "getCounts",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getCounts$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getCounts"],
    "getCountsPerPriority",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getCountsPerPriority$2d$4$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getCountsPerPriority"],
    "getDependencyCounts",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getDependencyCounts$2d$4$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getDependencyCounts"],
    "getJobScheduler",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getJobScheduler$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getJobScheduler"],
    "getMetrics",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getMetrics$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getMetrics"],
    "getRanges",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getRanges$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getRanges"],
    "getRateLimitTtl",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getRateLimitTtl$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getRateLimitTtl"],
    "getState",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getState$2d$8$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getState"],
    "getStateV2",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getStateV2$2d$8$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getStateV2"],
    "isFinished",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$isFinished$2d$3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isFinished"],
    "isJobInList",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$isJobInList$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isJobInList"],
    "isMaxed",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$isMaxed$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isMaxed"],
    "moveJobFromActiveToWait",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$moveJobFromActiveToWait$2d$9$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["moveJobFromActiveToWait"],
    "moveJobsToWait",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$moveJobsToWait$2d$8$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["moveJobsToWait"],
    "moveStalledJobsToWait",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$moveStalledJobsToWait$2d$8$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["moveStalledJobsToWait"],
    "moveToActive",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$moveToActive$2d$11$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["moveToActive"],
    "moveToDelayed",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$moveToDelayed$2d$8$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["moveToDelayed"],
    "moveToFinished",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$moveToFinished$2d$14$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["moveToFinished"],
    "moveToWaitingChildren",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$moveToWaitingChildren$2d$7$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["moveToWaitingChildren"],
    "obliterate",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$obliterate$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["obliterate"],
    "paginate",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$paginate$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["paginate"],
    "pause",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$pause$2d$7$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["pause"],
    "promote",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$promote$2d$9$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["promote"],
    "releaseLock",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$releaseLock$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["releaseLock"],
    "removeChildDependency",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$removeChildDependency$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["removeChildDependency"],
    "removeDeduplicationKey",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$removeDeduplicationKey$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["removeDeduplicationKey"],
    "removeJob",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$removeJob$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["removeJob"],
    "removeJobScheduler",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$removeJobScheduler$2d$3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["removeJobScheduler"],
    "removeRepeatable",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$removeRepeatable$2d$3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["removeRepeatable"],
    "removeUnprocessedChildren",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$removeUnprocessedChildren$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["removeUnprocessedChildren"],
    "reprocessJob",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$reprocessJob$2d$8$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["reprocessJob"],
    "retryJob",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$retryJob$2d$11$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["retryJob"],
    "saveStacktrace",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$saveStacktrace$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["saveStacktrace"],
    "updateData",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$updateData$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["updateData"],
    "updateJobScheduler",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$updateJobScheduler$2d$12$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["updateJobScheduler"],
    "updateProgress",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$updateProgress$2d$3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["updateProgress"],
    "updateRepeatableJobMillis",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$updateRepeatableJobMillis$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["updateRepeatableJobMillis"]
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$addDelayedJob$2d$6$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/addDelayedJob-6.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$addJobScheduler$2d$11$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/addJobScheduler-11.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$addLog$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/addLog-2.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$addParentJob$2d$6$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/addParentJob-6.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$addPrioritizedJob$2d$9$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/addPrioritizedJob-9.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$addRepeatableJob$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/addRepeatableJob-2.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$addStandardJob$2d$9$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/addStandardJob-9.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$changeDelay$2d$4$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/changeDelay-4.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$changePriority$2d$7$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/changePriority-7.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$cleanJobsInSet$2d$3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/cleanJobsInSet-3.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$drain$2d$5$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/drain-5.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$extendLock$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/extendLock-2.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$extendLocks$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/extendLocks-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getCounts$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/getCounts-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getCountsPerPriority$2d$4$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/getCountsPerPriority-4.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getDependencyCounts$2d$4$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/getDependencyCounts-4.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getJobScheduler$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/getJobScheduler-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getMetrics$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/getMetrics-2.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getRanges$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/getRanges-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getRateLimitTtl$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/getRateLimitTtl-2.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getState$2d$8$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/getState-8.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$getStateV2$2d$8$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/getStateV2-8.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$isFinished$2d$3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/isFinished-3.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$isJobInList$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/isJobInList-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$isMaxed$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/isMaxed-2.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$moveJobFromActiveToWait$2d$9$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/moveJobFromActiveToWait-9.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$moveJobsToWait$2d$8$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/moveJobsToWait-8.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$moveStalledJobsToWait$2d$8$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/moveStalledJobsToWait-8.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$moveToActive$2d$11$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/moveToActive-11.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$moveToDelayed$2d$8$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/moveToDelayed-8.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$moveToFinished$2d$14$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/moveToFinished-14.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$moveToWaitingChildren$2d$7$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/moveToWaitingChildren-7.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$obliterate$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/obliterate-2.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$paginate$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/paginate-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$pause$2d$7$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/pause-7.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$promote$2d$9$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/promote-9.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$releaseLock$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/releaseLock-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$removeChildDependency$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/removeChildDependency-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$removeDeduplicationKey$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/removeDeduplicationKey-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$removeJob$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/removeJob-2.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$removeJobScheduler$2d$3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/removeJobScheduler-3.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$removeRepeatable$2d$3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/removeRepeatable-3.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$removeUnprocessedChildren$2d$2$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/removeUnprocessedChildren-2.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$reprocessJob$2d$8$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/reprocessJob-8.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$retryJob$2d$11$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/retryJob-11.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$saveStacktrace$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/saveStacktrace-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$updateData$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/updateData-1.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$updateJobScheduler$2d$12$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/updateJobScheduler-12.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$updateProgress$2d$3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/updateProgress-3.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$updateRepeatableJobMillis$2d$1$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/updateRepeatableJobMillis-1.js [app-route] (ecmascript)");
}),
"[project]/node_modules/bullmq/dist/esm/classes/redis-connection.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "RedisConnection",
    ()=>RedisConnection
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$tslib$2f$tslib$2e$es6$2e$mjs__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/tslib/tslib.es6.mjs [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$externals$5d2f$events__$5b$external$5d$__$28$events$2c$__cjs$29$__ = __turbopack_context__.i("[externals]/events [external] (events, cjs)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$ioredis$2f$built$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/ioredis/built/index.js [app-route] (ecmascript)");
// eslint-disable-next-line @typescript-eslint/ban-ts-comment
// @ts-ignore
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$ioredis$2f$built$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/ioredis/built/utils/index.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/utils/index.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$version$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/version.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/scripts/index.js [app-route] (ecmascript)");
;
;
;
;
;
;
;
const overrideMessage = [
    'BullMQ: WARNING! Your redis options maxRetriesPerRequest must be null',
    'and will be overridden by BullMQ.'
].join(' ');
const deprecationMessage = 'BullMQ: Your redis options maxRetriesPerRequest must be null.';
class RedisConnection extends __TURBOPACK__imported__module__$5b$externals$5d2f$events__$5b$external$5d$__$28$events$2c$__cjs$29$__["EventEmitter"] {
    constructor(opts, extraOptions){
        super();
        this.extraOptions = extraOptions;
        this.capabilities = {
            canDoubleTimeout: false,
            canBlockFor1Ms: true
        };
        this.status = 'initializing';
        this.packageVersion = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$version$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["version"];
        // Set extra options defaults
        this.extraOptions = Object.assign({
            shared: false,
            blocking: true,
            skipVersionCheck: false,
            skipWaitingForReady: false
        }, extraOptions);
        if (!(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isRedisInstance"])(opts)) {
            this.checkBlockingOptions(overrideMessage, opts);
            this.opts = Object.assign({
                port: 6379,
                host: '127.0.0.1',
                retryStrategy: function(times) {
                    return Math.max(Math.min(Math.exp(times), 20000), 1000);
                }
            }, opts);
            if (this.extraOptions.blocking) {
                this.opts.maxRetriesPerRequest = null;
            }
        } else {
            this._client = opts;
            // Test if the redis instance is using keyPrefix
            // and if so, throw an error.
            if (this._client.options.keyPrefix) {
                throw new Error('BullMQ: ioredis does not support ioredis prefixes, use the prefix option instead.');
            }
            if ((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isRedisCluster"])(this._client)) {
                this.opts = this._client.options.redisOptions;
            } else {
                this.opts = this._client.options;
            }
            this.checkBlockingOptions(deprecationMessage, this.opts, true);
        }
        this.skipVersionCheck = (extraOptions === null || extraOptions === void 0 ? void 0 : extraOptions.skipVersionCheck) || !!(this.opts && this.opts.skipVersionCheck);
        this.handleClientError = (err)=>{
            this.emit('error', err);
        };
        this.handleClientClose = ()=>{
            this.emit('close');
        };
        this.handleClientReady = ()=>{
            this.emit('ready');
        };
        this.initializing = this.init();
        this.initializing.catch((err)=>this.emit('error', err));
    }
    checkBlockingOptions(msg, options, throwError = false) {
        if (this.extraOptions.blocking && options && options.maxRetriesPerRequest) {
            if (throwError) {
                throw new Error(msg);
            } else {
                console.error(msg);
            }
        }
    }
    /**
     * Waits for a redis client to be ready.
     * @param redis - client
     */ static async waitUntilReady(client) {
        if (client.status === 'ready') {
            return;
        }
        if (client.status === 'wait') {
            return client.connect();
        }
        if (client.status === 'end') {
            throw new Error(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$ioredis$2f$built$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["CONNECTION_CLOSED_ERROR_MSG"]);
        }
        let handleReady;
        let handleEnd;
        let handleError;
        try {
            await new Promise((resolve, reject)=>{
                let lastError;
                handleError = (err)=>{
                    lastError = err;
                };
                handleReady = ()=>{
                    resolve();
                };
                handleEnd = ()=>{
                    if (client.status !== 'end') {
                        reject(lastError || new Error(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$ioredis$2f$built$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["CONNECTION_CLOSED_ERROR_MSG"]));
                    } else {
                        if (lastError) {
                            reject(lastError);
                        } else {
                            // when custon 'end' status is set we already closed
                            resolve();
                        }
                    }
                };
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["increaseMaxListeners"])(client, 3);
                client.once('ready', handleReady);
                client.on('end', handleEnd);
                client.once('error', handleError);
            });
        } finally{
            client.removeListener('end', handleEnd);
            client.removeListener('error', handleError);
            client.removeListener('ready', handleReady);
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["decreaseMaxListeners"])(client, 3);
        }
    }
    get client() {
        return this.initializing;
    }
    loadCommands(packageVersion, providedScripts) {
        const finalScripts = providedScripts || __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$scripts$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__;
        for(const property in finalScripts){
            // Only define the command if not already defined
            const commandName = `${finalScripts[property].name}:${packageVersion}`;
            if (!this._client[commandName]) {
                this._client.defineCommand(commandName, {
                    numberOfKeys: finalScripts[property].keys,
                    lua: finalScripts[property].content
                });
            }
        }
    }
    async init() {
        if (!this._client) {
            const _a = this.opts, { url } = _a, rest = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$tslib$2f$tslib$2e$es6$2e$mjs__$5b$app$2d$route$5d$__$28$ecmascript$29$__["__rest"])(_a, [
                "url"
            ]);
            this._client = url ? new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$ioredis$2f$built$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["default"](url, rest) : new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$ioredis$2f$built$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["default"](rest);
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["increaseMaxListeners"])(this._client, 3);
        this._client.on('error', this.handleClientError);
        // ioredis treats connection errors as a different event ('close')
        this._client.on('close', this.handleClientClose);
        this._client.on('ready', this.handleClientReady);
        if (!this.extraOptions.skipWaitingForReady) {
            await RedisConnection.waitUntilReady(this._client);
        }
        this.loadCommands(this.packageVersion);
        if (this._client['status'] !== 'end') {
            this.version = await this.getRedisVersion();
            if (this.skipVersionCheck !== true && !this.closing) {
                if ((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isRedisVersionLowerThan"])(this.version, RedisConnection.minimumVersion)) {
                    throw new Error(`Redis version needs to be greater or equal than ${RedisConnection.minimumVersion} ` + `Current: ${this.version}`);
                }
                if ((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isRedisVersionLowerThan"])(this.version, RedisConnection.recommendedMinimumVersion)) {
                    console.warn(`It is highly recommended to use a minimum Redis version of ${RedisConnection.recommendedMinimumVersion}
             Current: ${this.version}`);
                }
            }
            this.capabilities = {
                canDoubleTimeout: !(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isRedisVersionLowerThan"])(this.version, '6.0.0'),
                canBlockFor1Ms: !(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isRedisVersionLowerThan"])(this.version, '7.0.8')
            };
            this.status = 'ready';
        }
        return this._client;
    }
    async disconnect(wait = true) {
        const client = await this.client;
        if (client.status !== 'end') {
            let _resolve, _reject;
            if (!wait) {
                return client.disconnect();
            }
            const disconnecting = new Promise((resolve, reject)=>{
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["increaseMaxListeners"])(client, 2);
                client.once('end', resolve);
                client.once('error', reject);
                _resolve = resolve;
                _reject = reject;
            });
            client.disconnect();
            try {
                await disconnecting;
            } finally{
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["decreaseMaxListeners"])(client, 2);
                client.removeListener('end', _resolve);
                client.removeListener('error', _reject);
            }
        }
    }
    async reconnect() {
        const client = await this.client;
        return client.connect();
    }
    async close(force = false) {
        if (!this.closing) {
            const status = this.status;
            this.status = 'closing';
            this.closing = true;
            try {
                if (status === 'ready') {
                    // Not sure if we need to wait for this
                    await this.initializing;
                }
                if (!this.extraOptions.shared) {
                    if (status == 'initializing' || force) {
                        // If we have not still connected to Redis, we need to disconnect.
                        this._client.disconnect();
                    } else {
                        await this._client.quit();
                    }
                    // As IORedis does not update this status properly, we do it ourselves.
                    this._client['status'] = 'end';
                }
            } catch (error) {
                if ((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isNotConnectionError"])(error)) {
                    throw error;
                }
            } finally{
                this._client.off('error', this.handleClientError);
                this._client.off('close', this.handleClientClose);
                this._client.off('ready', this.handleClientReady);
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["decreaseMaxListeners"])(this._client, 3);
                this.removeAllListeners();
                this.status = 'closed';
            }
        }
    }
    async getRedisVersion() {
        if (this.skipVersionCheck) {
            return RedisConnection.minimumVersion;
        }
        const doc = await this._client.info();
        const redisPrefix = 'redis_version:';
        const maxMemoryPolicyPrefix = 'maxmemory_policy:';
        const lines = doc.split(/\r?\n/);
        let redisVersion;
        for(let i = 0; i < lines.length; i++){
            if (lines[i].indexOf(maxMemoryPolicyPrefix) === 0) {
                const maxMemoryPolicy = lines[i].substr(maxMemoryPolicyPrefix.length);
                if (maxMemoryPolicy !== 'noeviction') {
                    console.warn(`IMPORTANT! Eviction policy is ${maxMemoryPolicy}. It should be "noeviction"`);
                }
            }
            if (lines[i].indexOf(redisPrefix) === 0) {
                redisVersion = lines[i].substr(redisPrefix.length);
            }
        }
        return redisVersion;
    }
    get redisVersion() {
        return this.version;
    }
}
RedisConnection.minimumVersion = '5.0.0';
RedisConnection.recommendedMinimumVersion = '6.2.0'; //# sourceMappingURL=redis-connection.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/flow-producer.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "FlowProducer",
    ()=>FlowProducer
]);
var __TURBOPACK__imported__module__$5b$externals$5d2f$events__$5b$external$5d$__$28$events$2c$__cjs$29$__ = __turbopack_context__.i("[externals]/events [external] (events, cjs)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$uuid$2f$dist$2f$esm$2f$v4$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$export__default__as__v4$3e$__ = __turbopack_context__.i("[project]/node_modules/uuid/dist/esm/v4.js [app-route] (ecmascript) <export default as v4>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/utils/index.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$job$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/job.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$keys$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/queue-keys.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$redis$2d$connection$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/redis-connection.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/telemetry-attributes.js [app-route] (ecmascript)");
;
;
;
;
;
;
;
class FlowProducer extends __TURBOPACK__imported__module__$5b$externals$5d2f$events__$5b$external$5d$__$28$events$2c$__cjs$29$__["EventEmitter"] {
    constructor(opts = {
        connection: {}
    }, Connection = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$redis$2d$connection$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["RedisConnection"]){
        super();
        this.opts = opts;
        this.opts = Object.assign({
            prefix: 'bull'
        }, opts);
        this.connection = new Connection(opts.connection, {
            shared: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isRedisInstance"])(opts.connection),
            blocking: false,
            skipVersionCheck: opts.skipVersionCheck,
            skipWaitingForReady: opts.skipWaitingForReady
        });
        this.connection.on('error', (error)=>this.emit('error', error));
        this.connection.on('close', ()=>{
            if (!this.closing) {
                this.emit('ioredis:close');
            }
        });
        this.queueKeys = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$keys$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["QueueKeys"](opts.prefix);
        if (opts === null || opts === void 0 ? void 0 : opts.telemetry) {
            this.telemetry = opts.telemetry;
        }
    }
    emit(event, ...args) {
        return super.emit(event, ...args);
    }
    off(eventName, listener) {
        super.off(eventName, listener);
        return this;
    }
    on(event, listener) {
        super.on(event, listener);
        return this;
    }
    once(event, listener) {
        super.once(event, listener);
        return this;
    }
    /**
     * Returns a promise that resolves to a redis client. Normally used only by subclasses.
     */ get client() {
        return this.connection.client;
    }
    /**
     * Helper to easily extend Job class calls.
     */ get Job() {
        return __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$job$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Job"];
    }
    waitUntilReady() {
        return this.client;
    }
    /**
     * Adds a flow.
     *
     * This call would be atomic, either it fails and no jobs will
     * be added to the queues, or it succeeds and all jobs will be added.
     *
     * @param flow - an object with a tree-like structure where children jobs
     * will be processed before their parents.
     * @param opts - options that will be applied to the flow object.
     */ async add(flow, opts) {
        var _a;
        if (this.closing) {
            return;
        }
        const client = await this.connection.client;
        const multi = client.multi();
        const parentOpts = (_a = flow === null || flow === void 0 ? void 0 : flow.opts) === null || _a === void 0 ? void 0 : _a.parent;
        const parentKey = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getParentKey"])(parentOpts);
        const parentDependenciesKey = parentKey ? `${parentKey}:dependencies` : undefined;
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["trace"])(this.telemetry, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].PRODUCER, flow.queueName, 'addFlow', flow.queueName, async (span)=>{
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].FlowName]: flow.name
            });
            const jobsTree = await this.addNode({
                multi,
                node: flow,
                queuesOpts: opts === null || opts === void 0 ? void 0 : opts.queuesOptions,
                parent: {
                    parentOpts,
                    parentDependenciesKey
                }
            });
            await multi.exec();
            return jobsTree;
        });
    }
    /**
     * Get a flow.
     *
     * @param opts - an object with options for getting a JobNode.
     */ async getFlow(opts) {
        if (this.closing) {
            return;
        }
        const client = await this.connection.client;
        const updatedOpts = Object.assign({
            depth: 10,
            maxChildren: 20,
            prefix: this.opts.prefix
        }, opts);
        const jobsTree = this.getNode(client, updatedOpts);
        return jobsTree;
    }
    /**
     * Adds multiple flows.
     *
     * A flow is a tree-like structure of jobs that depend on each other.
     * Whenever the children of a given parent are completed, the parent
     * will be processed, being able to access the children's result data.
     *
     * All Jobs can be in different queues, either children or parents,
     * however this call would be atomic, either it fails and no jobs will
     * be added to the queues, or it succeeds and all jobs will be added.
     *
     * @param flows - an array of objects with a tree-like structure where children jobs
     * will be processed before their parents.
     */ async addBulk(flows) {
        if (this.closing) {
            return;
        }
        const client = await this.connection.client;
        const multi = client.multi();
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["trace"])(this.telemetry, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].PRODUCER, '', 'addBulkFlows', '', async (span)=>{
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].BulkCount]: flows.length,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].BulkNames]: flows.map((flow)=>flow.name).join(',')
            });
            const jobsTrees = await this.addNodes(multi, flows);
            await multi.exec();
            return jobsTrees;
        });
    }
    /**
     * Add a node (job) of a flow to the queue. This method will recursively
     * add all its children as well. Note that a given job can potentially be
     * a parent and a child job at the same time depending on where it is located
     * in the tree hierarchy.
     *
     * @param multi - ioredis ChainableCommander
     * @param node - the node representing a job to be added to some queue
     * @param parent - parent data sent to children to create the "links" to their parent
     * @returns
     */ async addNode({ multi, node, parent, queuesOpts }) {
        var _a, _b;
        const prefix = node.prefix || this.opts.prefix;
        const queue = this.queueFromNode(node, new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$keys$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["QueueKeys"](prefix), prefix);
        const queueOpts = queuesOpts && queuesOpts[node.queueName];
        const jobsOpts = (_a = queueOpts === null || queueOpts === void 0 ? void 0 : queueOpts.defaultJobOptions) !== null && _a !== void 0 ? _a : {};
        const jobId = ((_b = node.opts) === null || _b === void 0 ? void 0 : _b.jobId) || (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$uuid$2f$dist$2f$esm$2f$v4$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$export__default__as__v4$3e$__["v4"])();
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["trace"])(this.telemetry, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].PRODUCER, node.queueName, 'addNode', node.queueName, async (span, srcPropagationMedatada)=>{
            var _a, _b;
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobName]: node.name,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobId]: jobId
            });
            const opts = node.opts;
            let telemetry = opts === null || opts === void 0 ? void 0 : opts.telemetry;
            if (srcPropagationMedatada && opts) {
                const omitContext = (_a = opts.telemetry) === null || _a === void 0 ? void 0 : _a.omitContext;
                const telemetryMetadata = ((_b = opts.telemetry) === null || _b === void 0 ? void 0 : _b.metadata) || !omitContext && srcPropagationMedatada;
                if (telemetryMetadata || omitContext) {
                    telemetry = {
                        metadata: telemetryMetadata,
                        omitContext
                    };
                }
            }
            const job = new this.Job(queue, node.name, node.data, Object.assign(Object.assign(Object.assign({}, jobsOpts), opts), {
                parent: parent === null || parent === void 0 ? void 0 : parent.parentOpts,
                telemetry
            }), jobId);
            const parentKey = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getParentKey"])(parent === null || parent === void 0 ? void 0 : parent.parentOpts);
            if (node.children && node.children.length > 0) {
                // Create the parent job, it will be a job in status "waiting-children".
                const parentId = jobId;
                const queueKeysParent = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$keys$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["QueueKeys"](node.prefix || this.opts.prefix);
                await job.addJob(multi, {
                    parentDependenciesKey: parent === null || parent === void 0 ? void 0 : parent.parentDependenciesKey,
                    addToWaitingChildren: true,
                    parentKey
                });
                const parentDependenciesKey = `${queueKeysParent.toKey(node.queueName, parentId)}:dependencies`;
                const children = await this.addChildren({
                    multi,
                    nodes: node.children,
                    parent: {
                        parentOpts: {
                            id: parentId,
                            queue: queueKeysParent.getQueueQualifiedName(node.queueName)
                        },
                        parentDependenciesKey
                    },
                    queuesOpts
                });
                return {
                    job,
                    children
                };
            } else {
                await job.addJob(multi, {
                    parentDependenciesKey: parent === null || parent === void 0 ? void 0 : parent.parentDependenciesKey,
                    parentKey
                });
                return {
                    job
                };
            }
        });
    }
    /**
     * Adds nodes (jobs) of multiple flows to the queue. This method will recursively
     * add all its children as well. Note that a given job can potentially be
     * a parent and a child job at the same time depending on where it is located
     * in the tree hierarchy.
     *
     * @param multi - ioredis ChainableCommander
     * @param nodes - the nodes representing jobs to be added to some queue
     * @returns
     */ addNodes(multi, nodes) {
        return Promise.all(nodes.map((node)=>{
            var _a;
            const parentOpts = (_a = node === null || node === void 0 ? void 0 : node.opts) === null || _a === void 0 ? void 0 : _a.parent;
            const parentKey = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getParentKey"])(parentOpts);
            const parentDependenciesKey = parentKey ? `${parentKey}:dependencies` : undefined;
            return this.addNode({
                multi,
                node,
                parent: {
                    parentOpts,
                    parentDependenciesKey
                }
            });
        }));
    }
    async getNode(client, node) {
        const queue = this.queueFromNode(node, new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$keys$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["QueueKeys"](node.prefix), node.prefix);
        const job = await this.Job.fromId(queue, node.id);
        if (job) {
            const { processed = {}, unprocessed = [], failed = [], ignored = {} } = await job.getDependencies({
                failed: {
                    count: node.maxChildren
                },
                processed: {
                    count: node.maxChildren
                },
                unprocessed: {
                    count: node.maxChildren
                },
                ignored: {
                    count: node.maxChildren
                }
            });
            const processedKeys = Object.keys(processed);
            const ignoredKeys = Object.keys(ignored);
            const childrenCount = processedKeys.length + unprocessed.length + ignoredKeys.length + failed.length;
            const newDepth = node.depth - 1;
            if (childrenCount > 0 && newDepth) {
                const children = await this.getChildren(client, [
                    ...processedKeys,
                    ...unprocessed,
                    ...failed,
                    ...ignoredKeys
                ], newDepth, node.maxChildren);
                return {
                    job,
                    children
                };
            } else {
                return {
                    job
                };
            }
        }
    }
    addChildren({ multi, nodes, parent, queuesOpts }) {
        return Promise.all(nodes.map((node)=>this.addNode({
                multi,
                node,
                parent,
                queuesOpts
            })));
    }
    getChildren(client, childrenKeys, depth, maxChildren) {
        const getChild = (key)=>{
            const [prefix, queueName, id] = key.split(':');
            return this.getNode(client, {
                id,
                queueName,
                prefix,
                depth,
                maxChildren
            });
        };
        return Promise.all([
            ...childrenKeys.map(getChild)
        ]);
    }
    /**
     * Helper factory method that creates a queue-like object
     * required to create jobs in any queue.
     *
     * @param node -
     * @param queueKeys -
     * @returns
     */ queueFromNode(node, queueKeys, prefix) {
        return {
            client: this.connection.client,
            name: node.queueName,
            keys: queueKeys.getKeys(node.queueName),
            toKey: (type)=>queueKeys.toKey(node.queueName, type),
            opts: {
                prefix,
                connection: {}
            },
            qualifiedName: queueKeys.getQueueQualifiedName(node.queueName),
            closing: this.closing,
            waitUntilReady: async ()=>this.connection.client,
            removeListener: this.removeListener.bind(this),
            emit: this.emit.bind(this),
            on: this.on.bind(this),
            redisVersion: this.connection.redisVersion,
            trace: async ()=>{}
        };
    }
    /**
     *
     * Closes the connection and returns a promise that resolves when the connection is closed.
     */ async close() {
        if (!this.closing) {
            this.closing = this.connection.close();
        }
        await this.closing;
    }
    /**
     *
     * Force disconnects a connection.
     */ disconnect() {
        return this.connection.disconnect();
    }
} //# sourceMappingURL=flow-producer.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/queue-base.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "QueueBase",
    ()=>QueueBase
]);
var __TURBOPACK__imported__module__$5b$externals$5d2f$events__$5b$external$5d$__$28$events$2c$__cjs$29$__ = __turbopack_context__.i("[externals]/events [external] (events, cjs)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/utils/index.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$create$2d$scripts$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/utils/create-scripts.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$redis$2d$connection$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/redis-connection.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$job$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/job.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$keys$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/queue-keys.js [app-route] (ecmascript)");
;
;
;
;
;
;
class QueueBase extends __TURBOPACK__imported__module__$5b$externals$5d2f$events__$5b$external$5d$__$28$events$2c$__cjs$29$__["EventEmitter"] {
    /**
     *
     * @param name - The name of the queue.
     * @param opts - Options for the queue.
     * @param Connection - An optional "Connection" class used to instantiate a Connection. This is useful for
     * testing with mockups and/or extending the Connection class and passing an alternate implementation.
     */ constructor(name, opts = {
        connection: {}
    }, Connection = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$redis$2d$connection$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["RedisConnection"], hasBlockingConnection = false){
        super();
        this.name = name;
        this.opts = opts;
        this.closed = false;
        this.hasBlockingConnection = false;
        this.hasBlockingConnection = hasBlockingConnection;
        this.opts = Object.assign({
            prefix: 'bull'
        }, opts);
        if (!name) {
            throw new Error('Queue name must be provided');
        }
        if (name.includes(':')) {
            throw new Error('Queue name cannot contain :');
        }
        this.connection = new Connection(opts.connection, {
            shared: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isRedisInstance"])(opts.connection),
            blocking: hasBlockingConnection,
            skipVersionCheck: opts.skipVersionCheck,
            skipWaitingForReady: opts.skipWaitingForReady
        });
        this.connection.on('error', (error)=>this.emit('error', error));
        this.connection.on('close', ()=>{
            if (!this.closing) {
                this.emit('ioredis:close');
            }
        });
        const queueKeys = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$keys$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["QueueKeys"](opts.prefix);
        this.qualifiedName = queueKeys.getQueueQualifiedName(name);
        this.keys = queueKeys.getKeys(name);
        this.toKey = (type)=>queueKeys.toKey(name, type);
        this.createScripts();
    }
    /**
     * Returns a promise that resolves to a redis client. Normally used only by subclasses.
     */ get client() {
        return this.connection.client;
    }
    createScripts() {
        this.scripts = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$create$2d$scripts$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["createScripts"])(this);
    }
    /**
     * Returns the version of the Redis instance the client is connected to,
     */ get redisVersion() {
        return this.connection.redisVersion;
    }
    /**
     * Helper to easily extend Job class calls.
     */ get Job() {
        return __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$job$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Job"];
    }
    /**
     * Emits an event. Normally used by subclasses to emit events.
     *
     * @param event - The emitted event.
     * @param args -
     * @returns
     */ emit(event, ...args) {
        try {
            return super.emit(event, ...args);
        } catch (err) {
            try {
                return super.emit('error', err);
            } catch (err) {
                // We give up if the error event also throws an exception.
                console.error(err);
                return false;
            }
        }
    }
    waitUntilReady() {
        return this.client;
    }
    base64Name() {
        return Buffer.from(this.name).toString('base64');
    }
    clientName(suffix = '') {
        const queueNameBase64 = this.base64Name();
        return `${this.opts.prefix}:${queueNameBase64}${suffix}`;
    }
    /**
     *
     * Closes the connection and returns a promise that resolves when the connection is closed.
     */ async close() {
        if (!this.closing) {
            this.closing = this.connection.close();
        }
        await this.closing;
        this.closed = true;
    }
    /**
     *
     * Force disconnects a connection.
     */ disconnect() {
        return this.connection.disconnect();
    }
    async checkConnectionError(fn, delayInMs = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["DELAY_TIME_5"]) {
        try {
            return await fn();
        } catch (error) {
            if ((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isNotConnectionError"])(error)) {
                this.emit('error', error);
            }
            if (!this.closing && delayInMs) {
                await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["delay"])(delayInMs);
            } else {
                return;
            }
        }
    }
    /**
     * Wraps the code with telemetry and provides a span for configuration.
     *
     * @param spanKind - kind of the span: Producer, Consumer, Internal
     * @param operation - operation name (such as add, process, etc)
     * @param destination - destination name (normally the queue name)
     * @param callback - code to wrap with telemetry
     * @param srcPropagationMedatada -
     * @returns
     */ trace(spanKind, operation, destination, callback, srcPropagationMetadata) {
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["trace"])(this.opts.telemetry, spanKind, this.name, operation, destination, callback, srcPropagationMetadata);
    }
} //# sourceMappingURL=queue-base.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/job-scheduler.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "JobScheduler",
    ()=>JobScheduler,
    "defaultRepeatStrategy",
    ()=>defaultRepeatStrategy
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$tslib$2f$tslib$2e$es6$2e$mjs__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/tslib/tslib.es6.mjs [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$cron$2d$parser$2f$lib$2f$parser$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/cron-parser/lib/parser.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$job$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/job.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$base$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/queue-base.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/telemetry-attributes.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/utils/index.js [app-route] (ecmascript)");
;
;
;
;
;
;
class JobScheduler extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$base$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["QueueBase"] {
    constructor(name, opts, Connection){
        super(name, opts, Connection);
        this.repeatStrategy = opts.settings && opts.settings.repeatStrategy || defaultRepeatStrategy;
    }
    async upsertJobScheduler(jobSchedulerId, repeatOpts, jobName, jobData, opts, { override, producerId }) {
        const { every, limit, pattern, offset } = repeatOpts;
        if (pattern && every) {
            throw new Error('Both .pattern and .every options are defined for this repeatable job');
        }
        if (!pattern && !every) {
            throw new Error('Either .pattern or .every options must be defined for this repeatable job');
        }
        if (repeatOpts.immediately && repeatOpts.startDate) {
            throw new Error('Both .immediately and .startDate options are defined for this repeatable job');
        }
        if (repeatOpts.immediately && repeatOpts.every) {
            console.warn("Using option immediately with every does not affect the job's schedule. Job will run immediately anyway.");
        }
        // Check if we reached the limit of the repeatable job's iterations
        const iterationCount = repeatOpts.count ? repeatOpts.count + 1 : 1;
        if (typeof repeatOpts.limit !== 'undefined' && iterationCount > repeatOpts.limit) {
            return;
        }
        // Check if we reached the end date of the repeatable job
        let now = Date.now();
        const { endDate } = repeatOpts;
        if (endDate && now > new Date(endDate).getTime()) {
            return;
        }
        const prevMillis = opts.prevMillis || 0;
        now = prevMillis < now ? now : prevMillis;
        // Check if we have a start date for the repeatable job
        const { immediately } = repeatOpts, filteredRepeatOpts = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$tslib$2f$tslib$2e$es6$2e$mjs__$5b$app$2d$route$5d$__$28$ecmascript$29$__["__rest"])(repeatOpts, [
            "immediately"
        ]);
        let nextMillis;
        const newOffset = null;
        if (pattern) {
            nextMillis = await this.repeatStrategy(now, repeatOpts, jobName);
            if (nextMillis < now) {
                nextMillis = now;
            }
        }
        if (nextMillis || every) {
            return this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].PRODUCER, 'add', `${this.name}.${jobName}`, async (span, srcPropagationMedatada)=>{
                var _a, _b;
                let telemetry = opts.telemetry;
                if (srcPropagationMedatada) {
                    const omitContext = (_a = opts.telemetry) === null || _a === void 0 ? void 0 : _a.omitContext;
                    const telemetryMetadata = ((_b = opts.telemetry) === null || _b === void 0 ? void 0 : _b.metadata) || !omitContext && srcPropagationMedatada;
                    if (telemetryMetadata || omitContext) {
                        telemetry = {
                            metadata: telemetryMetadata,
                            omitContext
                        };
                    }
                }
                const mergedOpts = this.getNextJobOpts(nextMillis, jobSchedulerId, Object.assign(Object.assign({}, opts), {
                    repeat: filteredRepeatOpts,
                    telemetry
                }), iterationCount, newOffset);
                if (override) {
                    // Clamp nextMillis to now if it's in the past
                    if (nextMillis < now) {
                        nextMillis = now;
                    }
                    const [jobId, delay] = await this.scripts.addJobScheduler(jobSchedulerId, nextMillis, JSON.stringify(typeof jobData === 'undefined' ? {} : jobData), __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$job$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Job"].optsAsJSON(opts), {
                        name: jobName,
                        startDate: repeatOpts.startDate ? new Date(repeatOpts.startDate).getTime() : undefined,
                        endDate: endDate ? new Date(endDate).getTime() : undefined,
                        tz: repeatOpts.tz,
                        pattern,
                        every,
                        limit,
                        offset: newOffset
                    }, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$job$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Job"].optsAsJSON(mergedOpts), producerId);
                    // Ensure delay is a number (Dragonflydb may return it as a string)
                    const numericDelay = typeof delay === 'string' ? parseInt(delay, 10) : delay;
                    const job = new this.Job(this, jobName, jobData, Object.assign(Object.assign({}, mergedOpts), {
                        delay: numericDelay
                    }), jobId);
                    job.id = jobId;
                    span === null || span === void 0 ? void 0 : span.setAttributes({
                        [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobSchedulerId]: jobSchedulerId,
                        [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobId]: job.id
                    });
                    return job;
                } else {
                    const jobId = await this.scripts.updateJobSchedulerNextMillis(jobSchedulerId, nextMillis, JSON.stringify(typeof jobData === 'undefined' ? {} : jobData), __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$job$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Job"].optsAsJSON(mergedOpts), producerId);
                    if (jobId) {
                        const job = new this.Job(this, jobName, jobData, mergedOpts, jobId);
                        job.id = jobId;
                        span === null || span === void 0 ? void 0 : span.setAttributes({
                            [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobSchedulerId]: jobSchedulerId,
                            [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobId]: job.id
                        });
                        return job;
                    }
                }
            });
        }
    }
    getNextJobOpts(nextMillis, jobSchedulerId, opts, currentCount, offset) {
        var _a, _b;
        //
        // Generate unique job id for this iteration.
        //
        const jobId = this.getSchedulerNextJobId({
            jobSchedulerId,
            nextMillis
        });
        const now = Date.now();
        const delay = nextMillis + offset - now;
        const mergedOpts = Object.assign(Object.assign({}, opts), {
            jobId,
            delay: delay < 0 ? 0 : delay,
            timestamp: now,
            prevMillis: nextMillis,
            repeatJobKey: jobSchedulerId
        });
        mergedOpts.repeat = Object.assign(Object.assign({}, opts.repeat), {
            offset,
            count: currentCount,
            startDate: ((_a = opts.repeat) === null || _a === void 0 ? void 0 : _a.startDate) ? new Date(opts.repeat.startDate).getTime() : undefined,
            endDate: ((_b = opts.repeat) === null || _b === void 0 ? void 0 : _b.endDate) ? new Date(opts.repeat.endDate).getTime() : undefined
        });
        return mergedOpts;
    }
    async removeJobScheduler(jobSchedulerId) {
        return this.scripts.removeJobScheduler(jobSchedulerId);
    }
    async getSchedulerData(client, key, next) {
        const jobData = await client.hgetall(this.toKey('repeat:' + key));
        return this.transformSchedulerData(key, jobData, next);
    }
    transformSchedulerData(key, jobData, next) {
        if (jobData) {
            const jobSchedulerData = {
                key,
                name: jobData.name,
                next
            };
            if (jobData.ic) {
                jobSchedulerData.iterationCount = parseInt(jobData.ic);
            }
            if (jobData.limit) {
                jobSchedulerData.limit = parseInt(jobData.limit);
            }
            if (jobData.startDate) {
                jobSchedulerData.startDate = parseInt(jobData.startDate);
            }
            if (jobData.endDate) {
                jobSchedulerData.endDate = parseInt(jobData.endDate);
            }
            if (jobData.tz) {
                jobSchedulerData.tz = jobData.tz;
            }
            if (jobData.pattern) {
                jobSchedulerData.pattern = jobData.pattern;
            }
            if (jobData.every) {
                jobSchedulerData.every = parseInt(jobData.every);
            }
            if (jobData.offset) {
                jobSchedulerData.offset = parseInt(jobData.offset);
            }
            if (jobData.data || jobData.opts) {
                jobSchedulerData.template = this.getTemplateFromJSON(jobData.data, jobData.opts);
            }
            return jobSchedulerData;
        }
        // TODO: remove this check and keyToData as it is here only to support legacy code
        if (key.includes(':')) {
            return this.keyToData(key, next);
        }
    }
    keyToData(key, next) {
        const data = key.split(':');
        const pattern = data.slice(4).join(':') || null;
        return {
            key,
            name: data[0],
            id: data[1] || null,
            endDate: parseInt(data[2]) || null,
            tz: data[3] || null,
            pattern,
            next
        };
    }
    async getScheduler(id) {
        const [rawJobData, next] = await this.scripts.getJobScheduler(id);
        return this.transformSchedulerData(id, rawJobData ? (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["array2obj"])(rawJobData) : null, next ? parseInt(next) : null);
    }
    getTemplateFromJSON(rawData, rawOpts) {
        const template = {};
        if (rawData) {
            template.data = JSON.parse(rawData);
        }
        if (rawOpts) {
            template.opts = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$job$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Job"].optsFromJSON(rawOpts);
        }
        return template;
    }
    async getJobSchedulers(start = 0, end = -1, asc = false) {
        const client = await this.client;
        const jobSchedulersKey = this.keys.repeat;
        const result = asc ? await client.zrange(jobSchedulersKey, start, end, 'WITHSCORES') : await client.zrevrange(jobSchedulersKey, start, end, 'WITHSCORES');
        const jobs = [];
        for(let i = 0; i < result.length; i += 2){
            jobs.push(this.getSchedulerData(client, result[i], parseInt(result[i + 1])));
        }
        return Promise.all(jobs);
    }
    async getSchedulersCount() {
        const jobSchedulersKey = this.keys.repeat;
        const client = await this.client;
        return client.zcard(jobSchedulersKey);
    }
    getSchedulerNextJobId({ nextMillis, jobSchedulerId }) {
        return `repeat:${jobSchedulerId}:${nextMillis}`;
    }
}
const defaultRepeatStrategy = (millis, opts)=>{
    const { pattern } = opts;
    const dateFromMillis = new Date(millis);
    const startDate = opts.startDate && new Date(opts.startDate);
    const currentDate = startDate > dateFromMillis ? startDate : dateFromMillis;
    const interval = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$cron$2d$parser$2f$lib$2f$parser$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["parseExpression"])(pattern, Object.assign(Object.assign({}, opts), {
        currentDate
    }));
    try {
        if (opts.immediately) {
            return new Date().getTime();
        } else {
            return interval.next().getTime();
        }
    } catch (e) {
    // Ignore error
    }
}; //# sourceMappingURL=job-scheduler.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/lock-manager.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "LockManager",
    ()=>LockManager
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$node$2d$abort$2d$controller$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/node-abort-controller/index.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/telemetry-attributes.js [app-route] (ecmascript)");
;
;
class LockManager {
    constructor(worker, opts){
        this.worker = worker;
        this.opts = opts;
        // Maps job ids with their tokens, timestamps, and abort controllers
        this.trackedJobs = new Map();
        this.closed = false;
    }
    /**
     * Starts the lock manager timers for lock renewal.
     */ start() {
        if (this.closed) {
            return;
        }
        // Start lock renewal timer if not disabled
        if (this.opts.lockRenewTime > 0) {
            this.startLockExtenderTimer();
        }
    }
    async extendLocks(jobIds) {
        await this.worker.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'extendLocks', this.worker.name, async (span)=>{
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerId]: this.opts.workerId,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerName]: this.opts.workerName,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerJobsToExtendLocks]: jobIds
            });
            try {
                const jobTokens = jobIds.map((id)=>{
                    var _a;
                    return ((_a = this.trackedJobs.get(id)) === null || _a === void 0 ? void 0 : _a.token) || '';
                });
                const erroredJobIds = await this.worker.extendJobLocks(jobIds, jobTokens, this.opts.lockDuration);
                if (erroredJobIds.length > 0) {
                    this.worker.emit('lockRenewalFailed', erroredJobIds);
                    for (const jobId of erroredJobIds){
                        this.worker.emit('error', new Error(`could not renew lock for job ${jobId}`));
                    }
                }
                const succeededJobIds = jobIds.filter((id)=>!erroredJobIds.includes(id));
                if (succeededJobIds.length > 0) {
                    this.worker.emit('locksRenewed', {
                        count: succeededJobIds.length,
                        jobIds: succeededJobIds
                    });
                }
            } catch (err) {
                this.worker.emit('error', err);
            }
        });
    }
    startLockExtenderTimer() {
        clearTimeout(this.lockRenewalTimer);
        if (!this.closed) {
            this.lockRenewalTimer = setTimeout(async ()=>{
                // Get all the jobs whose locks expire in less than 1/2 of the lockRenewTime
                const now = Date.now();
                const jobsToExtend = [];
                for (const jobId of this.trackedJobs.keys()){
                    const tracked = this.trackedJobs.get(jobId);
                    const { ts, token, abortController } = tracked;
                    if (!ts) {
                        this.trackedJobs.set(jobId, {
                            token,
                            ts: now,
                            abortController
                        });
                        continue;
                    }
                    if (ts + this.opts.lockRenewTime / 2 < now) {
                        this.trackedJobs.set(jobId, {
                            token,
                            ts: now,
                            abortController
                        });
                        jobsToExtend.push(jobId);
                    }
                }
                if (jobsToExtend.length) {
                    await this.extendLocks(jobsToExtend);
                }
                this.startLockExtenderTimer();
            }, this.opts.lockRenewTime / 2);
        }
    }
    /**
     * Stops the lock manager and clears all timers.
     */ async close() {
        if (this.closed) {
            return;
        }
        this.closed = true;
        if (this.lockRenewalTimer) {
            clearTimeout(this.lockRenewalTimer);
            this.lockRenewalTimer = undefined;
        }
        this.trackedJobs.clear();
    }
    /**
     * Adds a job to be tracked for lock renewal.
     * Returns an AbortController if shouldCreateController is true, undefined otherwise.
     */ trackJob(jobId, token, ts, shouldCreateController = false) {
        const abortController = shouldCreateController ? new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$node$2d$abort$2d$controller$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AbortController"]() : undefined;
        if (!this.closed && jobId) {
            this.trackedJobs.set(jobId, {
                token,
                ts,
                abortController
            });
        }
        return abortController;
    }
    /**
     * Removes a job from lock renewal tracking.
     */ untrackJob(jobId) {
        this.trackedJobs.delete(jobId);
    }
    /**
     * Gets the number of jobs currently being tracked.
     */ getActiveJobCount() {
        return this.trackedJobs.size;
    }
    /**
     * Checks if the lock manager is running.
     */ isRunning() {
        return !this.closed && this.lockRenewalTimer !== undefined;
    }
    /**
     * Cancels a specific job by aborting its signal.
     * @param jobId - The ID of the job to cancel
     * @param reason - Optional reason for the cancellation
     * @returns true if the job was found and cancelled, false otherwise
     */ cancelJob(jobId, reason) {
        const tracked = this.trackedJobs.get(jobId);
        if (tracked === null || tracked === void 0 ? void 0 : tracked.abortController) {
            tracked.abortController.abort(reason);
            return true;
        }
        return false;
    }
    /**
     * Cancels all tracked jobs by aborting their signals.
     * @param reason - Optional reason for the cancellation
     */ cancelAllJobs(reason) {
        for (const tracked of this.trackedJobs.values()){
            if (tracked.abortController) {
                tracked.abortController.abort(reason);
            }
        }
    }
    /**
     * Gets a list of all tracked job IDs.
     * @returns Array of job IDs currently being tracked
     */ getTrackedJobIds() {
        return Array.from(this.trackedJobs.keys());
    }
} //# sourceMappingURL=lock-manager.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/queue-events.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "QueueEvents",
    ()=>QueueEvents
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$tslib$2f$tslib$2e$es6$2e$mjs__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/tslib/tslib.es6.mjs [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/utils/index.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$base$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/queue-base.js [app-route] (ecmascript)");
;
;
;
class QueueEvents extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$base$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["QueueBase"] {
    constructor(name, _a = {
        connection: {}
    }, Connection){
        var { connection, autorun = true } = _a, opts = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$tslib$2f$tslib$2e$es6$2e$mjs__$5b$app$2d$route$5d$__$28$ecmascript$29$__["__rest"])(_a, [
            "connection",
            "autorun"
        ]);
        super(name, Object.assign(Object.assign({}, opts), {
            connection: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isRedisInstance"])(connection) ? connection.duplicate() : connection
        }), Connection, true);
        this.running = false;
        this.blocking = false;
        this.opts = Object.assign({
            blockingTimeout: 10000
        }, this.opts);
        if (autorun) {
            this.run().catch((error)=>this.emit('error', error));
        }
    }
    emit(event, ...args) {
        return super.emit(event, ...args);
    }
    off(eventName, listener) {
        super.off(eventName, listener);
        return this;
    }
    on(event, listener) {
        super.on(event, listener);
        return this;
    }
    once(event, listener) {
        super.once(event, listener);
        return this;
    }
    /**
     * Manually starts running the event consumming loop. This shall be used if you do not
     * use the default "autorun" option on the constructor.
     */ async run() {
        if (!this.running) {
            try {
                this.running = true;
                const client = await this.client;
                // TODO: Planed for deprecation as it has no really a use case
                try {
                    await client.client('SETNAME', this.clientName(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["QUEUE_EVENT_SUFFIX"]));
                } catch (err) {
                    if (!__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["clientCommandMessageReg"].test(err.message)) {
                        throw err;
                    }
                }
                await this.consumeEvents(client);
            } catch (error) {
                this.running = false;
                throw error;
            }
        } else {
            throw new Error('Queue Events is already running.');
        }
    }
    async consumeEvents(client) {
        const opts = this.opts;
        const key = this.keys.events;
        let id = opts.lastEventId || '$';
        while(!this.closing){
            this.blocking = true;
            // Cast to actual return type, see: https://github.com/DefinitelyTyped/DefinitelyTyped/issues/44301
            const data = await this.checkConnectionError(()=>client.xread('BLOCK', opts.blockingTimeout, 'STREAMS', key, id));
            this.blocking = false;
            if (data) {
                const stream = data[0];
                const events = stream[1];
                for(let i = 0; i < events.length; i++){
                    id = events[i][0];
                    const args = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["array2obj"])(events[i][1]);
                    //
                    // TODO: we may need to have a separate xtream for progress data
                    // to avoid this hack.
                    switch(args.event){
                        case 'progress':
                            args.data = JSON.parse(args.data);
                            break;
                        case 'completed':
                            args.returnvalue = JSON.parse(args.returnvalue);
                            break;
                    }
                    const { event } = args, restArgs = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$tslib$2f$tslib$2e$es6$2e$mjs__$5b$app$2d$route$5d$__$28$ecmascript$29$__["__rest"])(args, [
                        "event"
                    ]);
                    if (event === 'drained') {
                        this.emit(event, id);
                    } else {
                        this.emit(event, restArgs, id);
                        if (restArgs.jobId) {
                            this.emit(`${event}:${restArgs.jobId}`, restArgs, id);
                        }
                    }
                }
            }
        }
    }
    /**
     * Stops consuming events and close the underlying Redis connection if necessary.
     *
     * @returns
     */ async close() {
        if (!this.closing) {
            this.closing = (async ()=>{
                try {
                    // As the connection has been wrongly markes as "shared" by QueueBase,
                    // we need to forcibly close it here. We should fix QueueBase to avoid this in the future.
                    const client = await this.client;
                    client.disconnect();
                    await this.connection.close(this.blocking);
                } finally{
                    this.closed = true;
                }
            })();
        }
        return this.closing;
    }
} //# sourceMappingURL=queue-events.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/queue-events-producer.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "QueueEventsProducer",
    ()=>QueueEventsProducer
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$tslib$2f$tslib$2e$es6$2e$mjs__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/tslib/tslib.es6.mjs [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$base$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/queue-base.js [app-route] (ecmascript)");
;
;
class QueueEventsProducer extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$base$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["QueueBase"] {
    constructor(name, opts = {
        connection: {}
    }, Connection){
        super(name, Object.assign({
            blockingConnection: false
        }, opts), Connection);
        this.opts = opts;
    }
    /**
     * Publish custom event to be processed in QueueEvents.
     * @param argsObj - Event payload
     * @param maxEvents - Max quantity of events to be saved
     */ async publishEvent(argsObj, maxEvents = 1000) {
        const client = await this.client;
        const key = this.keys.events;
        const { eventName } = argsObj, restArgs = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$tslib$2f$tslib$2e$es6$2e$mjs__$5b$app$2d$route$5d$__$28$ecmascript$29$__["__rest"])(argsObj, [
            "eventName"
        ]);
        const args = [
            'MAXLEN',
            '~',
            maxEvents,
            '*',
            'event',
            eventName
        ];
        for (const [key, value] of Object.entries(restArgs)){
            args.push(key, value);
        }
        await client.xadd(key, ...args);
    }
    /**
     * Closes the connection and returns a promise that resolves when the connection is closed.
     */ async close() {
        if (!this.closing) {
            this.closing = this.connection.close();
        }
        await this.closing;
    }
} //# sourceMappingURL=queue-events-producer.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/queue-getters.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*eslint-env node */ __turbopack_context__.s([
    "QueueGetters",
    ()=>QueueGetters
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$tslib$2f$tslib$2e$es6$2e$mjs__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/tslib/tslib.es6.mjs [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$base$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/queue-base.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/utils/index.js [app-route] (ecmascript)");
'use strict';
;
;
;
class QueueGetters extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$base$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["QueueBase"] {
    getJob(jobId) {
        return this.Job.fromId(this, jobId);
    }
    commandByType(types, count, callback) {
        return types.map((type)=>{
            type = type === 'waiting' ? 'wait' : type; // alias
            const key = this.toKey(type);
            switch(type){
                case 'completed':
                case 'failed':
                case 'delayed':
                case 'prioritized':
                case 'repeat':
                case 'waiting-children':
                    return callback(key, count ? 'zcard' : 'zrange');
                case 'active':
                case 'wait':
                case 'paused':
                    return callback(key, count ? 'llen' : 'lrange');
            }
        });
    }
    sanitizeJobTypes(types) {
        const currentTypes = typeof types === 'string' ? [
            types
        ] : types;
        if (Array.isArray(currentTypes) && currentTypes.length > 0) {
            const sanitizedTypes = [
                ...currentTypes
            ];
            if (sanitizedTypes.indexOf('waiting') !== -1) {
                sanitizedTypes.push('paused');
            }
            return [
                ...new Set(sanitizedTypes)
            ];
        }
        return [
            'active',
            'completed',
            'delayed',
            'failed',
            'paused',
            'prioritized',
            'waiting',
            'waiting-children'
        ];
    }
    /**
      Returns the number of jobs waiting to be processed. This includes jobs that are
      "waiting" or "delayed" or "prioritized" or "waiting-children".
    */ async count() {
        const count = await this.getJobCountByTypes('waiting', 'paused', 'delayed', 'prioritized', 'waiting-children');
        return count;
    }
    /**
     * Returns the time to live for a rate limited key in milliseconds.
     * @param maxJobs - max jobs to be considered in rate limit state. If not passed
     * it will return the remaining ttl without considering if max jobs is excedeed.
     * @returns -2 if the key does not exist.
     * -1 if the key exists but has no associated expire.
     * @see {@link https://redis.io/commands/pttl/}
     */ async getRateLimitTtl(maxJobs) {
        return this.scripts.getRateLimitTtl(maxJobs);
    }
    /**
     * Get jobId that starts debounced state.
     * @deprecated use getDeduplicationJobId method
     *
     * @param id - debounce identifier
     */ async getDebounceJobId(id) {
        const client = await this.client;
        return client.get(`${this.keys.de}:${id}`);
    }
    /**
     * Get jobId from deduplicated state.
     *
     * @param id - deduplication identifier
     */ async getDeduplicationJobId(id) {
        const client = await this.client;
        return client.get(`${this.keys.de}:${id}`);
    }
    /**
     * Get global concurrency value.
     * Returns null in case no value is set.
     */ async getGlobalConcurrency() {
        const client = await this.client;
        const concurrency = await client.hget(this.keys.meta, 'concurrency');
        if (concurrency) {
            return Number(concurrency);
        }
        return null;
    }
    /**
     * Get global rate limit values.
     * Returns null in case no value is set.
     */ async getGlobalRateLimit() {
        const client = await this.client;
        const [max, duration] = await client.hmget(this.keys.meta, 'max', 'duration');
        if (max && duration) {
            return {
                max: Number(max),
                duration: Number(duration)
            };
        }
        return null;
    }
    /**
     * Job counts by type
     *
     * Queue#getJobCountByTypes('completed') =\> completed count
     * Queue#getJobCountByTypes('completed,failed') =\> completed + failed count
     * Queue#getJobCountByTypes('completed', 'failed') =\> completed + failed count
     * Queue#getJobCountByTypes('completed', 'waiting', 'failed') =\> completed + waiting + failed count
     */ async getJobCountByTypes(...types) {
        const result = await this.getJobCounts(...types);
        return Object.values(result).reduce((sum, count)=>sum + count, 0);
    }
    /**
     * Returns the job counts for each type specified or every list/set in the queue by default.
     *
     * @returns An object, key (type) and value (count)
     */ async getJobCounts(...types) {
        const currentTypes = this.sanitizeJobTypes(types);
        const responses = await this.scripts.getCounts(currentTypes);
        const counts = {};
        responses.forEach((res, index)=>{
            counts[currentTypes[index]] = res || 0;
        });
        return counts;
    }
    /**
     * Get current job state.
     *
     * @param jobId - job identifier.
     * @returns Returns one of these values:
     * 'completed', 'failed', 'delayed', 'active', 'waiting', 'waiting-children', 'unknown'.
     */ getJobState(jobId) {
        return this.scripts.getState(jobId);
    }
    /**
     * Get global queue configuration.
     *
     * @returns Returns the global queue configuration.
     */ async getMeta() {
        const client = await this.client;
        const config = await client.hgetall(this.keys.meta);
        const { concurrency, max, duration, paused, 'opts.maxLenEvents': maxLenEvents } = config, rest = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$tslib$2f$tslib$2e$es6$2e$mjs__$5b$app$2d$route$5d$__$28$ecmascript$29$__["__rest"])(config, [
            "concurrency",
            "max",
            "duration",
            "paused",
            'opts.maxLenEvents'
        ]);
        const parsedConfig = rest;
        if (concurrency) {
            parsedConfig['concurrency'] = Number(concurrency);
        }
        if (maxLenEvents) {
            parsedConfig['maxLenEvents'] = Number(maxLenEvents);
        }
        if (max) {
            parsedConfig['max'] = Number(max);
        }
        if (duration) {
            parsedConfig['duration'] = Number(duration);
        }
        parsedConfig['paused'] = paused === '1';
        return parsedConfig;
    }
    /**
     * @returns Returns the number of jobs in completed status.
     */ getCompletedCount() {
        return this.getJobCountByTypes('completed');
    }
    /**
     * Returns the number of jobs in failed status.
     */ getFailedCount() {
        return this.getJobCountByTypes('failed');
    }
    /**
     * Returns the number of jobs in delayed status.
     */ getDelayedCount() {
        return this.getJobCountByTypes('delayed');
    }
    /**
     * Returns the number of jobs in active status.
     */ getActiveCount() {
        return this.getJobCountByTypes('active');
    }
    /**
     * Returns the number of jobs in prioritized status.
     */ getPrioritizedCount() {
        return this.getJobCountByTypes('prioritized');
    }
    /**
     * Returns the number of jobs per priority.
     */ async getCountsPerPriority(priorities) {
        const uniquePriorities = [
            ...new Set(priorities)
        ];
        const responses = await this.scripts.getCountsPerPriority(uniquePriorities);
        const counts = {};
        responses.forEach((res, index)=>{
            counts[`${uniquePriorities[index]}`] = res || 0;
        });
        return counts;
    }
    /**
     * Returns the number of jobs in waiting or paused statuses.
     */ getWaitingCount() {
        return this.getJobCountByTypes('waiting');
    }
    /**
     * Returns the number of jobs in waiting-children status.
     */ getWaitingChildrenCount() {
        return this.getJobCountByTypes('waiting-children');
    }
    /**
     * Returns the jobs that are in the "waiting" status.
     * @param start - zero based index from where to start returning jobs.
     * @param end - zero based index where to stop returning jobs.
     */ getWaiting(start = 0, end = -1) {
        return this.getJobs([
            'waiting'
        ], start, end, true);
    }
    /**
     * Returns the jobs that are in the "waiting-children" status.
     * I.E. parent jobs that have at least one child that has not completed yet.
     * @param start - zero based index from where to start returning jobs.
     * @param end - zero based index where to stop returning jobs.
     */ getWaitingChildren(start = 0, end = -1) {
        return this.getJobs([
            'waiting-children'
        ], start, end, true);
    }
    /**
     * Returns the jobs that are in the "active" status.
     * @param start - zero based index from where to start returning jobs.
     * @param end - zero based index where to stop returning jobs.
     */ getActive(start = 0, end = -1) {
        return this.getJobs([
            'active'
        ], start, end, true);
    }
    /**
     * Returns the jobs that are in the "delayed" status.
     * @param start - zero based index from where to start returning jobs.
     * @param end - zero based index where to stop returning jobs.
     */ getDelayed(start = 0, end = -1) {
        return this.getJobs([
            'delayed'
        ], start, end, true);
    }
    /**
     * Returns the jobs that are in the "prioritized" status.
     * @param start - zero based index from where to start returning jobs.
     * @param end - zero based index where to stop returning jobs.
     */ getPrioritized(start = 0, end = -1) {
        return this.getJobs([
            'prioritized'
        ], start, end, true);
    }
    /**
     * Returns the jobs that are in the "completed" status.
     * @param start - zero based index from where to start returning jobs.
     * @param end - zero based index where to stop returning jobs.
     */ getCompleted(start = 0, end = -1) {
        return this.getJobs([
            'completed'
        ], start, end, false);
    }
    /**
     * Returns the jobs that are in the "failed" status.
     * @param start - zero based index from where to start returning jobs.
     * @param end - zero based index where to stop returning jobs.
     */ getFailed(start = 0, end = -1) {
        return this.getJobs([
            'failed'
        ], start, end, false);
    }
    /**
     * Returns the qualified job ids and the raw job data (if available) of the
     * children jobs of the given parent job.
     * It is possible to get either the already processed children, in this case
     * an array of qualified job ids and their result values will be returned,
     * or the pending children, in this case an array of qualified job ids will
     * be returned.
     * A qualified job id is a string representing the job id in a given queue,
     * for example: "bull:myqueue:jobid".
     *
     * @param parentId - The id of the parent job
     * @param type - "processed" | "pending"
     * @param opts - Options for the query.
     *
     * @returns an object with the following shape:
     * `{ items: { id: string, v?: any, err?: string } [], jobs: JobJsonRaw[], total: number}`
     */ async getDependencies(parentId, type, start, end) {
        const key = this.toKey(type == 'processed' ? `${parentId}:processed` : `${parentId}:dependencies`);
        const { items, total, jobs } = await this.scripts.paginate(key, {
            start,
            end,
            fetchJobs: true
        });
        return {
            items,
            jobs,
            total
        };
    }
    async getRanges(types, start = 0, end = 1, asc = false) {
        const multiCommands = [];
        this.commandByType(types, false, (key, command)=>{
            switch(command){
                case 'lrange':
                    multiCommands.push('lrange');
                    break;
                case 'zrange':
                    multiCommands.push('zrange');
                    break;
            }
        });
        const responses = await this.scripts.getRanges(types, start, end, asc);
        let results = [];
        responses.forEach((response, index)=>{
            const result = response || [];
            if (asc && multiCommands[index] === 'lrange') {
                results = results.concat(result.reverse());
            } else {
                results = results.concat(result);
            }
        });
        return [
            ...new Set(results)
        ];
    }
    /**
     * Returns the jobs that are on the given statuses (note that JobType is synonym for job status)
     * @param types - the statuses of the jobs to return.
     * @param start - zero based index from where to start returning jobs.
     * @param end - zero based index where to stop returning jobs.
     * @param asc - if true, the jobs will be returned in ascending order.
     */ async getJobs(types, start = 0, end = -1, asc = false) {
        const currentTypes = this.sanitizeJobTypes(types);
        const jobIds = await this.getRanges(currentTypes, start, end, asc);
        return Promise.all(jobIds.map((jobId)=>this.Job.fromId(this, jobId)));
    }
    /**
     * Returns the logs for a given Job.
     * @param jobId - the id of the job to get the logs for.
     * @param start - zero based index from where to start returning jobs.
     * @param end - zero based index where to stop returning jobs.
     * @param asc - if true, the jobs will be returned in ascending order.
     */ async getJobLogs(jobId, start = 0, end = -1, asc = true) {
        const client = await this.client;
        const multi = client.multi();
        const logsKey = this.toKey(jobId + ':logs');
        if (asc) {
            multi.lrange(logsKey, start, end);
        } else {
            multi.lrange(logsKey, -(end + 1), -(start + 1));
        }
        multi.llen(logsKey);
        const result = await multi.exec();
        if (!asc) {
            result[0][1].reverse();
        }
        return {
            logs: result[0][1],
            count: result[1][1]
        };
    }
    async baseGetClients(matcher) {
        const client = await this.client;
        try {
            const clients = await client.client('LIST');
            const list = this.parseClientList(clients, matcher);
            return list;
        } catch (err) {
            if (!__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["clientCommandMessageReg"].test(err.message)) {
                throw err;
            }
            return [
                {
                    name: 'GCP does not support client list'
                }
            ];
        }
    }
    /**
     * Get the worker list related to the queue. i.e. all the known
     * workers that are available to process jobs for this queue.
     * Note: GCP does not support SETNAME, so this call will not work
     *
     * @returns - Returns an array with workers info.
     */ getWorkers() {
        const unnamedWorkerClientName = `${this.clientName()}`;
        const namedWorkerClientName = `${this.clientName()}:w:`;
        const matcher = (name)=>name && (name === unnamedWorkerClientName || name.startsWith(namedWorkerClientName));
        return this.baseGetClients(matcher);
    }
    /**
     * Returns the current count of workers for the queue.
     *
     * getWorkersCount(): Promise<number>
     *
     */ async getWorkersCount() {
        const workers = await this.getWorkers();
        return workers.length;
    }
    /**
     * Get queue events list related to the queue.
     * Note: GCP does not support SETNAME, so this call will not work
     *
     * @deprecated do not use this method, it will be removed in the future.
     *
     * @returns - Returns an array with queue events info.
     */ async getQueueEvents() {
        const clientName = `${this.clientName()}${__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["QUEUE_EVENT_SUFFIX"]}`;
        return this.baseGetClients((name)=>name === clientName);
    }
    /**
     * Get queue metrics related to the queue.
     *
     * This method returns the gathered metrics for the queue.
     * The metrics are represented as an array of job counts
     * per unit of time (1 minute).
     *
     * @param start - Start point of the metrics, where 0
     * is the newest point to be returned.
     * @param end - End point of the metrics, where -1 is the
     * oldest point to be returned.
     *
     * @returns - Returns an object with queue metrics.
     */ async getMetrics(type, start = 0, end = -1) {
        const [meta, data, count] = await this.scripts.getMetrics(type, start, end);
        return {
            meta: {
                count: parseInt(meta[0] || '0', 10),
                prevTS: parseInt(meta[1] || '0', 10),
                prevCount: parseInt(meta[2] || '0', 10)
            },
            data: data.map((point)=>+point || 0),
            count
        };
    }
    parseClientList(list, matcher) {
        const lines = list.split(/\r?\n/);
        const clients = [];
        lines.forEach((line)=>{
            const client = {};
            const keyValues = line.split(' ');
            keyValues.forEach(function(keyValue) {
                const index = keyValue.indexOf('=');
                const key = keyValue.substring(0, index);
                const value = keyValue.substring(index + 1);
                client[key] = value;
            });
            const name = client['name'];
            if (matcher(name)) {
                client['name'] = this.name;
                client['rawname'] = name;
                clients.push(client);
            }
        });
        return clients;
    }
    /**
     * Export the metrics for the queue in the Prometheus format.
     * Automatically exports all the counts returned by getJobCounts().
     *
     * @returns - Returns a string with the metrics in the Prometheus format.
     *
     * @see {@link https://prometheus.io/docs/instrumenting/exposition_formats/}
     *
     **/ async exportPrometheusMetrics(globalVariables) {
        const counts = await this.getJobCounts();
        const metrics = [];
        // Match the test's expected HELP text
        metrics.push('# HELP bullmq_job_count Number of jobs in the queue by state');
        metrics.push('# TYPE bullmq_job_count gauge');
        const variables = !globalVariables ? '' : Object.keys(globalVariables).reduce((acc, curr)=>`${acc}, ${curr}="${globalVariables[curr]}"`, '');
        for (const [state, count] of Object.entries(counts)){
            metrics.push(`bullmq_job_count{queue="${this.name}", state="${state}"${variables}} ${count}`);
        }
        return metrics.join('\n');
    }
} //# sourceMappingURL=queue-getters.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/repeat.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "Repeat",
    ()=>Repeat,
    "getNextMillis",
    ()=>getNextMillis
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$tslib$2f$tslib$2e$es6$2e$mjs__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/tslib/tslib.es6.mjs [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$cron$2d$parser$2f$lib$2f$parser$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/cron-parser/lib/parser.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$externals$5d2f$crypto__$5b$external$5d$__$28$crypto$2c$__cjs$29$__ = __turbopack_context__.i("[externals]/crypto [external] (crypto, cjs)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$base$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/queue-base.js [app-route] (ecmascript)");
;
;
;
;
class Repeat extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$base$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["QueueBase"] {
    constructor(name, opts, Connection){
        super(name, opts, Connection);
        this.repeatStrategy = opts.settings && opts.settings.repeatStrategy || getNextMillis;
        this.repeatKeyHashAlgorithm = opts.settings && opts.settings.repeatKeyHashAlgorithm || 'md5';
    }
    async updateRepeatableJob(name, data, opts, { override }) {
        var _a, _b;
        // Backwards compatibility for repeatable jobs for versions <= 3.0.0
        const repeatOpts = Object.assign({}, opts.repeat);
        (_a = repeatOpts.pattern) !== null && _a !== void 0 ? _a : repeatOpts.pattern = repeatOpts.cron;
        delete repeatOpts.cron;
        // Check if we reached the limit of the repeatable job's iterations
        const iterationCount = repeatOpts.count ? repeatOpts.count + 1 : 1;
        if (typeof repeatOpts.limit !== 'undefined' && iterationCount > repeatOpts.limit) {
            return;
        }
        // Check if we reached the end date of the repeatable job
        let now = Date.now();
        const { endDate } = repeatOpts;
        if (endDate && now > new Date(endDate).getTime()) {
            return;
        }
        const prevMillis = opts.prevMillis || 0;
        now = prevMillis < now ? now : prevMillis;
        const nextMillis = await this.repeatStrategy(now, repeatOpts, name);
        const { every, pattern } = repeatOpts;
        const hasImmediately = Boolean((every || pattern) && repeatOpts.immediately);
        const offset = hasImmediately && every ? now - nextMillis : undefined;
        if (nextMillis) {
            // We store the undecorated opts.jobId into the repeat options
            if (!prevMillis && opts.jobId) {
                repeatOpts.jobId = opts.jobId;
            }
            const legacyRepeatKey = getRepeatConcatOptions(name, repeatOpts);
            const newRepeatKey = (_b = opts.repeat.key) !== null && _b !== void 0 ? _b : this.hash(legacyRepeatKey);
            let repeatJobKey;
            if (override) {
                repeatJobKey = await this.scripts.addRepeatableJob(newRepeatKey, nextMillis, {
                    name,
                    endDate: endDate ? new Date(endDate).getTime() : undefined,
                    tz: repeatOpts.tz,
                    pattern,
                    every
                }, legacyRepeatKey);
            } else {
                const client = await this.client;
                repeatJobKey = await this.scripts.updateRepeatableJobMillis(client, newRepeatKey, nextMillis, legacyRepeatKey);
            }
            const { immediately } = repeatOpts, filteredRepeatOpts = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$tslib$2f$tslib$2e$es6$2e$mjs__$5b$app$2d$route$5d$__$28$ecmascript$29$__["__rest"])(repeatOpts, [
                "immediately"
            ]);
            return this.createNextJob(name, nextMillis, repeatJobKey, Object.assign(Object.assign({}, opts), {
                repeat: Object.assign({
                    offset
                }, filteredRepeatOpts)
            }), data, iterationCount, hasImmediately);
        }
    }
    async createNextJob(name, nextMillis, repeatJobKey, opts, data, currentCount, hasImmediately) {
        //
        // Generate unique job id for this iteration.
        //
        const jobId = this.getRepeatJobKey(name, nextMillis, repeatJobKey, data);
        const now = Date.now();
        const delay = nextMillis + (opts.repeat.offset ? opts.repeat.offset : 0) - now;
        const mergedOpts = Object.assign(Object.assign({}, opts), {
            jobId,
            delay: delay < 0 || hasImmediately ? 0 : delay,
            timestamp: now,
            prevMillis: nextMillis,
            repeatJobKey
        });
        mergedOpts.repeat = Object.assign(Object.assign({}, opts.repeat), {
            count: currentCount
        });
        return this.Job.create(this, name, data, mergedOpts);
    }
    // TODO: remove legacy code in next breaking change
    getRepeatJobKey(name, nextMillis, repeatJobKey, data) {
        if (repeatJobKey.split(':').length > 2) {
            return this.getRepeatJobId({
                name: name,
                nextMillis: nextMillis,
                namespace: this.hash(repeatJobKey),
                jobId: data === null || data === void 0 ? void 0 : data.id
            });
        }
        return this.getRepeatDelayedJobId({
            customKey: repeatJobKey,
            nextMillis
        });
    }
    async removeRepeatable(name, repeat, jobId) {
        var _a;
        const repeatConcatOptions = getRepeatConcatOptions(name, Object.assign(Object.assign({}, repeat), {
            jobId
        }));
        const repeatJobKey = (_a = repeat.key) !== null && _a !== void 0 ? _a : this.hash(repeatConcatOptions);
        const legacyRepeatJobId = this.getRepeatJobId({
            name,
            nextMillis: '',
            namespace: this.hash(repeatConcatOptions),
            jobId: jobId !== null && jobId !== void 0 ? jobId : repeat.jobId,
            key: repeat.key
        });
        return this.scripts.removeRepeatable(legacyRepeatJobId, repeatConcatOptions, repeatJobKey);
    }
    async removeRepeatableByKey(repeatJobKey) {
        const data = this.keyToData(repeatJobKey);
        const legacyRepeatJobId = this.getRepeatJobId({
            name: data.name,
            nextMillis: '',
            namespace: this.hash(repeatJobKey),
            jobId: data.id
        });
        return this.scripts.removeRepeatable(legacyRepeatJobId, '', repeatJobKey);
    }
    async getRepeatableData(client, key, next) {
        const jobData = await client.hgetall(this.toKey('repeat:' + key));
        if (jobData) {
            return {
                key,
                name: jobData.name,
                endDate: parseInt(jobData.endDate) || null,
                tz: jobData.tz || null,
                pattern: jobData.pattern || null,
                every: jobData.every || null,
                next
            };
        }
        return this.keyToData(key, next);
    }
    keyToData(key, next) {
        const data = key.split(':');
        const pattern = data.slice(4).join(':') || null;
        return {
            key,
            name: data[0],
            id: data[1] || null,
            endDate: parseInt(data[2]) || null,
            tz: data[3] || null,
            pattern,
            next
        };
    }
    async getRepeatableJobs(start = 0, end = -1, asc = false) {
        const client = await this.client;
        const key = this.keys.repeat;
        const result = asc ? await client.zrange(key, start, end, 'WITHSCORES') : await client.zrevrange(key, start, end, 'WITHSCORES');
        const jobs = [];
        for(let i = 0; i < result.length; i += 2){
            jobs.push(this.getRepeatableData(client, result[i], parseInt(result[i + 1])));
        }
        return Promise.all(jobs);
    }
    async getRepeatableCount() {
        const client = await this.client;
        return client.zcard(this.toKey('repeat'));
    }
    hash(str) {
        return (0, __TURBOPACK__imported__module__$5b$externals$5d2f$crypto__$5b$external$5d$__$28$crypto$2c$__cjs$29$__["createHash"])(this.repeatKeyHashAlgorithm).update(str).digest('hex');
    }
    getRepeatDelayedJobId({ nextMillis, customKey }) {
        return `repeat:${customKey}:${nextMillis}`;
    }
    getRepeatJobId({ name, nextMillis, namespace, jobId, key }) {
        const checksum = key !== null && key !== void 0 ? key : this.hash(`${name}${jobId || ''}${namespace}`);
        return `repeat:${checksum}:${nextMillis}`;
    }
}
function getRepeatConcatOptions(name, repeat) {
    const endDate = repeat.endDate ? new Date(repeat.endDate).getTime() : '';
    const tz = repeat.tz || '';
    const pattern = repeat.pattern;
    const suffix = (pattern ? pattern : String(repeat.every)) || '';
    const jobId = repeat.jobId ? repeat.jobId : '';
    return `${name}:${jobId}:${endDate}:${tz}:${suffix}`;
}
const getNextMillis = (millis, opts)=>{
    const pattern = opts.pattern;
    if (pattern && opts.every) {
        throw new Error('Both .pattern and .every options are defined for this repeatable job');
    }
    if (opts.every) {
        return Math.floor(millis / opts.every) * opts.every + (opts.immediately ? 0 : opts.every);
    }
    const currentDate = opts.startDate && new Date(opts.startDate) > new Date(millis) ? new Date(opts.startDate) : new Date(millis);
    const interval = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$cron$2d$parser$2f$lib$2f$parser$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["parseExpression"])(pattern, Object.assign(Object.assign({}, opts), {
        currentDate
    }));
    try {
        if (opts.immediately) {
            return new Date().getTime();
        } else {
            return interval.next().getTime();
        }
    } catch (e) {
    // Ignore error
    }
}; //# sourceMappingURL=repeat.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/queue.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "Queue",
    ()=>Queue
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$uuid$2f$dist$2f$esm$2f$v4$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$export__default__as__v4$3e$__ = __turbopack_context__.i("[project]/node_modules/uuid/dist/esm/v4.js [app-route] (ecmascript) <export default as v4>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$job$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/job.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$getters$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/queue-getters.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$repeat$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/repeat.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/telemetry-attributes.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$job$2d$scheduler$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/job-scheduler.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$version$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/version.js [app-route] (ecmascript)");
;
;
;
;
;
;
;
class Queue extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$getters$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["QueueGetters"] {
    constructor(name, opts, Connection){
        var _a;
        super(name, Object.assign({}, opts), Connection);
        this.token = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$uuid$2f$dist$2f$esm$2f$v4$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$export__default__as__v4$3e$__["v4"])();
        this.libName = 'bullmq';
        this.jobsOpts = (_a = opts === null || opts === void 0 ? void 0 : opts.defaultJobOptions) !== null && _a !== void 0 ? _a : {};
        this.waitUntilReady().then((client)=>{
            if (!this.closing && !(opts === null || opts === void 0 ? void 0 : opts.skipMetasUpdate)) {
                return client.hmset(this.keys.meta, this.metaValues);
            }
        }).catch((err)=>{
        // We ignore this error to avoid warnings. The error can still
        // be received by listening to event 'error'
        });
    }
    emit(event, ...args) {
        return super.emit(event, ...args);
    }
    off(eventName, listener) {
        super.off(eventName, listener);
        return this;
    }
    on(event, listener) {
        super.on(event, listener);
        return this;
    }
    once(event, listener) {
        super.once(event, listener);
        return this;
    }
    /**
     * Returns this instance current default job options.
     */ get defaultJobOptions() {
        return Object.assign({}, this.jobsOpts);
    }
    get metaValues() {
        var _a, _b, _c, _d;
        return {
            'opts.maxLenEvents': (_d = (_c = (_b = (_a = this.opts) === null || _a === void 0 ? void 0 : _a.streams) === null || _b === void 0 ? void 0 : _b.events) === null || _c === void 0 ? void 0 : _c.maxLen) !== null && _d !== void 0 ? _d : 10000,
            version: `${this.libName}:${__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$version$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["version"]}`
        };
    }
    /**
     * Get library version.
     *
     * @returns the content of the meta.library field.
     */ async getVersion() {
        const client = await this.client;
        return await client.hget(this.keys.meta, 'version');
    }
    get repeat() {
        return new Promise(async (resolve)=>{
            if (!this._repeat) {
                this._repeat = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$repeat$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Repeat"](this.name, Object.assign(Object.assign({}, this.opts), {
                    connection: await this.client
                }));
                this._repeat.on('error', (e)=>this.emit.bind(this, e));
            }
            resolve(this._repeat);
        });
    }
    get jobScheduler() {
        return new Promise(async (resolve)=>{
            if (!this._jobScheduler) {
                this._jobScheduler = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$job$2d$scheduler$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["JobScheduler"](this.name, Object.assign(Object.assign({}, this.opts), {
                    connection: await this.client
                }));
                this._jobScheduler.on('error', (e)=>this.emit.bind(this, e));
            }
            resolve(this._jobScheduler);
        });
    }
    /**
     * Enable and set global concurrency value.
     * @param concurrency - Maximum number of simultaneous jobs that the workers can handle.
     * For instance, setting this value to 1 ensures that no more than one job
     * is processed at any given time. If this limit is not defined, there will be no
     * restriction on the number of concurrent jobs.
     */ async setGlobalConcurrency(concurrency) {
        const client = await this.client;
        return client.hset(this.keys.meta, 'concurrency', concurrency);
    }
    /**
     * Enable and set rate limit.
     * @param max - Max number of jobs to process in the time period specified in `duration`
     * @param duration - Time in milliseconds. During this time, a maximum of `max` jobs will be processed.
     */ async setGlobalRateLimit(max, duration) {
        const client = await this.client;
        return client.hset(this.keys.meta, 'max', max, 'duration', duration);
    }
    /**
     * Remove global concurrency value.
     */ async removeGlobalConcurrency() {
        const client = await this.client;
        return client.hdel(this.keys.meta, 'concurrency');
    }
    /**
     * Remove global rate limit values.
     */ async removeGlobalRateLimit() {
        const client = await this.client;
        return client.hdel(this.keys.meta, 'max', 'duration');
    }
    /**
     * Adds a new job to the queue.
     *
     * @param name - Name of the job to be added to the queue.
     * @param data - Arbitrary data to append to the job.
     * @param opts - Job options that affects how the job is going to be processed.
     */ async add(name, data, opts) {
        return this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].PRODUCER, 'add', `${this.name}.${name}`, async (span, srcPropagationMedatada)=>{
            var _a;
            if (srcPropagationMedatada && !((_a = opts === null || opts === void 0 ? void 0 : opts.telemetry) === null || _a === void 0 ? void 0 : _a.omitContext)) {
                const telemetry = {
                    metadata: srcPropagationMedatada
                };
                opts = Object.assign(Object.assign({}, opts), {
                    telemetry
                });
            }
            const job = await this.addJob(name, data, opts);
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobName]: name,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobId]: job.id
            });
            return job;
        });
    }
    /**
     * addJob is a telemetry free version of the add method, useful in order to wrap it
     * with custom telemetry on subclasses.
     *
     * @param name - Name of the job to be added to the queue.
     * @param data - Arbitrary data to append to the job.
     * @param opts - Job options that affects how the job is going to be processed.
     *
     * @returns Job
     */ async addJob(name, data, opts) {
        if (opts && opts.repeat) {
            if (opts.repeat.endDate) {
                if (+new Date(opts.repeat.endDate) < Date.now()) {
                    throw new Error('End date must be greater than current timestamp');
                }
            }
            return (await this.repeat).updateRepeatableJob(name, data, Object.assign(Object.assign({}, this.jobsOpts), opts), {
                override: true
            });
        } else {
            const jobId = opts === null || opts === void 0 ? void 0 : opts.jobId;
            if (jobId == '0' || (jobId === null || jobId === void 0 ? void 0 : jobId.startsWith('0:'))) {
                throw new Error("JobId cannot be '0' or start with 0:");
            }
            const job = await this.Job.create(this, name, data, Object.assign(Object.assign(Object.assign({}, this.jobsOpts), opts), {
                jobId
            }));
            this.emit('waiting', job);
            return job;
        }
    }
    /**
     * Adds an array of jobs to the queue. This method may be faster than adding
     * one job at a time in a sequence.
     *
     * @param jobs - The array of jobs to add to the queue. Each job is defined by 3
     * properties, 'name', 'data' and 'opts'. They follow the same signature as 'Queue.add'.
     */ async addBulk(jobs) {
        return this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].PRODUCER, 'addBulk', this.name, async (span, srcPropagationMedatada)=>{
            if (span) {
                span.setAttributes({
                    [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].BulkNames]: jobs.map((job)=>job.name),
                    [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].BulkCount]: jobs.length
                });
            }
            return await this.Job.createBulk(this, jobs.map((job)=>{
                var _a, _b, _c, _d, _e, _f;
                let telemetry = (_a = job.opts) === null || _a === void 0 ? void 0 : _a.telemetry;
                if (srcPropagationMedatada) {
                    const omitContext = (_c = (_b = job.opts) === null || _b === void 0 ? void 0 : _b.telemetry) === null || _c === void 0 ? void 0 : _c.omitContext;
                    const telemetryMetadata = ((_e = (_d = job.opts) === null || _d === void 0 ? void 0 : _d.telemetry) === null || _e === void 0 ? void 0 : _e.metadata) || !omitContext && srcPropagationMedatada;
                    if (telemetryMetadata || omitContext) {
                        telemetry = {
                            metadata: telemetryMetadata,
                            omitContext
                        };
                    }
                }
                return {
                    name: job.name,
                    data: job.data,
                    opts: Object.assign(Object.assign(Object.assign({}, this.jobsOpts), job.opts), {
                        jobId: (_f = job.opts) === null || _f === void 0 ? void 0 : _f.jobId,
                        telemetry
                    })
                };
            }));
        });
    }
    /**
     * Upserts a scheduler.
     *
     * A scheduler is a job factory that creates jobs at a given interval.
     * Upserting a scheduler will create a new job scheduler or update an existing one.
     * It will also create the first job based on the repeat options and delayed accordingly.
     *
     * @param key - Unique key for the repeatable job meta.
     * @param repeatOpts - Repeat options
     * @param jobTemplate - Job template. If provided it will be used for all the jobs
     * created by the scheduler.
     *
     * @returns The next job to be scheduled (would normally be in delayed state).
     */ async upsertJobScheduler(jobSchedulerId, repeatOpts, jobTemplate) {
        var _a, _b;
        if (repeatOpts.endDate) {
            if (+new Date(repeatOpts.endDate) < Date.now()) {
                throw new Error('End date must be greater than current timestamp');
            }
        }
        return (await this.jobScheduler).upsertJobScheduler(jobSchedulerId, repeatOpts, (_a = jobTemplate === null || jobTemplate === void 0 ? void 0 : jobTemplate.name) !== null && _a !== void 0 ? _a : jobSchedulerId, (_b = jobTemplate === null || jobTemplate === void 0 ? void 0 : jobTemplate.data) !== null && _b !== void 0 ? _b : {}, Object.assign(Object.assign({}, this.jobsOpts), jobTemplate === null || jobTemplate === void 0 ? void 0 : jobTemplate.opts), {
            override: true
        });
    }
    /**
     * Pauses the processing of this queue globally.
     *
     * We use an atomic RENAME operation on the wait queue. Since
     * we have blocking calls with BRPOPLPUSH on the wait queue, as long as the queue
     * is renamed to 'paused', no new jobs will be processed (the current ones
     * will run until finalized).
     *
     * Adding jobs requires a LUA script to check first if the paused list exist
     * and in that case it will add it there instead of the wait list.
     */ async pause() {
        await this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'pause', this.name, async ()=>{
            await this.scripts.pause(true);
            this.emit('paused');
        });
    }
    /**
     * Close the queue instance.
     *
     */ async close() {
        await this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'close', this.name, async ()=>{
            if (!this.closing) {
                if (this._repeat) {
                    await this._repeat.close();
                }
            }
            await super.close();
        });
    }
    /**
     * Overrides the rate limit to be active for the next jobs.
     *
     * @param expireTimeMs - expire time in ms of this rate limit.
     */ async rateLimit(expireTimeMs) {
        await this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'rateLimit', this.name, async (span)=>{
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].QueueRateLimit]: expireTimeMs
            });
            await this.client.then((client)=>client.set(this.keys.limiter, Number.MAX_SAFE_INTEGER, 'PX', expireTimeMs));
        });
    }
    /**
     * Resumes the processing of this queue globally.
     *
     * The method reverses the pause operation by resuming the processing of the
     * queue.
     */ async resume() {
        await this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'resume', this.name, async ()=>{
            await this.scripts.pause(false);
            this.emit('resumed');
        });
    }
    /**
     * Returns true if the queue is currently paused.
     */ async isPaused() {
        const client = await this.client;
        const pausedKeyExists = await client.hexists(this.keys.meta, 'paused');
        return pausedKeyExists === 1;
    }
    /**
     * Returns true if the queue is currently maxed.
     */ isMaxed() {
        return this.scripts.isMaxed();
    }
    /**
     * Get all repeatable meta jobs.
     *
     * @deprecated This method is deprecated and will be removed in v6. Use getJobSchedulers instead.
     *
     * @param start - Offset of first job to return.
     * @param end - Offset of last job to return.
     * @param asc - Determine the order in which jobs are returned based on their
     * next execution time.
     */ async getRepeatableJobs(start, end, asc) {
        return (await this.repeat).getRepeatableJobs(start, end, asc);
    }
    /**
     * Get Job Scheduler by id
     *
     * @param id - identifier of scheduler.
     */ async getJobScheduler(id) {
        return (await this.jobScheduler).getScheduler(id);
    }
    /**
     * Get all Job Schedulers
     *
     * @param start - Offset of first scheduler to return.
     * @param end - Offset of last scheduler to return.
     * @param asc - Determine the order in which schedulers are returned based on their
     * next execution time.
     */ async getJobSchedulers(start, end, asc) {
        return (await this.jobScheduler).getJobSchedulers(start, end, asc);
    }
    /**
     *
     * Get the number of job schedulers.
     *
     * @returns The number of job schedulers.
     */ async getJobSchedulersCount() {
        return (await this.jobScheduler).getSchedulersCount();
    }
    /**
     * Removes a repeatable job.
     *
     * Note: you need to use the exact same repeatOpts when deleting a repeatable job
     * than when adding it.
     *
     * @deprecated This method is deprecated and will be removed in v6. Use removeJobScheduler instead.
     *
     * @see removeRepeatableByKey
     *
     * @param name - Job name
     * @param repeatOpts - Repeat options
     * @param jobId - Job id to remove. If not provided, all jobs with the same repeatOpts
     * @returns
     */ async removeRepeatable(name, repeatOpts, jobId) {
        return this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'removeRepeatable', `${this.name}.${name}`, async (span)=>{
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobName]: name,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobId]: jobId
            });
            const repeat = await this.repeat;
            const removed = await repeat.removeRepeatable(name, repeatOpts, jobId);
            return !removed;
        });
    }
    /**
     *
     * Removes a job scheduler.
     *
     * @param jobSchedulerId - identifier of the job scheduler.
     *
     * @returns
     */ async removeJobScheduler(jobSchedulerId) {
        const jobScheduler = await this.jobScheduler;
        const removed = await jobScheduler.removeJobScheduler(jobSchedulerId);
        return !removed;
    }
    /**
     * Removes a debounce key.
     * @deprecated use removeDeduplicationKey
     *
     * @param id - debounce identifier
     */ async removeDebounceKey(id) {
        return this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'removeDebounceKey', `${this.name}`, async (span)=>{
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobKey]: id
            });
            const client = await this.client;
            return await client.del(`${this.keys.de}:${id}`);
        });
    }
    /**
     * Removes a deduplication key.
     *
     * @param id - identifier
     */ async removeDeduplicationKey(id) {
        return this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'removeDeduplicationKey', `${this.name}`, async (span)=>{
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].DeduplicationKey]: id
            });
            const client = await this.client;
            return client.del(`${this.keys.de}:${id}`);
        });
    }
    /**
     * Removes rate limit key.
     */ async removeRateLimitKey() {
        const client = await this.client;
        return client.del(this.keys.limiter);
    }
    /**
     * Removes a repeatable job by its key. Note that the key is the one used
     * to store the repeatable job metadata and not one of the job iterations
     * themselves. You can use "getRepeatableJobs" in order to get the keys.
     *
     * @see getRepeatableJobs
     *
     * @deprecated This method is deprecated and will be removed in v6. Use removeJobScheduler instead.
     *
     * @param repeatJobKey - To the repeatable job.
     * @returns
     */ async removeRepeatableByKey(key) {
        return this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'removeRepeatableByKey', `${this.name}`, async (span)=>{
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobKey]: key
            });
            const repeat = await this.repeat;
            const removed = await repeat.removeRepeatableByKey(key);
            return !removed;
        });
    }
    /**
     * Removes the given job from the queue as well as all its
     * dependencies.
     *
     * @param jobId - The id of the job to remove
     * @param opts - Options to remove a job
     * @returns 1 if it managed to remove the job or 0 if the job or
     * any of its dependencies were locked.
     */ async remove(jobId, { removeChildren = true } = {}) {
        return this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'remove', this.name, async (span)=>{
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobId]: jobId,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobOptions]: JSON.stringify({
                    removeChildren
                })
            });
            const code = await this.scripts.remove(jobId, removeChildren);
            if (code === 1) {
                this.emit('removed', jobId);
            }
            return code;
        });
    }
    /**
     * Updates the given job's progress.
     *
     * @param jobId - The id of the job to update
     * @param progress - Number or object to be saved as progress.
     */ async updateJobProgress(jobId, progress) {
        await this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'updateJobProgress', this.name, async (span)=>{
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobId]: jobId,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobProgress]: JSON.stringify(progress)
            });
            await this.scripts.updateProgress(jobId, progress);
            this.emit('progress', jobId, progress);
        });
    }
    /**
     * Logs one row of job's log data.
     *
     * @param jobId - The job id to log against.
     * @param logRow - String with log data to be logged.
     * @param keepLogs - Max number of log entries to keep (0 for unlimited).
     *
     * @returns The total number of log entries for this job so far.
     */ async addJobLog(jobId, logRow, keepLogs) {
        return __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$job$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Job"].addJobLog(this, jobId, logRow, keepLogs);
    }
    /**
     * Drains the queue, i.e., removes all jobs that are waiting
     * or delayed, but not active, completed or failed.
     *
     * @param delayed - Pass true if it should also clean the
     * delayed jobs.
     */ async drain(delayed = false) {
        await this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'drain', this.name, async (span)=>{
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].QueueDrainDelay]: delayed
            });
            await this.scripts.drain(delayed);
        });
    }
    /**
     * Cleans jobs from a queue. Similar to drain but keeps jobs within a certain
     * grace period.
     *
     * @param grace - The grace period in milliseconds
     * @param limit - Max number of jobs to clean
     * @param type - The type of job to clean
     * Possible values are completed, wait, active, paused, delayed, failed. Defaults to completed.
     * @returns Id jobs from the deleted records
     */ async clean(grace, limit, type = 'completed') {
        return this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'clean', this.name, async (span)=>{
            const maxCount = limit || Infinity;
            const maxCountPerCall = Math.min(10000, maxCount);
            const timestamp = Date.now() - grace;
            let deletedCount = 0;
            const deletedJobsIds = [];
            // Normalize 'waiting' to 'wait' for consistency with internal Redis keys
            const normalizedType = type === 'waiting' ? 'wait' : type;
            while(deletedCount < maxCount){
                const jobsIds = await this.scripts.cleanJobsInSet(normalizedType, timestamp, maxCountPerCall);
                this.emit('cleaned', jobsIds, normalizedType);
                deletedCount += jobsIds.length;
                deletedJobsIds.push(...jobsIds);
                if (jobsIds.length < maxCountPerCall) {
                    break;
                }
            }
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].QueueGrace]: grace,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobType]: type,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].QueueCleanLimit]: maxCount,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobIds]: deletedJobsIds
            });
            return deletedJobsIds;
        });
    }
    /**
     * Completely destroys the queue and all of its contents irreversibly.
     * This method will *pause* the queue and requires that there are no
     * active jobs. It is possible to bypass this requirement, i.e. not
     * having active jobs using the "force" option.
     *
     * Note: This operation requires to iterate on all the jobs stored in the queue
     * and can be slow for very large queues.
     *
     * @param opts - Obliterate options.
     */ async obliterate(opts) {
        await this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'obliterate', this.name, async ()=>{
            await this.pause();
            let cursor = 0;
            do {
                cursor = await this.scripts.obliterate(Object.assign({
                    force: false,
                    count: 1000
                }, opts));
            }while (cursor)
        });
    }
    /**
     * Retry all the failed or completed jobs.
     *
     * @param opts - An object with the following properties:
     *   - count  number to limit how many jobs will be moved to wait status per iteration,
     *   - state  failed by default or completed.
     *   - timestamp from which timestamp to start moving jobs to wait status, default Date.now().
     *
     * @returns
     */ async retryJobs(opts = {}) {
        await this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].PRODUCER, 'retryJobs', this.name, async (span)=>{
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].QueueOptions]: JSON.stringify(opts)
            });
            let cursor = 0;
            do {
                cursor = await this.scripts.retryJobs(opts.state, opts.count, opts.timestamp);
            }while (cursor)
        });
    }
    /**
     * Promote all the delayed jobs.
     *
     * @param opts - An object with the following properties:
     *   - count  number to limit how many jobs will be moved to wait status per iteration
     *
     * @returns
     */ async promoteJobs(opts = {}) {
        await this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'promoteJobs', this.name, async (span)=>{
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].QueueOptions]: JSON.stringify(opts)
            });
            let cursor = 0;
            do {
                cursor = await this.scripts.promoteJobs(opts.count);
            }while (cursor)
        });
    }
    /**
     * Trim the event stream to an approximately maxLength.
     *
     * @param maxLength -
     */ async trimEvents(maxLength) {
        return this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'trimEvents', this.name, async (span)=>{
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].QueueEventMaxLength]: maxLength
            });
            const client = await this.client;
            return await client.xtrim(this.keys.events, 'MAXLEN', '~', maxLength);
        });
    }
    /**
     * Delete old priority helper key.
     */ async removeDeprecatedPriorityKey() {
        const client = await this.client;
        return client.del(this.toKey('priority'));
    }
} //# sourceMappingURL=queue.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/sandbox.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "default",
    ()=>__TURBOPACK__default__export__
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$child$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/child-command.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/parent-command.js [app-route] (ecmascript)");
;
const sandbox = (processFile, childPool)=>{
    return async function process(job, token) {
        let child;
        let msgHandler;
        let exitHandler;
        try {
            const done = new Promise((resolve, reject)=>{
                const initChild = async ()=>{
                    try {
                        exitHandler = (exitCode, signal)=>{
                            reject(new Error('Unexpected exit code: ' + exitCode + ' signal: ' + signal));
                        };
                        child = await childPool.retain(processFile);
                        child.on('exit', exitHandler);
                        msgHandler = async (msg)=>{
                            var _a, _b, _c, _d, _e;
                            try {
                                switch(msg.cmd){
                                    case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].Completed:
                                        resolve(msg.value);
                                        break;
                                    case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].Failed:
                                    case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].Error:
                                        {
                                            const err = new Error();
                                            Object.assign(err, msg.value);
                                            reject(err);
                                            break;
                                        }
                                    case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].Progress:
                                        await job.updateProgress(msg.value);
                                        break;
                                    case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].Log:
                                        await job.log(msg.value);
                                        break;
                                    case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].MoveToDelayed:
                                        await job.moveToDelayed((_a = msg.value) === null || _a === void 0 ? void 0 : _a.timestamp, (_b = msg.value) === null || _b === void 0 ? void 0 : _b.token);
                                        break;
                                    case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].MoveToWait:
                                        await job.moveToWait((_c = msg.value) === null || _c === void 0 ? void 0 : _c.token);
                                        break;
                                    case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].MoveToWaitingChildren:
                                        {
                                            const value = await job.moveToWaitingChildren((_d = msg.value) === null || _d === void 0 ? void 0 : _d.token, (_e = msg.value) === null || _e === void 0 ? void 0 : _e.opts);
                                            child.send({
                                                requestId: msg.requestId,
                                                cmd: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$child$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ChildCommand"].MoveToWaitingChildrenResponse,
                                                value
                                            });
                                        }
                                        break;
                                    case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].Update:
                                        await job.updateData(msg.value);
                                        break;
                                    case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].GetChildrenValues:
                                        {
                                            const value = await job.getChildrenValues();
                                            child.send({
                                                requestId: msg.requestId,
                                                cmd: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$child$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ChildCommand"].GetChildrenValuesResponse,
                                                value
                                            });
                                        }
                                        break;
                                    case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$parent$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ParentCommand"].GetIgnoredChildrenFailures:
                                        {
                                            const value = await job.getIgnoredChildrenFailures();
                                            child.send({
                                                requestId: msg.requestId,
                                                cmd: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$child$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ChildCommand"].GetIgnoredChildrenFailuresResponse,
                                                value
                                            });
                                        }
                                        break;
                                }
                            } catch (err) {
                                reject(err);
                            }
                        };
                        child.on('message', msgHandler);
                        child.send({
                            cmd: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$child$2d$command$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ChildCommand"].Start,
                            job: job.asJSONSandbox(),
                            token
                        });
                    } catch (error) {
                        reject(error);
                    }
                };
                initChild();
            });
            await done;
            return done;
        } finally{
            if (child) {
                child.off('message', msgHandler);
                child.off('exit', exitHandler);
                if (child.exitCode === null && child.signalCode === null) {
                    childPool.release(child);
                }
            }
        }
    };
};
const __TURBOPACK__default__export__ = sandbox;
 //# sourceMappingURL=sandbox.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/worker.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "Worker",
    ()=>Worker
]);
var __TURBOPACK__imported__module__$5b$externals$5d2f$fs__$5b$external$5d$__$28$fs$2c$__cjs$29$__ = __turbopack_context__.i("[externals]/fs [external] (fs, cjs)");
var __TURBOPACK__imported__module__$5b$externals$5d2f$url__$5b$external$5d$__$28$url$2c$__cjs$29$__ = __turbopack_context__.i("[externals]/url [external] (url, cjs)");
var __TURBOPACK__imported__module__$5b$externals$5d2f$path__$5b$external$5d$__$28$path$2c$__cjs$29$__ = __turbopack_context__.i("[externals]/path [external] (path, cjs)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$uuid$2f$dist$2f$esm$2f$v4$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$export__default__as__v4$3e$__ = __turbopack_context__.i("[project]/node_modules/uuid/dist/esm/v4.js [app-route] (ecmascript) <export default as v4>");
// Note: this Polyfill is only needed for Node versions < 15.4.0
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$node$2d$abort$2d$controller$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/node-abort-controller/index.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/utils/index.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$base$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/queue-base.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$repeat$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/repeat.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$child$2d$pool$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/child-pool.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$redis$2d$connection$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/redis-connection.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$sandbox$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/sandbox.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$async$2d$fifo$2d$queue$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/async-fifo-queue.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/errors/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$delayed$2d$error$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/errors/delayed-error.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$rate$2d$limit$2d$error$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/errors/rate-limit-error.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$waiting$2d$children$2d$error$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/errors/waiting-children-error.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$waiting$2d$error$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/errors/waiting-error.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$unrecoverable$2d$error$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/errors/unrecoverable-error.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/telemetry-attributes.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$job$2d$scheduler$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/job-scheduler.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$lock$2d$manager$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/lock-manager.js [app-route] (ecmascript)");
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
// 10 seconds is the maximum time a BZPOPMIN can block.
const maximumBlockTimeout = 10;
class Worker extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$base$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["QueueBase"] {
    static RateLimitError() {
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$rate$2d$limit$2d$error$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["RateLimitError"]();
    }
    constructor(name, processor, opts, Connection){
        super(name, Object.assign(Object.assign({
            drainDelay: 5,
            concurrency: 1,
            lockDuration: 30000,
            maximumRateLimitDelay: 30000,
            maxStalledCount: 1,
            stalledInterval: 30000,
            autorun: true,
            runRetryDelay: 15000
        }, opts), {
            blockingConnection: true
        }), Connection);
        this.abortDelayController = null;
        this.blockUntil = 0;
        this.drained = false;
        this.limitUntil = 0;
        this.processorAcceptsSignal = false;
        this.waiting = null;
        this.running = false;
        this.mainLoopRunning = null;
        if (!opts || !opts.connection) {
            throw new Error('Worker requires a connection');
        }
        if (typeof this.opts.maxStalledCount !== 'number' || this.opts.maxStalledCount < 0) {
            throw new Error('maxStalledCount must be greater or equal than 0');
        }
        if (typeof this.opts.maxStartedAttempts === 'number' && this.opts.maxStartedAttempts < 0) {
            throw new Error('maxStartedAttempts must be greater or equal than 0');
        }
        if (typeof this.opts.stalledInterval !== 'number' || this.opts.stalledInterval <= 0) {
            throw new Error('stalledInterval must be greater than 0');
        }
        if (typeof this.opts.drainDelay !== 'number' || this.opts.drainDelay <= 0) {
            throw new Error('drainDelay must be greater than 0');
        }
        this.concurrency = this.opts.concurrency;
        this.opts.lockRenewTime = this.opts.lockRenewTime || this.opts.lockDuration / 2;
        this.id = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$uuid$2f$dist$2f$esm$2f$v4$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$export__default__as__v4$3e$__["v4"])();
        this.createLockManager();
        if (processor) {
            if (typeof processor === 'function') {
                this.processFn = processor;
                // Check if processor accepts signal parameter (3rd parameter)
                this.processorAcceptsSignal = processor.length >= 3;
            } else {
                // SANDBOXED
                if (processor instanceof __TURBOPACK__imported__module__$5b$externals$5d2f$url__$5b$external$5d$__$28$url$2c$__cjs$29$__["URL"]) {
                    if (!__TURBOPACK__imported__module__$5b$externals$5d2f$fs__$5b$external$5d$__$28$fs$2c$__cjs$29$__["existsSync"](processor)) {
                        throw new Error(`URL ${processor} does not exist in the local file system`);
                    }
                    processor = processor.href;
                } else {
                    const supportedFileTypes = [
                        '.js',
                        '.ts',
                        '.flow',
                        '.cjs',
                        '.mjs'
                    ];
                    const processorFile = processor + (supportedFileTypes.includes(__TURBOPACK__imported__module__$5b$externals$5d2f$path__$5b$external$5d$__$28$path$2c$__cjs$29$__["extname"](processor)) ? '' : '.js');
                    if (!__TURBOPACK__imported__module__$5b$externals$5d2f$fs__$5b$external$5d$__$28$fs$2c$__cjs$29$__["existsSync"](processorFile)) {
                        throw new Error(`File ${processorFile} does not exist`);
                    }
                }
                // Separate paths so that bundling tools can resolve dependencies easier
                const dirname = __TURBOPACK__imported__module__$5b$externals$5d2f$path__$5b$external$5d$__$28$path$2c$__cjs$29$__["dirname"](module.filename || ("TURBOPACK compile-time value", "/ROOT/node_modules/bullmq/dist/esm/classes/worker.js"));
                const workerThreadsMainFile = __TURBOPACK__imported__module__$5b$externals$5d2f$path__$5b$external$5d$__$28$path$2c$__cjs$29$__["join"](dirname, 'main-worker.js');
                const spawnProcessMainFile = __TURBOPACK__imported__module__$5b$externals$5d2f$path__$5b$external$5d$__$28$path$2c$__cjs$29$__["join"](dirname, 'main.js');
                let mainFilePath = this.opts.useWorkerThreads ? workerThreadsMainFile : spawnProcessMainFile;
                try {
                    __TURBOPACK__imported__module__$5b$externals$5d2f$fs__$5b$external$5d$__$28$fs$2c$__cjs$29$__["statSync"](mainFilePath); // would throw if file not exists
                } catch (_) {
                    const mainFile = this.opts.useWorkerThreads ? 'main-worker.js' : 'main.js';
                    mainFilePath = __TURBOPACK__imported__module__$5b$externals$5d2f$path__$5b$external$5d$__$28$path$2c$__cjs$29$__["join"](process.cwd(), `dist/cjs/classes/${mainFile}`);
                    __TURBOPACK__imported__module__$5b$externals$5d2f$fs__$5b$external$5d$__$28$fs$2c$__cjs$29$__["statSync"](mainFilePath);
                }
                this.childPool = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$child$2d$pool$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ChildPool"]({
                    mainFile: mainFilePath,
                    useWorkerThreads: this.opts.useWorkerThreads,
                    workerForkOptions: this.opts.workerForkOptions,
                    workerThreadsOptions: this.opts.workerThreadsOptions
                });
                this.createSandbox(processor);
            }
            if (this.opts.autorun) {
                this.run().catch((error)=>this.emit('error', error));
            }
        }
        const connectionName = this.clientName() + (this.opts.name ? `:w:${this.opts.name}` : '');
        this.blockingConnection = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$redis$2d$connection$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["RedisConnection"]((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isRedisInstance"])(opts.connection) ? opts.connection.duplicate({
            connectionName
        }) : Object.assign(Object.assign({}, opts.connection), {
            connectionName
        }), {
            shared: false,
            blocking: true,
            skipVersionCheck: opts.skipVersionCheck
        });
        this.blockingConnection.on('error', (error)=>this.emit('error', error));
        this.blockingConnection.on('ready', ()=>setTimeout(()=>this.emit('ready'), 0));
    }
    /**
     * Creates and configures the lock manager for processing jobs.
     * This method can be overridden in subclasses to customize lock manager behavior.
     */ createLockManager() {
        this.lockManager = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$lock$2d$manager$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["LockManager"](this, {
            lockRenewTime: this.opts.lockRenewTime,
            lockDuration: this.opts.lockDuration,
            workerId: this.id,
            workerName: this.opts.name
        });
    }
    /**
     * Creates and configures the sandbox for processing jobs.
     * This method can be overridden in subclasses to customize sandbox behavior.
     *
     * @param processor - The processor file path, URL, or function to be sandboxed
     */ createSandbox(processor) {
        this.processFn = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$sandbox$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["default"])(processor, this.childPool).bind(this);
    }
    /**
     * Public accessor method for LockManager to extend locks.
     * This delegates to the protected scripts object.
     */ async extendJobLocks(jobIds, tokens, duration) {
        return this.scripts.extendLocks(jobIds, tokens, duration);
    }
    emit(event, ...args) {
        return super.emit(event, ...args);
    }
    off(eventName, listener) {
        super.off(eventName, listener);
        return this;
    }
    on(event, listener) {
        super.on(event, listener);
        return this;
    }
    once(event, listener) {
        super.once(event, listener);
        return this;
    }
    callProcessJob(job, token, signal) {
        return this.processFn(job, token, signal);
    }
    createJob(data, jobId) {
        return this.Job.fromJSON(this, data, jobId);
    }
    /**
     *
     * Waits until the worker is ready to start processing jobs.
     * In general only useful when writing tests.
     *
     */ async waitUntilReady() {
        await super.waitUntilReady();
        return this.blockingConnection.client;
    }
    /**
     * Cancels a specific job currently being processed by this worker.
     * The job's processor function will receive an abort signal.
     *
     * @param jobId - The ID of the job to cancel
     * @param reason - Optional reason for the cancellation
     * @returns true if the job was found and cancelled, false otherwise
     */ cancelJob(jobId, reason) {
        return this.lockManager.cancelJob(jobId, reason);
    }
    /**
     * Cancels all jobs currently being processed by this worker.
     * All active job processor functions will receive abort signals.
     *
     * @param reason - Optional reason for the cancellation
     */ cancelAllJobs(reason) {
        this.lockManager.cancelAllJobs(reason);
    }
    set concurrency(concurrency) {
        if (typeof concurrency !== 'number' || concurrency < 1 || !isFinite(concurrency)) {
            throw new Error('concurrency must be a finite number greater than 0');
        }
        this._concurrency = concurrency;
    }
    get concurrency() {
        return this._concurrency;
    }
    get repeat() {
        return new Promise(async (resolve)=>{
            if (!this._repeat) {
                const connection = await this.client;
                this._repeat = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$repeat$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Repeat"](this.name, Object.assign(Object.assign({}, this.opts), {
                    connection
                }));
                this._repeat.on('error', (e)=>this.emit.bind(this, e));
            }
            resolve(this._repeat);
        });
    }
    get jobScheduler() {
        return new Promise(async (resolve)=>{
            if (!this._jobScheduler) {
                const connection = await this.client;
                this._jobScheduler = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$job$2d$scheduler$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["JobScheduler"](this.name, Object.assign(Object.assign({}, this.opts), {
                    connection
                }));
                this._jobScheduler.on('error', (e)=>this.emit.bind(this, e));
            }
            resolve(this._jobScheduler);
        });
    }
    async run() {
        if (!this.processFn) {
            throw new Error('No process function is defined.');
        }
        if (this.running) {
            throw new Error('Worker is already running.');
        }
        try {
            this.running = true;
            if (this.closing || this.paused) {
                return;
            }
            await this.startStalledCheckTimer();
            if (!this.opts.skipLockRenewal) {
                this.lockManager.start();
            }
            const client = await this.client;
            const bclient = await this.blockingConnection.client;
            this.mainLoopRunning = this.mainLoop(client, bclient);
            // We must await here or finally will be called too early.
            await this.mainLoopRunning;
        } finally{
            this.running = false;
        }
    }
    async waitForRateLimit() {
        var _a;
        const limitUntil = this.limitUntil;
        if (limitUntil > Date.now()) {
            (_a = this.abortDelayController) === null || _a === void 0 ? void 0 : _a.abort();
            this.abortDelayController = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$node$2d$abort$2d$controller$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AbortController"]();
            const delay = this.getRateLimitDelay(limitUntil - Date.now());
            await this.delay(delay, this.abortDelayController);
            this.drained = false;
            this.limitUntil = 0;
        }
    }
    /**
     * This is the main loop in BullMQ. Its goals are to fetch jobs from the queue
     * as efficiently as possible, providing concurrency and minimal unnecessary calls
     * to Redis.
     */ async mainLoop(client, bclient) {
        const asyncFifoQueue = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$async$2d$fifo$2d$queue$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AsyncFifoQueue"]();
        let tokenPostfix = 0;
        while(!this.closing && !this.paused || asyncFifoQueue.numTotal() > 0){
            /**
             * This inner loop tries to fetch jobs concurrently, but if we are waiting for a job
             * to arrive at the queue we should not try to fetch more jobs (as it would be pointless)
             */ while(!this.closing && !this.paused && !this.waiting && asyncFifoQueue.numTotal() < this._concurrency && !this.isRateLimited()){
                const token = `${this.id}:${tokenPostfix++}`;
                const fetchedJob = this.retryIfFailed(()=>this._getNextJob(client, bclient, token, {
                        block: true
                    }), {
                    delayInMs: this.opts.runRetryDelay,
                    onlyEmitError: true
                });
                asyncFifoQueue.add(fetchedJob);
                if (this.waiting && asyncFifoQueue.numTotal() > 1) {
                    break;
                }
                // We await here so that we fetch jobs in sequence, this is important to avoid unnecessary calls
                // to Redis in high concurrency scenarios.
                const job = await fetchedJob;
                // No more jobs waiting but we have others that could start processing already
                if (!job && asyncFifoQueue.numTotal() > 1) {
                    break;
                }
                // If there are potential jobs to be processed and blockUntil is set, we should exit to avoid waiting
                // for processing this job.
                if (this.blockUntil) {
                    break;
                }
            }
            // Since there can be undefined jobs in the queue (when a job fails or queue is empty)
            // we iterate until we find a job.
            let job;
            do {
                job = await asyncFifoQueue.fetch();
            }while (!job && asyncFifoQueue.numQueued() > 0)
            if (job) {
                const token = job.token;
                asyncFifoQueue.add(this.processJob(job, token, ()=>asyncFifoQueue.numTotal() <= this._concurrency));
            } else if (asyncFifoQueue.numQueued() === 0) {
                await this.waitForRateLimit();
            }
        }
    }
    /**
     * Returns a promise that resolves to the next job in queue.
     * @param token - worker token to be assigned to retrieved job
     * @returns a Job or undefined if no job was available in the queue.
     */ async getNextJob(token, { block = true } = {}) {
        var _a, _b;
        const nextJob = await this._getNextJob(await this.client, await this.blockingConnection.client, token, {
            block
        });
        return this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'getNextJob', this.name, async (span)=>{
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerId]: this.id,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].QueueName]: this.name,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerName]: this.opts.name,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerOptions]: JSON.stringify({
                    block
                }),
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobId]: nextJob === null || nextJob === void 0 ? void 0 : nextJob.id
            });
            return nextJob;
        }, (_b = (_a = nextJob === null || nextJob === void 0 ? void 0 : nextJob.opts) === null || _a === void 0 ? void 0 : _a.telemetry) === null || _b === void 0 ? void 0 : _b.metadata);
    }
    async _getNextJob(client, bclient, token, { block = true } = {}) {
        if (this.paused) {
            return;
        }
        if (this.closing) {
            return;
        }
        if (this.drained && block && !this.limitUntil && !this.waiting) {
            this.waiting = this.waitForJob(bclient, this.blockUntil);
            try {
                this.blockUntil = await this.waiting;
                if (this.blockUntil <= 0 || this.blockUntil - Date.now() < 1) {
                    return await this.moveToActive(client, token, this.opts.name);
                }
            } finally{
                this.waiting = null;
            }
        } else {
            if (!this.isRateLimited()) {
                return this.moveToActive(client, token, this.opts.name);
            }
        }
    }
    /**
     * Overrides the rate limit to be active for the next jobs.
     * @deprecated This method is deprecated and will be removed in v6. Use queue.rateLimit method instead.
     * @param expireTimeMs - expire time in ms of this rate limit.
     */ async rateLimit(expireTimeMs) {
        await this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'rateLimit', this.name, async (span)=>{
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerId]: this.id,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerRateLimit]: expireTimeMs
            });
            await this.client.then((client)=>client.set(this.keys.limiter, Number.MAX_SAFE_INTEGER, 'PX', expireTimeMs));
        });
    }
    get minimumBlockTimeout() {
        return this.blockingConnection.capabilities.canBlockFor1Ms ? /* 1 millisecond is chosen because the granularity of our timestamps are milliseconds.
      Obviously we can still process much faster than 1 job per millisecond but delays and rate limits
      will never work with more accuracy than 1ms. */ 0.001 : 0.002;
    }
    isRateLimited() {
        return this.limitUntil > Date.now();
    }
    async moveToActive(client, token, name) {
        const [jobData, id, rateLimitDelay, delayUntil] = await this.scripts.moveToActive(client, token, name);
        this.updateDelays(rateLimitDelay, delayUntil);
        return this.nextJobFromJobData(jobData, id, token);
    }
    async waitForJob(bclient, blockUntil) {
        if (this.paused) {
            return Infinity;
        }
        let timeout;
        try {
            if (!this.closing && !this.isRateLimited()) {
                let blockTimeout = this.getBlockTimeout(blockUntil);
                if (blockTimeout > 0) {
                    blockTimeout = this.blockingConnection.capabilities.canDoubleTimeout ? blockTimeout : Math.ceil(blockTimeout);
                    // We cannot trust that the blocking connection stays blocking forever
                    // due to issues in Redis and IORedis, so we will reconnect if we
                    // don't get a response in the expected time.
                    timeout = setTimeout(async ()=>{
                        bclient.disconnect(!this.closing);
                    }, blockTimeout * 1000 + 1000);
                    this.updateDelays(); // reset delays to avoid reusing same values in next iteration
                    // Markers should only be used for un-blocking, so we will handle them in this
                    // function only.
                    const result = await bclient.bzpopmin(this.keys.marker, blockTimeout);
                    if (result) {
                        const [_key, member, score] = result;
                        if (member) {
                            const newBlockUntil = parseInt(score);
                            // Use by pro version as rate limited groups could generate lower blockUntil values
                            // markers only return delays for delayed jobs
                            if (blockUntil && newBlockUntil > blockUntil) {
                                return blockUntil;
                            }
                            return newBlockUntil;
                        }
                    }
                }
                return 0;
            }
        } catch (error) {
            if ((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isNotConnectionError"])(error)) {
                this.emit('error', error);
            }
            if (!this.closing) {
                await this.delay();
            }
        } finally{
            clearTimeout(timeout);
        }
        return Infinity;
    }
    getBlockTimeout(blockUntil) {
        const opts = this.opts;
        // when there are delayed jobs
        if (blockUntil) {
            const blockDelay = blockUntil - Date.now();
            // when we reach the time to get new jobs
            if (blockDelay <= 0) {
                return blockDelay;
            } else if (blockDelay < this.minimumBlockTimeout * 1000) {
                return this.minimumBlockTimeout;
            } else {
                // We restrict the maximum block timeout to 10 second to avoid
                // blocking the connection for too long in the case of reconnections
                // reference: https://github.com/taskforcesh/bullmq/issues/1658
                return Math.min(blockDelay / 1000, maximumBlockTimeout);
            }
        } else {
            return Math.max(opts.drainDelay, this.minimumBlockTimeout);
        }
    }
    getRateLimitDelay(delay) {
        // We restrict the maximum limit delay to the configured maximumRateLimitDelay
        // to be able to promote delayed jobs while the queue is rate limited
        return Math.min(delay, this.opts.maximumRateLimitDelay);
    }
    /**
     *
     * This function is exposed only for testing purposes.
     */ async delay(milliseconds, abortController) {
        await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["delay"])(milliseconds || __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["DELAY_TIME_1"], abortController);
    }
    updateDelays(limitDelay = 0, delayUntil = 0) {
        const clampedLimit = Math.max(limitDelay, 0);
        if (clampedLimit > 0) {
            this.limitUntil = Date.now() + clampedLimit;
        } else {
            this.limitUntil = 0;
        }
        this.blockUntil = Math.max(delayUntil, 0) || 0;
    }
    async nextJobFromJobData(jobData, jobId, token) {
        if (!jobData) {
            if (!this.drained) {
                this.emit('drained');
                this.drained = true;
            }
        } else {
            this.drained = false;
            const job = this.createJob(jobData, jobId);
            job.token = token;
            try {
                await this.retryIfFailed(async ()=>{
                    if (job.repeatJobKey && job.repeatJobKey.split(':').length < 5) {
                        const jobScheduler = await this.jobScheduler;
                        await jobScheduler.upsertJobScheduler(// Most of these arguments are not really needed
                        // anymore as we read them from the job scheduler itself
                        job.repeatJobKey, job.opts.repeat, job.name, job.data, job.opts, {
                            override: false,
                            producerId: job.id
                        });
                    } else if (job.opts.repeat) {
                        const repeat = await this.repeat;
                        await repeat.updateRepeatableJob(job.name, job.data, job.opts, {
                            override: false
                        });
                    }
                }, {
                    delayInMs: this.opts.runRetryDelay
                });
            } catch (err) {
                // Emit error but don't throw to avoid breaking current job completion
                // Note: This means the next repeatable job will not be scheduled
                const errorMessage = err instanceof Error ? err.message : String(err);
                const schedulingError = new Error(`Failed to add repeatable job for next iteration: ${errorMessage}`);
                this.emit('error', schedulingError);
                // Return undefined to indicate no next job is available
                return undefined;
            }
            return job;
        }
    }
    async processJob(job, token, fetchNextCallback = ()=>true) {
        var _a, _b;
        const srcPropagationMedatada = (_b = (_a = job.opts) === null || _a === void 0 ? void 0 : _a.telemetry) === null || _b === void 0 ? void 0 : _b.metadata;
        return this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].CONSUMER, 'process', this.name, async (span)=>{
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerId]: this.id,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerName]: this.opts.name,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobId]: job.id,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobName]: job.name,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobAttemptsMade]: job.attemptsMade
            });
            this.emit('active', job, 'waiting');
            const processedOn = Date.now();
            const abortController = this.lockManager.trackJob(job.id, token, processedOn, this.processorAcceptsSignal);
            try {
                const unrecoverableErrorMessage = this.getUnrecoverableErrorMessage(job);
                if (unrecoverableErrorMessage) {
                    const failed = await this.retryIfFailed(()=>{
                        this.lockManager.untrackJob(job.id);
                        return this.handleFailed(new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$unrecoverable$2d$error$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["UnrecoverableError"](unrecoverableErrorMessage), job, token, fetchNextCallback, span);
                    }, {
                        delayInMs: this.opts.runRetryDelay,
                        span
                    });
                    return failed;
                }
                const result = await this.callProcessJob(job, token, abortController ? abortController.signal : undefined);
                return await this.retryIfFailed(()=>{
                    this.lockManager.untrackJob(job.id);
                    return this.handleCompleted(result, job, token, fetchNextCallback, span);
                }, {
                    delayInMs: this.opts.runRetryDelay,
                    span
                });
            } catch (err) {
                const failed = await this.retryIfFailed(()=>{
                    this.lockManager.untrackJob(job.id);
                    return this.handleFailed(err, job, token, fetchNextCallback, span);
                }, {
                    delayInMs: this.opts.runRetryDelay,
                    span,
                    onlyEmitError: true
                });
                return failed;
            } finally{
                this.lockManager.untrackJob(job.id);
                span === null || span === void 0 ? void 0 : span.setAttributes({
                    [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobFinishedTimestamp]: Date.now(),
                    [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobProcessedTimestamp]: processedOn
                });
            }
        }, srcPropagationMedatada);
    }
    getUnrecoverableErrorMessage(job) {
        if (job.deferredFailure) {
            return job.deferredFailure;
        }
        if (this.opts.maxStartedAttempts && this.opts.maxStartedAttempts < job.attemptsStarted) {
            return 'job started more than allowable limit';
        }
    }
    async handleCompleted(result, job, token, fetchNextCallback = ()=>true, span) {
        if (!this.connection.closing) {
            const completed = await job.moveToCompleted(result, token, fetchNextCallback() && !(this.closing || this.paused));
            this.emit('completed', job, result, 'active');
            span === null || span === void 0 ? void 0 : span.addEvent('job completed', {
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobResult]: JSON.stringify(result)
            });
            const [jobData, jobId, rateLimitDelay, delayUntil] = completed || [];
            this.updateDelays(rateLimitDelay, delayUntil);
            return this.nextJobFromJobData(jobData, jobId, token);
        }
    }
    async handleFailed(err, job, token, fetchNextCallback = ()=>true, span) {
        if (!this.connection.closing) {
            // Check if the job was manually rate-limited
            if (err.message === __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$rate$2d$limit$2d$error$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["RATE_LIMIT_ERROR"]) {
                const rateLimitTtl = await this.moveLimitedBackToWait(job, token);
                this.limitUntil = rateLimitTtl > 0 ? Date.now() + rateLimitTtl : 0;
                return;
            }
            if (err instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$delayed$2d$error$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["DelayedError"] || err.name == 'DelayedError' || err instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$waiting$2d$error$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["WaitingError"] || err.name == 'WaitingError' || err instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$waiting$2d$children$2d$error$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["WaitingChildrenError"] || err.name == 'WaitingChildrenError') {
                const client = await this.client;
                return this.moveToActive(client, token, this.opts.name);
            }
            const result = await job.moveToFailed(err, token, fetchNextCallback() && !(this.closing || this.paused));
            this.emit('failed', job, err, 'active');
            // Note: result can be undefined if moveToFailed fails (e.g., lock was lost)
            if (result) {
                span === null || span === void 0 ? void 0 : span.addEvent('job failed', {
                    [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobFailedReason]: err.message
                });
                const [jobData, jobId, rateLimitDelay, delayUntil] = result;
                this.updateDelays(rateLimitDelay, delayUntil);
                return this.nextJobFromJobData(jobData, jobId, token);
            }
        }
    }
    /**
     *
     * Pauses the processing of this queue only for this worker.
     */ async pause(doNotWaitActive) {
        await this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'pause', this.name, async (span)=>{
            var _a;
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerId]: this.id,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerName]: this.opts.name,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerDoNotWaitActive]: doNotWaitActive
            });
            if (!this.paused) {
                this.paused = true;
                if (!doNotWaitActive) {
                    await this.whenCurrentJobsFinished();
                }
                (_a = this.stalledCheckStopper) === null || _a === void 0 ? void 0 : _a.call(this);
                this.emit('paused');
            }
        });
    }
    /**
     *
     * Resumes processing of this worker (if paused).
     */ resume() {
        if (!this.running) {
            this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'resume', this.name, (span)=>{
                span === null || span === void 0 ? void 0 : span.setAttributes({
                    [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerId]: this.id,
                    [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerName]: this.opts.name
                });
                this.paused = false;
                if (this.processFn) {
                    this.run();
                }
                this.emit('resumed');
            });
        }
    }
    /**
     *
     * Checks if worker is paused.
     *
     * @returns true if worker is paused, false otherwise.
     */ isPaused() {
        return !!this.paused;
    }
    /**
     *
     * Checks if worker is currently running.
     *
     * @returns true if worker is running, false otherwise.
     */ isRunning() {
        return this.running;
    }
    /**
     *
     * Closes the worker and related redis connections.
     *
     * This method waits for current jobs to finalize before returning.
     *
     * @param force - Use force boolean parameter if you do not want to wait for
     * current jobs to be processed. When using telemetry, be mindful that it can
     * interfere with the proper closure of spans, potentially preventing them from being exported.
     *
     * @returns Promise that resolves when the worker has been closed.
     */ async close(force = false) {
        if (this.closing) {
            return this.closing;
        }
        this.closing = (async ()=>{
            await this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'close', this.name, async (span)=>{
                var _a, _b;
                span === null || span === void 0 ? void 0 : span.setAttributes({
                    [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerId]: this.id,
                    [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerName]: this.opts.name,
                    [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerForceClose]: force
                });
                this.emit('closing', 'closing queue');
                (_a = this.abortDelayController) === null || _a === void 0 ? void 0 : _a.abort();
                // Define the async cleanup functions
                const asyncCleanups = [
                    ()=>{
                        return force || this.whenCurrentJobsFinished(false);
                    },
                    ()=>this.lockManager.close(),
                    ()=>{
                        var _a;
                        return (_a = this.childPool) === null || _a === void 0 ? void 0 : _a.clean();
                    },
                    ()=>this.blockingConnection.close(force),
                    ()=>this.connection.close(force)
                ];
                // Run cleanup functions sequentially and make sure all are run despite any errors
                for (const cleanup of asyncCleanups){
                    try {
                        await cleanup();
                    } catch (err) {
                        this.emit('error', err);
                    }
                }
                (_b = this.stalledCheckStopper) === null || _b === void 0 ? void 0 : _b.call(this);
                this.closed = true;
                this.emit('closed');
            });
        })();
        return await this.closing;
    }
    /**
     *
     * Manually starts the stalled checker.
     * The check will run once as soon as this method is called, and
     * then every opts.stalledInterval milliseconds until the worker is closed.
     * Note: Normally you do not need to call this method, since the stalled checker
     * is automatically started when the worker starts processing jobs after
     * calling run. However if you want to process the jobs manually you need
     * to call this method to start the stalled checker.
     *
     * @see {@link https://docs.bullmq.io/patterns/manually-fetching-jobs}
     */ async startStalledCheckTimer() {
        if (!this.opts.skipStalledCheck) {
            if (!this.closing) {
                await this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'startStalledCheckTimer', this.name, async (span)=>{
                    span === null || span === void 0 ? void 0 : span.setAttributes({
                        [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerId]: this.id,
                        [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerName]: this.opts.name
                    });
                    this.stalledChecker().catch((err)=>{
                        this.emit('error', err);
                    });
                });
            }
        }
    }
    async stalledChecker() {
        while(!(this.closing || this.paused)){
            await this.checkConnectionError(()=>this.moveStalledJobsToWait());
            await new Promise((resolve)=>{
                const timeout = setTimeout(resolve, this.opts.stalledInterval);
                this.stalledCheckStopper = ()=>{
                    clearTimeout(timeout);
                    resolve();
                };
            });
        }
    }
    /**
     * Returns a promise that resolves when active jobs are cleared
     *
     * @returns
     */ async whenCurrentJobsFinished(reconnect = true) {
        //
        // Force reconnection of blocking connection to abort blocking redis call immediately.
        //
        if (this.waiting) {
            // If we are not going to reconnect, we will not wait for the disconnection.
            await this.blockingConnection.disconnect(reconnect);
        } else {
            reconnect = false;
        }
        if (this.mainLoopRunning) {
            await this.mainLoopRunning;
        }
        reconnect && await this.blockingConnection.reconnect();
    }
    async retryIfFailed(fn, opts) {
        var _a;
        let retry = 0;
        const maxRetries = opts.maxRetries || Infinity;
        do {
            try {
                return await fn();
            } catch (err) {
                (_a = opts.span) === null || _a === void 0 ? void 0 : _a.recordException(err.message);
                if ((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isNotConnectionError"])(err)) {
                    // Emit error when not paused or closing; optionally swallow (no throw) when opts.onlyEmitError is set.
                    if (!this.paused && !this.closing) {
                        this.emit('error', err);
                    }
                    if (opts.onlyEmitError) {
                        return;
                    } else {
                        throw err;
                    }
                } else {
                    if (opts.delayInMs && !this.closing && !this.closed) {
                        await this.delay(opts.delayInMs, this.abortDelayController);
                    }
                    if (retry + 1 >= maxRetries) {
                        // If we've reached max retries, throw the last error
                        throw err;
                    }
                }
            }
        }while (++retry < maxRetries)
    }
    async moveStalledJobsToWait() {
        await this.trace(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SpanKind"].INTERNAL, 'moveStalledJobsToWait', this.name, async (span)=>{
            const stalled = await this.scripts.moveStalledJobsToWait();
            span === null || span === void 0 ? void 0 : span.setAttributes({
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerId]: this.id,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerName]: this.opts.name,
                [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].WorkerStalledJobs]: stalled
            });
            stalled.forEach((jobId)=>{
                span === null || span === void 0 ? void 0 : span.addEvent('job stalled', {
                    [__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$telemetry$2d$attributes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TelemetryAttributes"].JobId]: jobId
                });
                this.emit('stalled', jobId, 'active');
            });
        });
    }
    moveLimitedBackToWait(job, token) {
        return job.moveToWait(token);
    }
} //# sourceMappingURL=worker.js.map
}),
"[project]/node_modules/bullmq/dist/esm/classes/index.js [app-route] (ecmascript) <locals>", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$async$2d$fifo$2d$queue$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/async-fifo-queue.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$backoffs$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/backoffs.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$child$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/child.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$child$2d$pool$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/child-pool.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$child$2d$processor$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/child-processor.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$errors$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/errors/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$flow$2d$producer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/flow-producer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$job$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/job.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$job$2d$scheduler$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/job-scheduler.js [app-route] (ecmascript)");
// export * from './main'; this file must not be exported
// export * from './main-worker'; this file must not be exported
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$lock$2d$manager$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/lock-manager.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$base$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/queue-base.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$events$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/queue-events.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$events$2d$producer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/queue-events-producer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$getters$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/queue-getters.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2d$keys$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/queue-keys.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$queue$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/queue.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$redis$2d$connection$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/redis-connection.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$repeat$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/repeat.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$sandbox$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/sandbox.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$scripts$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/scripts.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$worker$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/worker.js [app-route] (ecmascript)"); //# sourceMappingURL=index.js.map
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/advanced-options.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=advanced-options.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/backoff-options.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=backoff-options.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/base-job-options.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=base-job-options.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/child-message.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=child-message.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/connection.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=connection.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/flow-job.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=flow-job.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/ioredis-events.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=ioredis-events.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/job-json.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=job-json.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/job-scheduler-json.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=job-scheduler-json.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/keep-jobs.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=keep-jobs.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/metrics-options.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=metrics-options.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/metrics.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=metrics.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/minimal-job.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=minimal-job.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/minimal-queue.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=minimal-queue.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/parent-message.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=parent-message.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/parent.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=parent.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/parent-options.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=parent-options.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/queue-meta.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=queue-meta.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/queue-options.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "ClientType",
    ()=>ClientType
]);
var ClientType;
(function(ClientType) {
    ClientType["blocking"] = "blocking";
    ClientType["normal"] = "normal";
})(ClientType || (ClientType = {})); //# sourceMappingURL=queue-options.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/rate-limiter-options.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=rate-limiter-options.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/redis-options.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=redis-options.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/redis-streams.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=redis-streams.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/repeatable-job.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=repeatable-job.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/repeatable-options.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=repeatable-options.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/repeat-options.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=repeat-options.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/script-queue-context.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=script-queue-context.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/sandboxed-job-processor.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=sandboxed-job-processor.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/sandboxed-job.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=sandboxed-job.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/sandboxed-options.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=sandboxed-options.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/worker-options.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=worker-options.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/telemetry.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=telemetry.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/receiver.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=receiver.js.map
}),
"[project]/node_modules/bullmq/dist/esm/interfaces/index.js [app-route] (ecmascript) <locals>", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$advanced$2d$options$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/advanced-options.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$backoff$2d$options$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/backoff-options.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$base$2d$job$2d$options$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/base-job-options.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$child$2d$message$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/child-message.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$connection$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/connection.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$flow$2d$job$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/flow-job.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$ioredis$2d$events$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/ioredis-events.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$job$2d$json$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/job-json.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$job$2d$scheduler$2d$json$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/job-scheduler-json.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$keep$2d$jobs$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/keep-jobs.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$metrics$2d$options$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/metrics-options.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$metrics$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/metrics.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$minimal$2d$job$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/minimal-job.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$minimal$2d$queue$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/minimal-queue.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$parent$2d$message$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/parent-message.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$parent$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/parent.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$parent$2d$options$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/parent-options.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$queue$2d$meta$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/queue-meta.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$queue$2d$options$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/queue-options.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$rate$2d$limiter$2d$options$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/rate-limiter-options.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$redis$2d$options$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/redis-options.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$redis$2d$streams$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/redis-streams.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$repeatable$2d$job$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/repeatable-job.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$repeatable$2d$options$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/repeatable-options.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$repeat$2d$options$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/repeat-options.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$script$2d$queue$2d$context$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/script-queue-context.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$sandboxed$2d$job$2d$processor$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/sandboxed-job-processor.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$sandboxed$2d$job$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/sandboxed-job.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$sandboxed$2d$options$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/sandboxed-options.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$worker$2d$options$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/worker-options.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$telemetry$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/telemetry.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$receiver$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/receiver.js [app-route] (ecmascript)"); //# sourceMappingURL=index.js.map
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
}),
"[project]/node_modules/bullmq/dist/esm/types/backoff-strategy.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=backoff-strategy.js.map
}),
"[project]/node_modules/bullmq/dist/esm/types/deduplication-options.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=deduplication-options.js.map
}),
"[project]/node_modules/bullmq/dist/esm/types/finished-status.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=finished-status.js.map
}),
"[project]/node_modules/bullmq/dist/esm/types/job-json-sandbox.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=job-json-sandbox.js.map
}),
"[project]/node_modules/bullmq/dist/esm/types/job-options.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=job-options.js.map
}),
"[project]/node_modules/bullmq/dist/esm/types/job-scheduler-template-options.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=job-scheduler-template-options.js.map
}),
"[project]/node_modules/bullmq/dist/esm/types/job-type.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=job-type.js.map
}),
"[project]/node_modules/bullmq/dist/esm/types/job-progress.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=job-progress.js.map
}),
"[project]/node_modules/bullmq/dist/esm/types/repeat-strategy.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=repeat-strategy.js.map
}),
"[project]/node_modules/bullmq/dist/esm/types/index.js [app-route] (ecmascript) <locals>", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$types$2f$backoff$2d$strategy$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/types/backoff-strategy.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$types$2f$deduplication$2d$options$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/types/deduplication-options.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$types$2f$finished$2d$status$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/types/finished-status.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$types$2f$job$2d$json$2d$sandbox$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/types/job-json-sandbox.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$types$2f$job$2d$options$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/types/job-options.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$types$2f$job$2d$scheduler$2d$template$2d$options$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/types/job-scheduler-template-options.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$types$2f$job$2d$type$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/types/job-type.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$types$2f$job$2d$progress$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/types/job-progress.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$types$2f$repeat$2d$strategy$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/types/repeat-strategy.js [app-route] (ecmascript)"); //# sourceMappingURL=index.js.map
;
;
;
;
;
;
;
;
;
}),
"[project]/node_modules/bullmq/dist/esm/types/processor.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
;
 //# sourceMappingURL=processor.js.map
}),
"[project]/node_modules/bullmq/dist/esm/index.js [app-route] (ecmascript) <locals>", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$classes$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/classes/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$enums$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/enums/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$interfaces$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/interfaces/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$types$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/types/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/utils/index.js [app-route] (ecmascript)");
// to prevent circular references
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$types$2f$processor$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/types/processor.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$bullmq$2f$dist$2f$esm$2f$utils$2f$create$2d$scripts$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/bullmq/dist/esm/utils/create-scripts.js [app-route] (ecmascript)"); //# sourceMappingURL=index.js.map
;
;
;
;
;
;
;
}),
];

//# sourceMappingURL=node_modules_bullmq_dist_esm_643b9dcc._.js.map